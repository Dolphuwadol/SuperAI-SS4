{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":80927,"databundleVersionId":8721443,"sourceType":"competition"}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nimport plotly.express as px","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-06T11:48:00.499124Z","iopub.execute_input":"2024-06-06T11:48:00.499696Z","iopub.status.idle":"2024-06-06T11:48:00.505605Z","shell.execute_reply.started":"2024-06-06T11:48:00.499654Z","shell.execute_reply":"2024-06-06T11:48:00.504475Z"},"trusted":true},"outputs":[],"execution_count":63},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/forest-type-classification-spai/train.csv')\ntest = pd.read_csv('/kaggle/input/forest-type-classification-spai/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/forest-type-classification-spai/sample_submission.csv')\nmetadata = pd.read_csv('/kaggle/input/forest-type-classification-spai/metaData.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:48:02.073207Z","iopub.execute_input":"2024-06-06T11:48:02.073616Z","iopub.status.idle":"2024-06-06T11:48:02.144101Z","shell.execute_reply.started":"2024-06-06T11:48:02.073583Z","shell.execute_reply":"2024-06-06T11:48:02.142979Z"},"trusted":true},"outputs":[],"execution_count":64},{"cell_type":"code","source":"train.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:04:57.042904Z","iopub.execute_input":"2024-06-03T05:04:57.043454Z","iopub.status.idle":"2024-06-03T05:04:57.063714Z","shell.execute_reply.started":"2024-06-03T05:04:57.043406Z","shell.execute_reply":"2024-06-03T05:04:57.062910Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"      id   b1   b11   b12   b2    b3   b4    b5    b6    b7    b8  b8_a    b9  \\\n0   2002  293  1927  1038  278   475  453   987  1773  2184  1900  2343  3039   \n1   3212  197  1598   697  201   347  228   682  1982  2449  2254  2685  2690   \n2  13312  929  1975  1031  982  1020  856  1220  2051  2421  2392  2671  2683   \n\n  nforest_type  \n0          MDF  \n1          DDF  \n2          MDF  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>b1</th>\n      <th>b11</th>\n      <th>b12</th>\n      <th>b2</th>\n      <th>b3</th>\n      <th>b4</th>\n      <th>b5</th>\n      <th>b6</th>\n      <th>b7</th>\n      <th>b8</th>\n      <th>b8_a</th>\n      <th>b9</th>\n      <th>nforest_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2002</td>\n      <td>293</td>\n      <td>1927</td>\n      <td>1038</td>\n      <td>278</td>\n      <td>475</td>\n      <td>453</td>\n      <td>987</td>\n      <td>1773</td>\n      <td>2184</td>\n      <td>1900</td>\n      <td>2343</td>\n      <td>3039</td>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3212</td>\n      <td>197</td>\n      <td>1598</td>\n      <td>697</td>\n      <td>201</td>\n      <td>347</td>\n      <td>228</td>\n      <td>682</td>\n      <td>1982</td>\n      <td>2449</td>\n      <td>2254</td>\n      <td>2685</td>\n      <td>2690</td>\n      <td>DDF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13312</td>\n      <td>929</td>\n      <td>1975</td>\n      <td>1031</td>\n      <td>982</td>\n      <td>1020</td>\n      <td>856</td>\n      <td>1220</td>\n      <td>2051</td>\n      <td>2421</td>\n      <td>2392</td>\n      <td>2671</td>\n      <td>2683</td>\n      <td>MDF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"test.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:05:02.367136Z","iopub.execute_input":"2024-06-03T05:05:02.367646Z","iopub.status.idle":"2024-06-03T05:05:02.385371Z","shell.execute_reply.started":"2024-06-03T05:05:02.367606Z","shell.execute_reply":"2024-06-03T05:05:02.384430Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      id   b1   b11   b12   b2   b3   b4   b5    b6    b7    b8  b8_a    b9\n0  13467   69  1425   693  312  524  376  847  1821  2356  2378  2611  2595\n1  12719  242  1514   691  343  522  324  718  1730  2178  2472  2359  2582\n2   1054  218  2354  1118  292  596  410  965  2586  3226  3371  3645  3149","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>b1</th>\n      <th>b11</th>\n      <th>b12</th>\n      <th>b2</th>\n      <th>b3</th>\n      <th>b4</th>\n      <th>b5</th>\n      <th>b6</th>\n      <th>b7</th>\n      <th>b8</th>\n      <th>b8_a</th>\n      <th>b9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13467</td>\n      <td>69</td>\n      <td>1425</td>\n      <td>693</td>\n      <td>312</td>\n      <td>524</td>\n      <td>376</td>\n      <td>847</td>\n      <td>1821</td>\n      <td>2356</td>\n      <td>2378</td>\n      <td>2611</td>\n      <td>2595</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12719</td>\n      <td>242</td>\n      <td>1514</td>\n      <td>691</td>\n      <td>343</td>\n      <td>522</td>\n      <td>324</td>\n      <td>718</td>\n      <td>1730</td>\n      <td>2178</td>\n      <td>2472</td>\n      <td>2359</td>\n      <td>2582</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1054</td>\n      <td>218</td>\n      <td>2354</td>\n      <td>1118</td>\n      <td>292</td>\n      <td>596</td>\n      <td>410</td>\n      <td>965</td>\n      <td>2586</td>\n      <td>3226</td>\n      <td>3371</td>\n      <td>3645</td>\n      <td>3149</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"sample_submission.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:05:12.837794Z","iopub.execute_input":"2024-06-03T05:05:12.838232Z","iopub.status.idle":"2024-06-03T05:05:12.849488Z","shell.execute_reply.started":"2024-06-03T05:05:12.838200Z","shell.execute_reply":"2024-06-03T05:05:12.848091Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"      id nforest_type\n0  13467          DEF\n1  12719          DDF\n2   1054          MDF","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>nforest_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13467</td>\n      <td>DEF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12719</td>\n      <td>DDF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1054</td>\n      <td>MDF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"metadata","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:07:42.781965Z","iopub.execute_input":"2024-06-03T05:07:42.782332Z","iopub.status.idle":"2024-06-03T05:07:42.794466Z","shell.execute_reply.started":"2024-06-03T05:07:42.782304Z","shell.execute_reply":"2024-06-03T05:07:42.793159Z"},"trusted":true},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"     column_name                                        description\n0             id                                          unique id\n1             b1                         Band instrument  Sentinel2\n2            b11                         Band instrument  Sentinel2\n3            b12                         Band instrument  Sentinel2\n4             b2                         Band instrument  Sentinel2\n5             b3                         Band instrument  Sentinel2\n6             b4                         Band instrument  Sentinel2\n7             b5                         Band instrument  Sentinel2\n8             b6                         Band instrument  Sentinel2\n9             b7                         Band instrument  Sentinel2\n10            b8                         Band instrument  Sentinel2\n11          b8_a                         Band instrument  Sentinel2\n12            b9                         Band instrument  Sentinel2\n13  nforest_type  Forest Type (DDF (ป่าเต็งรัง), MDF (ป่าเบญจพรร...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>column_name</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id</td>\n      <td>unique id</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b1</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b11</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b12</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b2</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>b3</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>b4</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>b5</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>b6</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>b7</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>b8</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>b8_a</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>b9</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>nforest_type</td>\n      <td>Forest Type (DDF (ป่าเต็งรัง), MDF (ป่าเบญจพรร...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"train['nforest_type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T06:05:34.802068Z","iopub.execute_input":"2024-06-03T06:05:34.802463Z","iopub.status.idle":"2024-06-03T06:05:34.814277Z","shell.execute_reply.started":"2024-06-03T06:05:34.802432Z","shell.execute_reply":"2024-06-03T06:05:34.812933Z"},"trusted":true},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"nforest_type\nMDF    5865\nDDF    4603\nDEF    2585\nName: count, dtype: int64"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:08:05.193453Z","iopub.execute_input":"2024-06-03T05:08:05.193899Z","iopub.status.idle":"2024-06-03T05:08:05.221788Z","shell.execute_reply.started":"2024-06-03T05:08:05.193864Z","shell.execute_reply":"2024-06-03T05:08:05.219645Z"},"trusted":true},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 13053 entries, 0 to 13052\nData columns (total 14 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   id            13053 non-null  int64 \n 1   b1            13053 non-null  int64 \n 2   b11           13053 non-null  int64 \n 3   b12           13053 non-null  int64 \n 4   b2            13053 non-null  int64 \n 5   b3            13053 non-null  int64 \n 6   b4            13053 non-null  int64 \n 7   b5            13053 non-null  int64 \n 8   b6            13053 non-null  int64 \n 9   b7            13053 non-null  int64 \n 10  b8            13053 non-null  int64 \n 11  b8_a          13053 non-null  int64 \n 12  b9            13053 non-null  int64 \n 13  nforest_type  13053 non-null  object\ndtypes: int64(13), object(1)\nmemory usage: 1.4+ MB\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Pycarat","metadata":{}},{"cell_type":"code","source":"!pip install pycaret","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:08:57.926430Z","iopub.execute_input":"2024-06-03T05:08:57.926946Z","iopub.status.idle":"2024-06-03T05:09:46.657095Z","shell.execute_reply.started":"2024-06-03T05:08:57.926899Z","shell.execute_reply":"2024-06-03T05:09:46.655658Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting pycaret\n  Using cached pycaret-3.3.2-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: ipython>=5.5.0 in /opt/conda/lib/python3.10/site-packages (from pycaret) (8.20.0)\nRequirement already satisfied: ipywidgets>=7.6.5 in /opt/conda/lib/python3.10/site-packages (from pycaret) (7.7.1)\nRequirement already satisfied: tqdm>=4.62.0 in /opt/conda/lib/python3.10/site-packages (from pycaret) (4.66.4)\nRequirement already satisfied: numpy<1.27,>=1.21 in /opt/conda/lib/python3.10/site-packages (from pycaret) (1.26.4)\nCollecting pandas<2.2.0 (from pycaret)\n  Using cached pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: jinja2>=3 in /opt/conda/lib/python3.10/site-packages (from pycaret) (3.1.2)\nRequirement already satisfied: scipy<=1.11.4,>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from pycaret) (1.11.4)\nCollecting joblib<1.4,>=1.2.0 (from pycaret)\n  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting scikit-learn>1.4.0 (from pycaret)\n  Using cached scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting pyod>=1.1.3 (from pycaret)\n  Using cached pyod-2.0.0.tar.gz (164 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: imbalanced-learn>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from pycaret) (0.12.3)\nRequirement already satisfied: category-encoders>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from pycaret) (2.6.3)\nRequirement already satisfied: lightgbm>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from pycaret) (4.2.0)\nRequirement already satisfied: numba>=0.55.0 in /opt/conda/lib/python3.10/site-packages (from pycaret) (0.58.1)\nRequirement already satisfied: requests>=2.27.1 in /opt/conda/lib/python3.10/site-packages (from pycaret) (2.31.0)\nRequirement already satisfied: psutil>=5.9.0 in /opt/conda/lib/python3.10/site-packages (from pycaret) (5.9.3)\nRequirement already satisfied: markupsafe>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from pycaret) (2.1.3)\nRequirement already satisfied: importlib-metadata>=4.12.0 in /opt/conda/lib/python3.10/site-packages (from pycaret) (6.11.0)\nRequirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pycaret) (5.9.2)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from pycaret) (2.2.1)\nRequirement already satisfied: deprecation>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycaret) (2.1.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from pycaret) (3.4.1)\nRequirement already satisfied: matplotlib<3.8.0 in /opt/conda/lib/python3.10/site-packages (from pycaret) (3.7.5)\nRequirement already satisfied: scikit-plot>=0.3.7 in /opt/conda/lib/python3.10/site-packages (from pycaret) (0.3.7)\nRequirement already satisfied: yellowbrick>=1.4 in /opt/conda/lib/python3.10/site-packages (from pycaret) (1.5)\nRequirement already satisfied: plotly>=5.14.0 in /opt/conda/lib/python3.10/site-packages (from pycaret) (5.18.0)\nCollecting kaleido>=0.2.1 (from pycaret)\n  Using cached kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\nCollecting schemdraw==0.15 (from pycaret)\n  Using cached schemdraw-0.15-py3-none-any.whl.metadata (2.2 kB)\nCollecting plotly-resampler>=0.8.3.1 (from pycaret)\n  Using cached plotly_resampler-0.10.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: statsmodels>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from pycaret) (0.14.1)\nCollecting sktime==0.26.0 (from pycaret)\n  Using cached sktime-0.26.0-py3-none-any.whl.metadata (29 kB)\nCollecting tbats>=1.1.3 (from pycaret)\n  Using cached tbats-1.1.3-py3-none-any.whl.metadata (3.8 kB)\nCollecting pmdarima>=2.0.4 (from pycaret)\n  Using cached pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\nCollecting wurlitzer (from pycaret)\n  Using cached wurlitzer-3.1.0-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from sktime==0.26.0->pycaret) (21.3)\nCollecting scikit-base<0.8.0 (from sktime==0.26.0->pycaret)\n  Using cached scikit_base-0.7.8-py3-none-any.whl.metadata (8.8 kB)\nCollecting scikit-learn>1.4.0 (from pycaret)\n  Using cached scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from category-encoders>=2.4.0->pycaret) (0.5.6)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from imbalanced-learn>=0.12.0->pycaret) (3.2.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.12.0->pycaret) (3.17.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (0.1.6)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (3.0.42)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (2.17.2)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (0.6.2)\nRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (5.9.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret) (4.8.0)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets>=7.6.5->pycaret) (6.28.0)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets>=7.6.5->pycaret) (0.2.0)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets>=7.6.5->pycaret) (3.6.6)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets>=7.6.5->pycaret) (3.0.9)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret) (2.9.0.post0)\nRequirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.2.0->pycaret) (2.19.1)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.2.0->pycaret) (4.20.0)\nRequirement already satisfied: jupyter-core in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.2.0->pycaret) (5.7.1)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.55.0->pycaret) (0.41.1)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.2.0->pycaret) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.2.0->pycaret) (2023.4)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly>=5.14.0->pycaret) (8.2.3)\nCollecting dash>=2.9.0 (from plotly-resampler>=0.8.3.1->pycaret)\n  Using cached dash-2.17.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: orjson<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from plotly-resampler>=0.8.3.1->pycaret) (3.9.10)\nCollecting tsdownsample>=0.1.3 (from plotly-resampler>=0.8.3.1->pycaret)\n  Using cached tsdownsample-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\nRequirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /opt/conda/lib/python3.10/site-packages (from pmdarima>=2.0.4->pycaret) (3.0.8)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from pmdarima>=2.0.4->pycaret) (1.26.18)\nRequirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /opt/conda/lib/python3.10/site-packages (from pmdarima>=2.0.4->pycaret) (69.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.27.1->pycaret) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.27.1->pycaret) (3.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.27.1->pycaret) (2024.2.2)\nRequirement already satisfied: Flask<3.1,>=1.0.4 in /opt/conda/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\nRequirement already satisfied: Werkzeug<3.1 in /opt/conda/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (3.0.3)\nCollecting dash-html-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n  Using cached dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting dash-core-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n  Using cached dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting dash-table==5.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret)\n  Using cached dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (4.9.0)\nRequirement already satisfied: retrying in /opt/conda/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.3.3)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.5.8)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (0.2.1)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (1.8.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (7.4.9)\nRequirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (24.0.1)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.3.3)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.16.2)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core->nbformat>=4.2.0->pycaret) (4.2.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.1->category-encoders>=2.4.0->pycaret) (1.16.0)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.5.0->pycaret) (0.2.13)\nRequirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.4)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=5.5.0->pycaret) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=5.5.0->pycaret) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=5.5.0->pycaret) (0.2.2)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret) (1.8.2)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (0.4)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (23.1.0)\nRequirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.4.5)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.2)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.18.0)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.19.0)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.0.0)\nRequirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.12.5)\nRequirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.2.3)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.3.0)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.1.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.12.2)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.13)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (21.2.0)\nRequirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.2.0)\nRequirement already satisfied: jupyter-events>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.9.0)\nRequirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.1)\nRequirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (7.4.0)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.7.0)\nRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.16.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.5)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.1)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.21)\nRequirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.0.7)\nRequirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.0.1)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.1.1)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.5.1)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.4)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.0)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.13)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.3.0)\nRequirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.8.19.20240106)\nDownloading pycaret-3.3.2-py3-none-any.whl (486 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.1/486.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading schemdraw-0.15-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sktime-0.26.0-py3-none-any.whl (21.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading plotly_resampler-0.10.0-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading tbats-1.1.3-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wurlitzer-3.1.0-py3-none-any.whl (8.4 kB)\nDownloading dash-2.17.0-py3-none-any.whl (7.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\nDownloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\nDownloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\nDownloading scikit_base-0.7.8-py3-none-any.whl (130 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.1/130.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tsdownsample-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pyod\n  Building wheel for pyod (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyod: filename=pyod-2.0.0-py3-none-any.whl size=196325 sha256=faf40645a75760d355215da1da7ca69e59b805a27ffa1720fc34eae4021e10e0\n  Stored in directory: /root/.cache/pip/wheels/15/0e/91/96b270e6741d4eece88727489411330226ff47ac1cb9ea0097\nSuccessfully built pyod\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: kaleido, dash-table, dash-html-components, dash-core-components, wurlitzer, tsdownsample, scikit-base, schemdraw, joblib, scikit-learn, pandas, sktime, pyod, dash, pmdarima, plotly-resampler, tbats, pycaret\n  Attempting uninstall: joblib\n    Found existing installation: joblib 1.4.2\n    Uninstalling joblib-1.4.2:\n      Successfully uninstalled joblib-1.4.2\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.2\n    Uninstalling pandas-2.2.2:\n      Successfully uninstalled pandas-2.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 2.19.1 requires aiohttp, which is not installed.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.1 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nxarray 2024.5.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed dash-2.17.0 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 joblib-1.3.2 kaleido-0.2.1 pandas-2.1.4 plotly-resampler-0.10.0 pmdarima-2.0.4 pycaret-3.3.2 pyod-2.0.0 schemdraw-0.15 scikit-base-0.7.8 scikit-learn-1.4.2 sktime-0.26.0 tbats-1.1.3 tsdownsample-0.1.3 wurlitzer-3.1.0\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from pycaret.classification import *\nfrom sklearn.model_selection import train_test_split\nfrom pycaret.classification import setup","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:10:18.211133Z","iopub.execute_input":"2024-06-03T05:10:18.211503Z","iopub.status.idle":"2024-06-03T05:10:18.216750Z","shell.execute_reply.started":"2024-06-03T05:10:18.211474Z","shell.execute_reply":"2024-06-03T05:10:18.215626Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"train_data, test_data = train_test_split(train, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:10:29.984389Z","iopub.execute_input":"2024-06-03T05:10:29.984951Z","iopub.status.idle":"2024-06-03T05:10:29.997389Z","shell.execute_reply.started":"2024-06-03T05:10:29.984905Z","shell.execute_reply":"2024-06-03T05:10:29.996542Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Setting up the PyCaret environment with the training data and generating a profile report\nclf1 = setup(data = train_data, target = 'nforest_type')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:11:13.296018Z","iopub.execute_input":"2024-06-03T05:11:13.296538Z","iopub.status.idle":"2024-06-03T05:11:17.499526Z","shell.execute_reply.started":"2024-06-03T05:11:13.296495Z","shell.execute_reply":"2024-06-03T05:11:17.498461Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7b457a0a2bf0>","text/html":"<style type=\"text/css\">\n#T_9050c_row9_col1 {\n  background-color: lightgreen;\n}\n</style>\n<table id=\"T_9050c\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_9050c_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n      <th id=\"T_9050c_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_9050c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_9050c_row0_col0\" class=\"data row0 col0\" >Session id</td>\n      <td id=\"T_9050c_row0_col1\" class=\"data row0 col1\" >8606</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_9050c_row1_col0\" class=\"data row1 col0\" >Target</td>\n      <td id=\"T_9050c_row1_col1\" class=\"data row1 col1\" >nforest_type</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_9050c_row2_col0\" class=\"data row2 col0\" >Target type</td>\n      <td id=\"T_9050c_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_9050c_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n      <td id=\"T_9050c_row3_col1\" class=\"data row3 col1\" >DDF: 0, DEF: 1, MDF: 2</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_9050c_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n      <td id=\"T_9050c_row4_col1\" class=\"data row4 col1\" >(9137, 14)</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_9050c_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n      <td id=\"T_9050c_row5_col1\" class=\"data row5 col1\" >(9137, 14)</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n      <td id=\"T_9050c_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n      <td id=\"T_9050c_row6_col1\" class=\"data row6 col1\" >(6395, 14)</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n      <td id=\"T_9050c_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n      <td id=\"T_9050c_row7_col1\" class=\"data row7 col1\" >(2742, 14)</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n      <td id=\"T_9050c_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n      <td id=\"T_9050c_row8_col1\" class=\"data row8 col1\" >13</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n      <td id=\"T_9050c_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n      <td id=\"T_9050c_row9_col1\" class=\"data row9 col1\" >True</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n      <td id=\"T_9050c_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n      <td id=\"T_9050c_row10_col1\" class=\"data row10 col1\" >simple</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n      <td id=\"T_9050c_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n      <td id=\"T_9050c_row11_col1\" class=\"data row11 col1\" >mean</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n      <td id=\"T_9050c_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n      <td id=\"T_9050c_row12_col1\" class=\"data row12 col1\" >mode</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n      <td id=\"T_9050c_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n      <td id=\"T_9050c_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n      <td id=\"T_9050c_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n      <td id=\"T_9050c_row14_col1\" class=\"data row14 col1\" >10</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n      <td id=\"T_9050c_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n      <td id=\"T_9050c_row15_col1\" class=\"data row15 col1\" >-1</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n      <td id=\"T_9050c_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n      <td id=\"T_9050c_row16_col1\" class=\"data row16 col1\" >False</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n      <td id=\"T_9050c_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n      <td id=\"T_9050c_row17_col1\" class=\"data row17 col1\" >False</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n      <td id=\"T_9050c_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n      <td id=\"T_9050c_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n    </tr>\n    <tr>\n      <th id=\"T_9050c_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n      <td id=\"T_9050c_row19_col0\" class=\"data row19 col0\" >USI</td>\n      <td id=\"T_9050c_row19_col1\" class=\"data row19 col1\" >0065</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"models = compare_models()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:11:38.035063Z","iopub.execute_input":"2024-06-03T05:11:38.035515Z","iopub.status.idle":"2024-06-03T05:14:44.685892Z","shell.execute_reply.started":"2024-06-03T05:11:38.035485Z","shell.execute_reply":"2024-06-03T05:14:44.684201Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7b457addf9d0>","text/html":"<style type=\"text/css\">\n#T_d1337 th {\n  text-align: left;\n}\n#T_d1337_row0_col0, #T_d1337_row1_col0, #T_d1337_row1_col1, #T_d1337_row1_col2, #T_d1337_row1_col3, #T_d1337_row1_col4, #T_d1337_row1_col5, #T_d1337_row1_col6, #T_d1337_row1_col7, #T_d1337_row2_col0, #T_d1337_row2_col1, #T_d1337_row2_col2, #T_d1337_row2_col3, #T_d1337_row2_col4, #T_d1337_row2_col5, #T_d1337_row2_col6, #T_d1337_row2_col7, #T_d1337_row3_col0, #T_d1337_row3_col1, #T_d1337_row3_col2, #T_d1337_row3_col3, #T_d1337_row3_col4, #T_d1337_row3_col5, #T_d1337_row3_col6, #T_d1337_row3_col7, #T_d1337_row4_col0, #T_d1337_row4_col1, #T_d1337_row4_col2, #T_d1337_row4_col3, #T_d1337_row4_col4, #T_d1337_row4_col5, #T_d1337_row4_col6, #T_d1337_row4_col7, #T_d1337_row5_col0, #T_d1337_row5_col1, #T_d1337_row5_col2, #T_d1337_row5_col3, #T_d1337_row5_col4, #T_d1337_row5_col5, #T_d1337_row5_col6, #T_d1337_row5_col7, #T_d1337_row6_col0, #T_d1337_row6_col1, #T_d1337_row6_col2, #T_d1337_row6_col3, #T_d1337_row6_col4, #T_d1337_row6_col5, #T_d1337_row6_col6, #T_d1337_row6_col7, #T_d1337_row7_col0, #T_d1337_row7_col1, #T_d1337_row7_col2, #T_d1337_row7_col3, #T_d1337_row7_col4, #T_d1337_row7_col5, #T_d1337_row7_col6, #T_d1337_row7_col7, #T_d1337_row8_col0, #T_d1337_row8_col1, #T_d1337_row8_col2, #T_d1337_row8_col3, #T_d1337_row8_col4, #T_d1337_row8_col5, #T_d1337_row8_col6, #T_d1337_row8_col7, #T_d1337_row9_col0, #T_d1337_row9_col1, #T_d1337_row9_col2, #T_d1337_row9_col3, #T_d1337_row9_col4, #T_d1337_row9_col5, #T_d1337_row9_col6, #T_d1337_row9_col7, #T_d1337_row10_col0, #T_d1337_row10_col1, #T_d1337_row10_col2, #T_d1337_row10_col3, #T_d1337_row10_col4, #T_d1337_row10_col5, #T_d1337_row10_col6, #T_d1337_row10_col7, #T_d1337_row11_col0, #T_d1337_row11_col1, #T_d1337_row11_col2, #T_d1337_row11_col3, #T_d1337_row11_col4, #T_d1337_row11_col5, #T_d1337_row11_col6, #T_d1337_row11_col7, #T_d1337_row12_col0, #T_d1337_row12_col1, #T_d1337_row12_col2, #T_d1337_row12_col3, #T_d1337_row12_col4, #T_d1337_row12_col5, #T_d1337_row12_col6, #T_d1337_row12_col7, #T_d1337_row13_col0, #T_d1337_row13_col1, #T_d1337_row13_col2, #T_d1337_row13_col3, #T_d1337_row13_col4, #T_d1337_row13_col5, #T_d1337_row13_col6, #T_d1337_row13_col7, #T_d1337_row14_col0, #T_d1337_row14_col1, #T_d1337_row14_col2, #T_d1337_row14_col3, #T_d1337_row14_col4, #T_d1337_row14_col5, #T_d1337_row14_col6, #T_d1337_row14_col7, #T_d1337_row15_col0, #T_d1337_row15_col1, #T_d1337_row15_col2, #T_d1337_row15_col3, #T_d1337_row15_col4, #T_d1337_row15_col5, #T_d1337_row15_col6, #T_d1337_row15_col7 {\n  text-align: left;\n}\n#T_d1337_row0_col1, #T_d1337_row0_col2, #T_d1337_row0_col3, #T_d1337_row0_col4, #T_d1337_row0_col5, #T_d1337_row0_col6, #T_d1337_row0_col7 {\n  text-align: left;\n  background-color: yellow;\n}\n#T_d1337_row0_col8, #T_d1337_row1_col8, #T_d1337_row2_col8, #T_d1337_row3_col8, #T_d1337_row4_col8, #T_d1337_row5_col8, #T_d1337_row7_col8, #T_d1337_row9_col8, #T_d1337_row10_col8, #T_d1337_row11_col8, #T_d1337_row12_col8, #T_d1337_row13_col8, #T_d1337_row14_col8, #T_d1337_row15_col8 {\n  text-align: left;\n  background-color: lightgrey;\n}\n#T_d1337_row6_col8, #T_d1337_row8_col8 {\n  text-align: left;\n  background-color: yellow;\n  background-color: lightgrey;\n}\n</style>\n<table id=\"T_d1337\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_d1337_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n      <th id=\"T_d1337_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n      <th id=\"T_d1337_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n      <th id=\"T_d1337_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n      <th id=\"T_d1337_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n      <th id=\"T_d1337_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n      <th id=\"T_d1337_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n      <th id=\"T_d1337_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n      <th id=\"T_d1337_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_d1337_level0_row0\" class=\"row_heading level0 row0\" >catboost</th>\n      <td id=\"T_d1337_row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n      <td id=\"T_d1337_row0_col1\" class=\"data row0 col1\" >0.6735</td>\n      <td id=\"T_d1337_row0_col2\" class=\"data row0 col2\" >0.8112</td>\n      <td id=\"T_d1337_row0_col3\" class=\"data row0 col3\" >0.6735</td>\n      <td id=\"T_d1337_row0_col4\" class=\"data row0 col4\" >0.6756</td>\n      <td id=\"T_d1337_row0_col5\" class=\"data row0 col5\" >0.6729</td>\n      <td id=\"T_d1337_row0_col6\" class=\"data row0 col6\" >0.4791</td>\n      <td id=\"T_d1337_row0_col7\" class=\"data row0 col7\" >0.4804</td>\n      <td id=\"T_d1337_row0_col8\" class=\"data row0 col8\" >8.9450</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n      <td id=\"T_d1337_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n      <td id=\"T_d1337_row1_col1\" class=\"data row1 col1\" >0.6610</td>\n      <td id=\"T_d1337_row1_col2\" class=\"data row1 col2\" >0.8015</td>\n      <td id=\"T_d1337_row1_col3\" class=\"data row1 col3\" >0.6610</td>\n      <td id=\"T_d1337_row1_col4\" class=\"data row1 col4\" >0.6634</td>\n      <td id=\"T_d1337_row1_col5\" class=\"data row1 col5\" >0.6604</td>\n      <td id=\"T_d1337_row1_col6\" class=\"data row1 col6\" >0.4585</td>\n      <td id=\"T_d1337_row1_col7\" class=\"data row1 col7\" >0.4598</td>\n      <td id=\"T_d1337_row1_col8\" class=\"data row1 col8\" >1.2050</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n      <td id=\"T_d1337_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n      <td id=\"T_d1337_row2_col1\" class=\"data row2 col1\" >0.6593</td>\n      <td id=\"T_d1337_row2_col2\" class=\"data row2 col2\" >0.7989</td>\n      <td id=\"T_d1337_row2_col3\" class=\"data row2 col3\" >0.6593</td>\n      <td id=\"T_d1337_row2_col4\" class=\"data row2 col4\" >0.6614</td>\n      <td id=\"T_d1337_row2_col5\" class=\"data row2 col5\" >0.6579</td>\n      <td id=\"T_d1337_row2_col6\" class=\"data row2 col6\" >0.4548</td>\n      <td id=\"T_d1337_row2_col7\" class=\"data row2 col7\" >0.4565</td>\n      <td id=\"T_d1337_row2_col8\" class=\"data row2 col8\" >0.9580</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row3\" class=\"row_heading level0 row3\" >et</th>\n      <td id=\"T_d1337_row3_col0\" class=\"data row3 col0\" >Extra Trees Classifier</td>\n      <td id=\"T_d1337_row3_col1\" class=\"data row3 col1\" >0.6572</td>\n      <td id=\"T_d1337_row3_col2\" class=\"data row3 col2\" >0.7988</td>\n      <td id=\"T_d1337_row3_col3\" class=\"data row3 col3\" >0.6572</td>\n      <td id=\"T_d1337_row3_col4\" class=\"data row3 col4\" >0.6618</td>\n      <td id=\"T_d1337_row3_col5\" class=\"data row3 col5\" >0.6566</td>\n      <td id=\"T_d1337_row3_col6\" class=\"data row3 col6\" >0.4504</td>\n      <td id=\"T_d1337_row3_col7\" class=\"data row3 col7\" >0.4521</td>\n      <td id=\"T_d1337_row3_col8\" class=\"data row3 col8\" >0.4520</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row4\" class=\"row_heading level0 row4\" >xgboost</th>\n      <td id=\"T_d1337_row4_col0\" class=\"data row4 col0\" >Extreme Gradient Boosting</td>\n      <td id=\"T_d1337_row4_col1\" class=\"data row4 col1\" >0.6555</td>\n      <td id=\"T_d1337_row4_col2\" class=\"data row4 col2\" >0.7988</td>\n      <td id=\"T_d1337_row4_col3\" class=\"data row4 col3\" >0.6555</td>\n      <td id=\"T_d1337_row4_col4\" class=\"data row4 col4\" >0.6587</td>\n      <td id=\"T_d1337_row4_col5\" class=\"data row4 col5\" >0.6550</td>\n      <td id=\"T_d1337_row4_col6\" class=\"data row4 col6\" >0.4491</td>\n      <td id=\"T_d1337_row4_col7\" class=\"data row4 col7\" >0.4504</td>\n      <td id=\"T_d1337_row4_col8\" class=\"data row4 col8\" >0.6170</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row5\" class=\"row_heading level0 row5\" >gbc</th>\n      <td id=\"T_d1337_row5_col0\" class=\"data row5 col0\" >Gradient Boosting Classifier</td>\n      <td id=\"T_d1337_row5_col1\" class=\"data row5 col1\" >0.6458</td>\n      <td id=\"T_d1337_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n      <td id=\"T_d1337_row5_col3\" class=\"data row5 col3\" >0.6458</td>\n      <td id=\"T_d1337_row5_col4\" class=\"data row5 col4\" >0.6496</td>\n      <td id=\"T_d1337_row5_col5\" class=\"data row5 col5\" >0.6441</td>\n      <td id=\"T_d1337_row5_col6\" class=\"data row5 col6\" >0.4305</td>\n      <td id=\"T_d1337_row5_col7\" class=\"data row5 col7\" >0.4329</td>\n      <td id=\"T_d1337_row5_col8\" class=\"data row5 col8\" >2.9920</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row6\" class=\"row_heading level0 row6\" >ridge</th>\n      <td id=\"T_d1337_row6_col0\" class=\"data row6 col0\" >Ridge Classifier</td>\n      <td id=\"T_d1337_row6_col1\" class=\"data row6 col1\" >0.6158</td>\n      <td id=\"T_d1337_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n      <td id=\"T_d1337_row6_col3\" class=\"data row6 col3\" >0.6158</td>\n      <td id=\"T_d1337_row6_col4\" class=\"data row6 col4\" >0.6155</td>\n      <td id=\"T_d1337_row6_col5\" class=\"data row6 col5\" >0.6121</td>\n      <td id=\"T_d1337_row6_col6\" class=\"data row6 col6\" >0.3840</td>\n      <td id=\"T_d1337_row6_col7\" class=\"data row6 col7\" >0.3868</td>\n      <td id=\"T_d1337_row6_col8\" class=\"data row6 col8\" >0.0330</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row7\" class=\"row_heading level0 row7\" >lda</th>\n      <td id=\"T_d1337_row7_col0\" class=\"data row7 col0\" >Linear Discriminant Analysis</td>\n      <td id=\"T_d1337_row7_col1\" class=\"data row7 col1\" >0.6147</td>\n      <td id=\"T_d1337_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n      <td id=\"T_d1337_row7_col3\" class=\"data row7 col3\" >0.6147</td>\n      <td id=\"T_d1337_row7_col4\" class=\"data row7 col4\" >0.6140</td>\n      <td id=\"T_d1337_row7_col5\" class=\"data row7 col5\" >0.6126</td>\n      <td id=\"T_d1337_row7_col6\" class=\"data row7 col6\" >0.3863</td>\n      <td id=\"T_d1337_row7_col7\" class=\"data row7 col7\" >0.3877</td>\n      <td id=\"T_d1337_row7_col8\" class=\"data row7 col8\" >0.0350</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row8\" class=\"row_heading level0 row8\" >qda</th>\n      <td id=\"T_d1337_row8_col0\" class=\"data row8 col0\" >Quadratic Discriminant Analysis</td>\n      <td id=\"T_d1337_row8_col1\" class=\"data row8 col1\" >0.6050</td>\n      <td id=\"T_d1337_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n      <td id=\"T_d1337_row8_col3\" class=\"data row8 col3\" >0.6050</td>\n      <td id=\"T_d1337_row8_col4\" class=\"data row8 col4\" >0.6154</td>\n      <td id=\"T_d1337_row8_col5\" class=\"data row8 col5\" >0.6045</td>\n      <td id=\"T_d1337_row8_col6\" class=\"data row8 col6\" >0.3869</td>\n      <td id=\"T_d1337_row8_col7\" class=\"data row8 col7\" >0.3913</td>\n      <td id=\"T_d1337_row8_col8\" class=\"data row8 col8\" >0.0330</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row9\" class=\"row_heading level0 row9\" >ada</th>\n      <td id=\"T_d1337_row9_col0\" class=\"data row9 col0\" >Ada Boost Classifier</td>\n      <td id=\"T_d1337_row9_col1\" class=\"data row9 col1\" >0.5920</td>\n      <td id=\"T_d1337_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n      <td id=\"T_d1337_row9_col3\" class=\"data row9 col3\" >0.5920</td>\n      <td id=\"T_d1337_row9_col4\" class=\"data row9 col4\" >0.5912</td>\n      <td id=\"T_d1337_row9_col5\" class=\"data row9 col5\" >0.5879</td>\n      <td id=\"T_d1337_row9_col6\" class=\"data row9 col6\" >0.3445</td>\n      <td id=\"T_d1337_row9_col7\" class=\"data row9 col7\" >0.3472</td>\n      <td id=\"T_d1337_row9_col8\" class=\"data row9 col8\" >0.2800</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row10\" class=\"row_heading level0 row10\" >lr</th>\n      <td id=\"T_d1337_row10_col0\" class=\"data row10 col0\" >Logistic Regression</td>\n      <td id=\"T_d1337_row10_col1\" class=\"data row10 col1\" >0.5748</td>\n      <td id=\"T_d1337_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n      <td id=\"T_d1337_row10_col3\" class=\"data row10 col3\" >0.5748</td>\n      <td id=\"T_d1337_row10_col4\" class=\"data row10 col4\" >0.5802</td>\n      <td id=\"T_d1337_row10_col5\" class=\"data row10 col5\" >0.5612</td>\n      <td id=\"T_d1337_row10_col6\" class=\"data row10 col6\" >0.3085</td>\n      <td id=\"T_d1337_row10_col7\" class=\"data row10 col7\" >0.3206</td>\n      <td id=\"T_d1337_row10_col8\" class=\"data row10 col8\" >1.1490</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row11\" class=\"row_heading level0 row11\" >dt</th>\n      <td id=\"T_d1337_row11_col0\" class=\"data row11 col0\" >Decision Tree Classifier</td>\n      <td id=\"T_d1337_row11_col1\" class=\"data row11 col1\" >0.5529</td>\n      <td id=\"T_d1337_row11_col2\" class=\"data row11 col2\" >0.6418</td>\n      <td id=\"T_d1337_row11_col3\" class=\"data row11 col3\" >0.5529</td>\n      <td id=\"T_d1337_row11_col4\" class=\"data row11 col4\" >0.5535</td>\n      <td id=\"T_d1337_row11_col5\" class=\"data row11 col5\" >0.5527</td>\n      <td id=\"T_d1337_row11_col6\" class=\"data row11 col6\" >0.2939</td>\n      <td id=\"T_d1337_row11_col7\" class=\"data row11 col7\" >0.2941</td>\n      <td id=\"T_d1337_row11_col8\" class=\"data row11 col8\" >0.0770</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row12\" class=\"row_heading level0 row12\" >knn</th>\n      <td id=\"T_d1337_row12_col0\" class=\"data row12 col0\" >K Neighbors Classifier</td>\n      <td id=\"T_d1337_row12_col1\" class=\"data row12 col1\" >0.5121</td>\n      <td id=\"T_d1337_row12_col2\" class=\"data row12 col2\" >0.6558</td>\n      <td id=\"T_d1337_row12_col3\" class=\"data row12 col3\" >0.5121</td>\n      <td id=\"T_d1337_row12_col4\" class=\"data row12 col4\" >0.5213</td>\n      <td id=\"T_d1337_row12_col5\" class=\"data row12 col5\" >0.5058</td>\n      <td id=\"T_d1337_row12_col6\" class=\"data row12 col6\" >0.2196</td>\n      <td id=\"T_d1337_row12_col7\" class=\"data row12 col7\" >0.2243</td>\n      <td id=\"T_d1337_row12_col8\" class=\"data row12 col8\" >0.0740</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row13\" class=\"row_heading level0 row13\" >svm</th>\n      <td id=\"T_d1337_row13_col0\" class=\"data row13 col0\" >SVM - Linear Kernel</td>\n      <td id=\"T_d1337_row13_col1\" class=\"data row13 col1\" >0.4980</td>\n      <td id=\"T_d1337_row13_col2\" class=\"data row13 col2\" >0.0000</td>\n      <td id=\"T_d1337_row13_col3\" class=\"data row13 col3\" >0.4980</td>\n      <td id=\"T_d1337_row13_col4\" class=\"data row13 col4\" >0.5593</td>\n      <td id=\"T_d1337_row13_col5\" class=\"data row13 col5\" >0.4284</td>\n      <td id=\"T_d1337_row13_col6\" class=\"data row13 col6\" >0.1937</td>\n      <td id=\"T_d1337_row13_col7\" class=\"data row13 col7\" >0.2477</td>\n      <td id=\"T_d1337_row13_col8\" class=\"data row13 col8\" >0.1290</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row14\" class=\"row_heading level0 row14\" >nb</th>\n      <td id=\"T_d1337_row14_col0\" class=\"data row14 col0\" >Naive Bayes</td>\n      <td id=\"T_d1337_row14_col1\" class=\"data row14 col1\" >0.4780</td>\n      <td id=\"T_d1337_row14_col2\" class=\"data row14 col2\" >0.6610</td>\n      <td id=\"T_d1337_row14_col3\" class=\"data row14 col3\" >0.4780</td>\n      <td id=\"T_d1337_row14_col4\" class=\"data row14 col4\" >0.4941</td>\n      <td id=\"T_d1337_row14_col5\" class=\"data row14 col5\" >0.4777</td>\n      <td id=\"T_d1337_row14_col6\" class=\"data row14 col6\" >0.1969</td>\n      <td id=\"T_d1337_row14_col7\" class=\"data row14 col7\" >0.2007</td>\n      <td id=\"T_d1337_row14_col8\" class=\"data row14 col8\" >0.0340</td>\n    </tr>\n    <tr>\n      <th id=\"T_d1337_level0_row15\" class=\"row_heading level0 row15\" >dummy</th>\n      <td id=\"T_d1337_row15_col0\" class=\"data row15 col0\" >Dummy Classifier</td>\n      <td id=\"T_d1337_row15_col1\" class=\"data row15 col1\" >0.4518</td>\n      <td id=\"T_d1337_row15_col2\" class=\"data row15 col2\" >0.5000</td>\n      <td id=\"T_d1337_row15_col3\" class=\"data row15 col3\" >0.4518</td>\n      <td id=\"T_d1337_row15_col4\" class=\"data row15 col4\" >0.2041</td>\n      <td id=\"T_d1337_row15_col5\" class=\"data row15 col5\" >0.2812</td>\n      <td id=\"T_d1337_row15_col6\" class=\"data row15 col6\" >0.0000</td>\n      <td id=\"T_d1337_row15_col7\" class=\"data row15 col7\" >0.0000</td>\n      <td id=\"T_d1337_row15_col8\" class=\"data row15 col8\" >0.0780</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing:   0%|          | 0/69 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"#Picking the winner \nbest_model = automl(optimize = 'Accuracy')\n\n#Fine-tuning the best model\ntuned_best_model = tune_model(best_model)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:15:54.595621Z","iopub.execute_input":"2024-06-03T05:15:54.596498Z","iopub.status.idle":"2024-06-03T05:21:02.807832Z","shell.execute_reply.started":"2024-06-03T05:15:54.596459Z","shell.execute_reply":"2024-06-03T05:21:02.806580Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7b4579af3ac0>","text/html":"<style type=\"text/css\">\n#T_30dea_row10_col0, #T_30dea_row10_col1, #T_30dea_row10_col2, #T_30dea_row10_col3, #T_30dea_row10_col4, #T_30dea_row10_col5, #T_30dea_row10_col6 {\n  background: yellow;\n}\n</style>\n<table id=\"T_30dea\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_30dea_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n      <th id=\"T_30dea_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n      <th id=\"T_30dea_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n      <th id=\"T_30dea_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n      <th id=\"T_30dea_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n      <th id=\"T_30dea_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n      <th id=\"T_30dea_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n    </tr>\n    <tr>\n      <th class=\"index_name level0\" >Fold</th>\n      <th class=\"blank col0\" >&nbsp;</th>\n      <th class=\"blank col1\" >&nbsp;</th>\n      <th class=\"blank col2\" >&nbsp;</th>\n      <th class=\"blank col3\" >&nbsp;</th>\n      <th class=\"blank col4\" >&nbsp;</th>\n      <th class=\"blank col5\" >&nbsp;</th>\n      <th class=\"blank col6\" >&nbsp;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_30dea_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_30dea_row0_col0\" class=\"data row0 col0\" >0.6641</td>\n      <td id=\"T_30dea_row0_col1\" class=\"data row0 col1\" >0.8005</td>\n      <td id=\"T_30dea_row0_col2\" class=\"data row0 col2\" >0.6641</td>\n      <td id=\"T_30dea_row0_col3\" class=\"data row0 col3\" >0.6658</td>\n      <td id=\"T_30dea_row0_col4\" class=\"data row0 col4\" >0.6610</td>\n      <td id=\"T_30dea_row0_col5\" class=\"data row0 col5\" >0.4624</td>\n      <td id=\"T_30dea_row0_col6\" class=\"data row0 col6\" >0.4661</td>\n    </tr>\n    <tr>\n      <th id=\"T_30dea_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_30dea_row1_col0\" class=\"data row1 col0\" >0.6312</td>\n      <td id=\"T_30dea_row1_col1\" class=\"data row1 col1\" >0.7856</td>\n      <td id=\"T_30dea_row1_col2\" class=\"data row1 col2\" >0.6312</td>\n      <td id=\"T_30dea_row1_col3\" class=\"data row1 col3\" >0.6362</td>\n      <td id=\"T_30dea_row1_col4\" class=\"data row1 col4\" >0.6298</td>\n      <td id=\"T_30dea_row1_col5\" class=\"data row1 col5\" >0.4066</td>\n      <td id=\"T_30dea_row1_col6\" class=\"data row1 col6\" >0.4097</td>\n    </tr>\n    <tr>\n      <th id=\"T_30dea_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_30dea_row2_col0\" class=\"data row2 col0\" >0.6391</td>\n      <td id=\"T_30dea_row2_col1\" class=\"data row2 col1\" >0.7981</td>\n      <td id=\"T_30dea_row2_col2\" class=\"data row2 col2\" >0.6391</td>\n      <td id=\"T_30dea_row2_col3\" class=\"data row2 col3\" >0.6412</td>\n      <td id=\"T_30dea_row2_col4\" class=\"data row2 col4\" >0.6382</td>\n      <td id=\"T_30dea_row2_col5\" class=\"data row2 col5\" >0.4223</td>\n      <td id=\"T_30dea_row2_col6\" class=\"data row2 col6\" >0.4236</td>\n    </tr>\n    <tr>\n      <th id=\"T_30dea_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_30dea_row3_col0\" class=\"data row3 col0\" >0.6875</td>\n      <td id=\"T_30dea_row3_col1\" class=\"data row3 col1\" >0.8262</td>\n      <td id=\"T_30dea_row3_col2\" class=\"data row3 col2\" >0.6875</td>\n      <td id=\"T_30dea_row3_col3\" class=\"data row3 col3\" >0.6882</td>\n      <td id=\"T_30dea_row3_col4\" class=\"data row3 col4\" >0.6877</td>\n      <td id=\"T_30dea_row3_col5\" class=\"data row3 col5\" >0.5060</td>\n      <td id=\"T_30dea_row3_col6\" class=\"data row3 col6\" >0.5060</td>\n    </tr>\n    <tr>\n      <th id=\"T_30dea_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_30dea_row4_col0\" class=\"data row4 col0\" >0.6656</td>\n      <td id=\"T_30dea_row4_col1\" class=\"data row4 col1\" >0.7948</td>\n      <td id=\"T_30dea_row4_col2\" class=\"data row4 col2\" >0.6656</td>\n      <td id=\"T_30dea_row4_col3\" class=\"data row4 col3\" >0.6744</td>\n      <td id=\"T_30dea_row4_col4\" class=\"data row4 col4\" >0.6645</td>\n      <td id=\"T_30dea_row4_col5\" class=\"data row4 col5\" >0.4598</td>\n      <td id=\"T_30dea_row4_col6\" class=\"data row4 col6\" >0.4628</td>\n    </tr>\n    <tr>\n      <th id=\"T_30dea_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_30dea_row5_col0\" class=\"data row5 col0\" >0.6729</td>\n      <td id=\"T_30dea_row5_col1\" class=\"data row5 col1\" >0.8038</td>\n      <td id=\"T_30dea_row5_col2\" class=\"data row5 col2\" >0.6729</td>\n      <td id=\"T_30dea_row5_col3\" class=\"data row5 col3\" >0.6782</td>\n      <td id=\"T_30dea_row5_col4\" class=\"data row5 col4\" >0.6737</td>\n      <td id=\"T_30dea_row5_col5\" class=\"data row5 col5\" >0.4770</td>\n      <td id=\"T_30dea_row5_col6\" class=\"data row5 col6\" >0.4781</td>\n    </tr>\n    <tr>\n      <th id=\"T_30dea_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n      <td id=\"T_30dea_row6_col0\" class=\"data row6 col0\" >0.6729</td>\n      <td id=\"T_30dea_row6_col1\" class=\"data row6 col1\" >0.8121</td>\n      <td id=\"T_30dea_row6_col2\" class=\"data row6 col2\" >0.6729</td>\n      <td id=\"T_30dea_row6_col3\" class=\"data row6 col3\" >0.6772</td>\n      <td id=\"T_30dea_row6_col4\" class=\"data row6 col4\" >0.6730</td>\n      <td id=\"T_30dea_row6_col5\" class=\"data row6 col5\" >0.4761</td>\n      <td id=\"T_30dea_row6_col6\" class=\"data row6 col6\" >0.4775</td>\n    </tr>\n    <tr>\n      <th id=\"T_30dea_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n      <td id=\"T_30dea_row7_col0\" class=\"data row7 col0\" >0.6651</td>\n      <td id=\"T_30dea_row7_col1\" class=\"data row7 col1\" >0.8090</td>\n      <td id=\"T_30dea_row7_col2\" class=\"data row7 col2\" >0.6651</td>\n      <td id=\"T_30dea_row7_col3\" class=\"data row7 col3\" >0.6669</td>\n      <td id=\"T_30dea_row7_col4\" class=\"data row7 col4\" >0.6655</td>\n      <td id=\"T_30dea_row7_col5\" class=\"data row7 col5\" >0.4681</td>\n      <td id=\"T_30dea_row7_col6\" class=\"data row7 col6\" >0.4683</td>\n    </tr>\n    <tr>\n      <th id=\"T_30dea_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n      <td id=\"T_30dea_row8_col0\" class=\"data row8 col0\" >0.6870</td>\n      <td id=\"T_30dea_row8_col1\" class=\"data row8 col1\" >0.8309</td>\n      <td id=\"T_30dea_row8_col2\" class=\"data row8 col2\" >0.6870</td>\n      <td id=\"T_30dea_row8_col3\" class=\"data row8 col3\" >0.6870</td>\n      <td id=\"T_30dea_row8_col4\" class=\"data row8 col4\" >0.6867</td>\n      <td id=\"T_30dea_row8_col5\" class=\"data row8 col5\" >0.5034</td>\n      <td id=\"T_30dea_row8_col6\" class=\"data row8 col6\" >0.5037</td>\n    </tr>\n    <tr>\n      <th id=\"T_30dea_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n      <td id=\"T_30dea_row9_col0\" class=\"data row9 col0\" >0.6448</td>\n      <td id=\"T_30dea_row9_col1\" class=\"data row9 col1\" >0.8037</td>\n      <td id=\"T_30dea_row9_col2\" class=\"data row9 col2\" >0.6448</td>\n      <td id=\"T_30dea_row9_col3\" class=\"data row9 col3\" >0.6449</td>\n      <td id=\"T_30dea_row9_col4\" class=\"data row9 col4\" >0.6435</td>\n      <td id=\"T_30dea_row9_col5\" class=\"data row9 col5\" >0.4342</td>\n      <td id=\"T_30dea_row9_col6\" class=\"data row9 col6\" >0.4354</td>\n    </tr>\n    <tr>\n      <th id=\"T_30dea_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n      <td id=\"T_30dea_row10_col0\" class=\"data row10 col0\" >0.6630</td>\n      <td id=\"T_30dea_row10_col1\" class=\"data row10 col1\" >0.8065</td>\n      <td id=\"T_30dea_row10_col2\" class=\"data row10 col2\" >0.6630</td>\n      <td id=\"T_30dea_row10_col3\" class=\"data row10 col3\" >0.6660</td>\n      <td id=\"T_30dea_row10_col4\" class=\"data row10 col4\" >0.6623</td>\n      <td id=\"T_30dea_row10_col5\" class=\"data row10 col5\" >0.4616</td>\n      <td id=\"T_30dea_row10_col6\" class=\"data row10 col6\" >0.4631</td>\n    </tr>\n    <tr>\n      <th id=\"T_30dea_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n      <td id=\"T_30dea_row11_col0\" class=\"data row11 col0\" >0.0182</td>\n      <td id=\"T_30dea_row11_col1\" class=\"data row11 col1\" >0.0131</td>\n      <td id=\"T_30dea_row11_col2\" class=\"data row11 col2\" >0.0182</td>\n      <td id=\"T_30dea_row11_col3\" class=\"data row11 col3\" >0.0180</td>\n      <td id=\"T_30dea_row11_col4\" class=\"data row11 col4\" >0.0187</td>\n      <td id=\"T_30dea_row11_col5\" class=\"data row11 col5\" >0.0309</td>\n      <td id=\"T_30dea_row11_col6\" class=\"data row11 col6\" >0.0302</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Fitting 10 folds for each of 10 candidates, totalling 100 fits\nOriginal model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"best_model","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:23:34.843004Z","iopub.execute_input":"2024-06-03T05:23:34.843429Z","iopub.status.idle":"2024-06-03T05:23:34.851530Z","shell.execute_reply.started":"2024-06-03T05:23:34.843398Z","shell.execute_reply":"2024-06-03T05:23:34.850336Z"},"trusted":true},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<catboost.core.CatBoostClassifier at 0x7b4579af32b0>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"tuned_best_model","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:23:38.847958Z","iopub.execute_input":"2024-06-03T05:23:38.848349Z","iopub.status.idle":"2024-06-03T05:23:38.856148Z","shell.execute_reply.started":"2024-06-03T05:23:38.848319Z","shell.execute_reply":"2024-06-03T05:23:38.854906Z"},"trusted":true},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<catboost.core.CatBoostClassifier at 0x7b457acfc5e0>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"predictions = predict_model(tuned_best_model, data = test_data)\npredictions","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:23:42.784502Z","iopub.execute_input":"2024-06-03T05:23:42.785336Z","iopub.status.idle":"2024-06-03T05:23:43.479688Z","shell.execute_reply.started":"2024-06-03T05:23:42.785286Z","shell.execute_reply":"2024-06-03T05:23:43.478449Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7b457acfdf90>","text/html":"<style type=\"text/css\">\n</style>\n<table id=\"T_0b021\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_0b021_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n      <th id=\"T_0b021_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n      <th id=\"T_0b021_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n      <th id=\"T_0b021_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n      <th id=\"T_0b021_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n      <th id=\"T_0b021_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n      <th id=\"T_0b021_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n      <th id=\"T_0b021_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_0b021_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_0b021_row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n      <td id=\"T_0b021_row0_col1\" class=\"data row0 col1\" >0.6890</td>\n      <td id=\"T_0b021_row0_col2\" class=\"data row0 col2\" >0.8296</td>\n      <td id=\"T_0b021_row0_col3\" class=\"data row0 col3\" >0.6890</td>\n      <td id=\"T_0b021_row0_col4\" class=\"data row0 col4\" >0.6920</td>\n      <td id=\"T_0b021_row0_col5\" class=\"data row0 col5\" >0.6882</td>\n      <td id=\"T_0b021_row0_col6\" class=\"data row0 col6\" >0.5028</td>\n      <td id=\"T_0b021_row0_col7\" class=\"data row0 col7\" >0.5047</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"          id    b1   b11   b12    b2    b3    b4    b5    b6    b7    b8  \\\n2614   15433   249  1697   736   221   387   251   632  1756  2753  2946   \n10003  12640   467  2124  1007   475   602   534  1116  2448  2915  2964   \n11478   4340   277  1162   511   280   378   203   508  1873  2416  2585   \n2924   10537   504  2350  1299   520   731   668  1150  1820  2176  2340   \n2495    3490  1263  1639   824  1256  1240  1004  1272  2090  2401  2625   \n...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n7447   12839   245  1613   694   252   424   268   674  2225  2764  2794   \n9551   12713   261  1551   695   216   341   237   631  2319  2919  2497   \n10562    399   257  1527   744   251   416   336   717  1734  2035  2342   \n10065  16541   105  1319   557   182   322   169   486  1687  2354  2569   \n8349    8597   332  2039  1051   416   592   500  1073  2377  2859  2562   \n\n       b8_a    b9 nforest_type prediction_label  prediction_score  \n2614   2802  2890          MDF              MDF            0.8714  \n10003  3297  3253          MDF              MDF            0.6615  \n11478  2682  3416          MDF              MDF            0.7584  \n2924   2486  2691          MDF              MDF            0.6111  \n2495   2583  2679          DEF              DEF            0.8622  \n...     ...   ...          ...              ...               ...  \n7447   3093  2860          MDF              DDF            0.5160  \n9551   3373  3098          DEF              DEF            0.8717  \n10562  2289  2382          DDF              DDF            0.7829  \n10065  2449  2458          DDF              MDF            0.3751  \n8349   3192  2633          DEF              MDF            0.6265  \n\n[3916 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>b1</th>\n      <th>b11</th>\n      <th>b12</th>\n      <th>b2</th>\n      <th>b3</th>\n      <th>b4</th>\n      <th>b5</th>\n      <th>b6</th>\n      <th>b7</th>\n      <th>b8</th>\n      <th>b8_a</th>\n      <th>b9</th>\n      <th>nforest_type</th>\n      <th>prediction_label</th>\n      <th>prediction_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2614</th>\n      <td>15433</td>\n      <td>249</td>\n      <td>1697</td>\n      <td>736</td>\n      <td>221</td>\n      <td>387</td>\n      <td>251</td>\n      <td>632</td>\n      <td>1756</td>\n      <td>2753</td>\n      <td>2946</td>\n      <td>2802</td>\n      <td>2890</td>\n      <td>MDF</td>\n      <td>MDF</td>\n      <td>0.8714</td>\n    </tr>\n    <tr>\n      <th>10003</th>\n      <td>12640</td>\n      <td>467</td>\n      <td>2124</td>\n      <td>1007</td>\n      <td>475</td>\n      <td>602</td>\n      <td>534</td>\n      <td>1116</td>\n      <td>2448</td>\n      <td>2915</td>\n      <td>2964</td>\n      <td>3297</td>\n      <td>3253</td>\n      <td>MDF</td>\n      <td>MDF</td>\n      <td>0.6615</td>\n    </tr>\n    <tr>\n      <th>11478</th>\n      <td>4340</td>\n      <td>277</td>\n      <td>1162</td>\n      <td>511</td>\n      <td>280</td>\n      <td>378</td>\n      <td>203</td>\n      <td>508</td>\n      <td>1873</td>\n      <td>2416</td>\n      <td>2585</td>\n      <td>2682</td>\n      <td>3416</td>\n      <td>MDF</td>\n      <td>MDF</td>\n      <td>0.7584</td>\n    </tr>\n    <tr>\n      <th>2924</th>\n      <td>10537</td>\n      <td>504</td>\n      <td>2350</td>\n      <td>1299</td>\n      <td>520</td>\n      <td>731</td>\n      <td>668</td>\n      <td>1150</td>\n      <td>1820</td>\n      <td>2176</td>\n      <td>2340</td>\n      <td>2486</td>\n      <td>2691</td>\n      <td>MDF</td>\n      <td>MDF</td>\n      <td>0.6111</td>\n    </tr>\n    <tr>\n      <th>2495</th>\n      <td>3490</td>\n      <td>1263</td>\n      <td>1639</td>\n      <td>824</td>\n      <td>1256</td>\n      <td>1240</td>\n      <td>1004</td>\n      <td>1272</td>\n      <td>2090</td>\n      <td>2401</td>\n      <td>2625</td>\n      <td>2583</td>\n      <td>2679</td>\n      <td>DEF</td>\n      <td>DEF</td>\n      <td>0.8622</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7447</th>\n      <td>12839</td>\n      <td>245</td>\n      <td>1613</td>\n      <td>694</td>\n      <td>252</td>\n      <td>424</td>\n      <td>268</td>\n      <td>674</td>\n      <td>2225</td>\n      <td>2764</td>\n      <td>2794</td>\n      <td>3093</td>\n      <td>2860</td>\n      <td>MDF</td>\n      <td>DDF</td>\n      <td>0.5160</td>\n    </tr>\n    <tr>\n      <th>9551</th>\n      <td>12713</td>\n      <td>261</td>\n      <td>1551</td>\n      <td>695</td>\n      <td>216</td>\n      <td>341</td>\n      <td>237</td>\n      <td>631</td>\n      <td>2319</td>\n      <td>2919</td>\n      <td>2497</td>\n      <td>3373</td>\n      <td>3098</td>\n      <td>DEF</td>\n      <td>DEF</td>\n      <td>0.8717</td>\n    </tr>\n    <tr>\n      <th>10562</th>\n      <td>399</td>\n      <td>257</td>\n      <td>1527</td>\n      <td>744</td>\n      <td>251</td>\n      <td>416</td>\n      <td>336</td>\n      <td>717</td>\n      <td>1734</td>\n      <td>2035</td>\n      <td>2342</td>\n      <td>2289</td>\n      <td>2382</td>\n      <td>DDF</td>\n      <td>DDF</td>\n      <td>0.7829</td>\n    </tr>\n    <tr>\n      <th>10065</th>\n      <td>16541</td>\n      <td>105</td>\n      <td>1319</td>\n      <td>557</td>\n      <td>182</td>\n      <td>322</td>\n      <td>169</td>\n      <td>486</td>\n      <td>1687</td>\n      <td>2354</td>\n      <td>2569</td>\n      <td>2449</td>\n      <td>2458</td>\n      <td>DDF</td>\n      <td>MDF</td>\n      <td>0.3751</td>\n    </tr>\n    <tr>\n      <th>8349</th>\n      <td>8597</td>\n      <td>332</td>\n      <td>2039</td>\n      <td>1051</td>\n      <td>416</td>\n      <td>592</td>\n      <td>500</td>\n      <td>1073</td>\n      <td>2377</td>\n      <td>2859</td>\n      <td>2562</td>\n      <td>3192</td>\n      <td>2633</td>\n      <td>DEF</td>\n      <td>MDF</td>\n      <td>0.6265</td>\n    </tr>\n  </tbody>\n</table>\n<p>3916 rows × 16 columns</p>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(predictions['nforest_type'], predictions['prediction_label'])","metadata":{"execution":{"iopub.status.busy":"2024-06-03T05:25:56.470104Z","iopub.execute_input":"2024-06-03T05:25:56.470523Z","iopub.status.idle":"2024-06-03T05:25:56.490504Z","shell.execute_reply.started":"2024-06-03T05:25:56.470489Z","shell.execute_reply":"2024-06-03T05:25:56.489414Z"},"trusted":true},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"0.6889683350357507"},"metadata":{}}],"execution_count":34},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"#main\ndef features_engineerin_main(df):\n    \n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    df.dropna(inplace=True)\n    \n    # Calculate indices\n    df['NDVI'] = (df['b8'] - df['b4']) / (df['b8'] + df['b4'])\n    df['EVI'] = 2.5 * (df['b8'] - df['b4']) / (df['b8'] + 6 * df['b4'] - 7.5 * df['b2'] + 1)\n    df['GNDVI'] = (df['b8'] - df['b3']) / (df['b8'] + df['b3'])\n    df['SAVI'] = (df['b8'] - df['b4']) * 1.5 / (df['b8'] + df['b4'] + 0.5)\n    df['RENDVI'] = (df['b8_a'] - df['b5']) / (df['b8_a'] + df['b5'])\n    df['MCARI'] = ((df['b5'] - df['b4']) - 0.2 * (df['b5'] - df['b3'])) * (df['b5'] / df['b4'])\n    df['NDLI'] = (np.log(df['b9']) - np.log(df['b12'])) / (np.log(df['b9']) + np.log(df['b12']))\n    df['PSRI'] = (df['b4'] - df['b3']) / df['b5']\n    df['NDII'] = (df['b8'] - df['b11']) / (df['b8'] + df['b11'])\n    df['NBR'] = (df['b8'] - df['b12']) / (df['b8'] + df['b12'])\n    df['BAI'] = 1.0 / ((0.1 - df['b8'])**2 + (0.06 - df['b12'])**2)\n    df['TCB'] = 0.3029 * df['b2'] + 0.2786 * df['b3'] + 0.4733 * df['b4'] + 0.5599 * df['b8'] + 0.508 * df['b11'] + 0.1872 * df['b12']\n    df['TCG'] = -0.2941 * df['b2'] - 0.243 * df['b3'] - 0.5424 * df['b4'] + 0.7276 * df['b8'] + 0.0713 * df['b11'] - 0.1608 * df['b12']\n    df['TCW'] = 0.1511 * df['b2'] + 0.1973 * df['b3'] + 0.3283 * df['b4'] + 0.3407 * df['b8'] - 0.7117 * df['b11'] - 0.4559 * df['b12']\n\n    # Calculate additional indices\n    df['NDWI'] = (df['b3'] - df['b8']) / (df['b3'] + df['b8'])\n    df['NDBI'] = (df['b11'] - df['b8']) / (df['b11'] + df['b8'])\n    df['MNDWI'] = (df['b3'] - df['b11']) / (df['b3'] + df['b11'])\n    df['BSI'] = ((df['b11'] + df['b4']) - (df['b8'] + df['b2'])) / ((df['b11'] + df['b4']) + (df['b8'] + df['b2']))\n    df['MSI'] = df['b11'] / df['b8']\n    df['ARI'] = (1 / df['b3']) - (1 / df['b5'])\n    df['CIrededge'] = (df['b7'] / df['b5']) - 1\n    df['NDRE'] = (df['b8_a'] - df['b5']) / (df['b8_a'] + df['b5'])\n    \n    df['NRVI'] = (df['b4'] / df['b8'] - 1) / (df['b4'] / df['b8'] + 1)\n    df['GCI'] = (df['b8'] / df['b3']) - 1\n    df['RECI'] = (df['b8'] - df['b5']) / df['b5']\n    df['SBI'] = np.sqrt(df['b4']**2 + df['b5']**2)\n    df['BU'] = (df['b11'] - df['b4']) / (df['b11'] + df['b4'])\n    df['NDVIre'] = (df['b8_a'] - df['b5']) / (df['b8_a'] + df['b5'])\n    df['MSAVI'] = (2 * df['b8'] + 1 - np.sqrt((2 * df['b8'] + 1)**2 - 8 * (df['b8'] - df['b4']))) / 2\n\n    gamma = 1\n    df['ARVIG'] = (df['b8'] - (df['b4'] - gamma * (df['b4'] - df['b2']))) / (df['b8'] + (df['b4'] - gamma * (df['b4'] - df['b2'])))\n    df['CCCI'] = df['NDRE'] / df['NDVI']\n    df['DSI'] = (df['b8'] - df['b12']) / (df['b8'] + df['b12'])\n    \n    df['NWI'] = (df['b3'] - df['b8']) / (df['b3'] + df['b8'])\n    df['MSI2'] = (df['b11'] - df['b4']) / (df['b11'] + df['b4'])\n    df['DVI'] = df['b8'] - df['b3']\n    df['SAVI2'] = (1 + 0.5) * (df['b8'] - df['b3']) / (df['b8'] + df['b3'] + 0.5)\n    df['TFVI'] = (df['b8'] - df['b3']) / (df['b8'] + df['b3'] + 0.5)\n    df['VARI'] = (df['b3'] - df['b2']) / (df['b3'] + df['b2'] - df['b1'])\n    df['NDSI'] = (df['b3'] - df['b11']) / (df['b3'] + df['b11'])\n    df['NLI'] = (df['b11'] - df['b4']) / (df['b11'] + df['b4'])\n    df['MCARI2'] = ((1.5 * (2.5 * (df['b5'] - df['b3']) - 1.3 * (df['b5'] - df['b4']) * (df['b5'] / df['b4']))) - (2 * (df['b5'] - df['b3']))) / (2 * (df['b5'] - df['b3']) + 1.5 * (2 * df['b5'] + 1) + 0.5)\n\n    df['GVMI'] = (df['b3'] - df['b11']) / (df['b3'] + df['b11'])\n    df['SAVI3'] = (1 + 0.6) * (df['b8'] - df['b3']) / (df['b8'] + df['b3'] + 0.6)\n    df['NDGI'] = (df['b3'] - df['b2']) / (df['b3'] + df['b2'])\n    df['HGI'] = (df['b4'] - df['b3']) / (df['b4'] + df['b3'])\n    df['FDI'] = (df['b5'] - df['b4']) / (df['b5'] + df['b4'])\n    df['CRI'] = (df['b4'] - df['b2']) / (df['b4'] + df['b2'])\n    df['PSRI2'] = (df['b4'] - df['b3']) / df['b6']\n    df['PRI'] = (df['b3'] - df['b2']) / (df['b3'] + df['b2'])\n    df['MSR'] = df['b8'] / df['b4']\n    df['GOSAVI'] = (1 + 0.16) * (df['b3'] - df['b2']) / (df['b3'] + df['b2'] + 0.16)\n    df['EVI2'] = 2.5 * (df['b8'] - df['b4']) / (df['b8'] + 2.4 * df['b4'] + 1)\n    \n    df['b3_b2_ratio'] = df['b3'] / df['b2']\n    df['b4_b2_ratio'] = df['b4'] / df['b2']\n    df['b8_b4_ratio'] = df['b8'] / df['b4']\n    df['b11_b2_ratio'] = df['b11'] / df['b2']\n    df['b12_b3_ratio'] = df['b12'] / df['b3']\n    df['b8_b4_diff'] = df['b8'] - df['b4']\n    df['b11_b8_diff'] = df['b11'] - df['b8']\n    \n    df['ARVI'] = (df['b8'] - df['b4'] - (df['b4'] - df['b2'])) / (df['b8'] + df['b4'] - (df['b4'] - df['b2']))\n    df['ARVI2'] = -0.18 + 1.17 * (df['b8'] - df['b4']) / (df['b8'] + df['b4'])\n    df['CASI_NDVI'] = ((df['b8'] + df['b8_a']) - (df['b4'] + df['b3'])) / ((df['b8'] + df['b8_a']) + (df['b4'] + df['b3']))\n    df['CWSI'] = (df['b3'] - df['b4']) / (df['b2'] - df['b4'])\n    df['GBNDVI'] = (df['b8'] - (df['b3'] + df['b2'])) / (df['b8'] + (df['b3'] + df['b2']))\n    df['GRNDVI'] = (df['b8'] - (df['b3'] + df['b4'])) / (df['b8'] + (df['b3'] + df['b4']))\n    df['mNDVI'] = (df['b8'] - df['b4']) / (df['b8'] + df['b4'] - df['b11'])\n    df['NDVI750_650'] = (df['b8'] - df['b4']) / (df['b8'] + df['b4'])\n    df['NDVI705'] = (df['b8'] - df['b6']) / (df['b8'] + df['b6'])\n    df['BNDVI'] = (df['b8'] - df['b2']) / (df['b8'] + df['b2'])\n    \n    nforest_type = None\n    \n    # Remove column\n    if 'nforest_type' in df.columns:\n        forest_type = df['nforest_type']\n        df = df.drop('nforest_type',axis=1) \n    else:\n        nforest_type = None\n        \n    # Remove 'id' column\n    if 'id' in df.columns:\n        df = df.drop('id',axis=1)\n        \n    #StandardScaler\n    #scaler = StandardScaler()\n    #df_scaler = scaler.fit_transform(df)\n    #df = pd.DataFrame(df_scaler, columns=df.columns)\n    \n    #Power Transformer\n    from sklearn.preprocessing import PowerTransformer\n    pt = PowerTransformer(method='yeo-johnson', standardize=True)\n    df = pt.fit(df)\n    df = pd.DataFrame(df)\n    \n    # Principal Component Analysis (PCA)\n    bands = df[['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b8_a', 'b9', 'b11', 'b12']]\n    pca = PCA(n_components=3)\n    pca_features = pca.fit_transform(bands)\n    df['PCA1'] = pca_features[:, 0]\n    df['PCA2'] = pca_features[:, 1]\n    df['PCA3'] = pca_features[:, 2]\n    \n    \n    if nforest_type is not None:\n        df['nforest_type'] = nforest_type.values\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-06-05T10:47:53.046041Z","iopub.execute_input":"2024-06-05T10:47:53.046575Z","iopub.status.idle":"2024-06-05T10:47:53.128955Z","shell.execute_reply.started":"2024-06-05T10:47:53.046532Z","shell.execute_reply":"2024-06-05T10:47:53.127415Z"},"trusted":true},"outputs":[],"execution_count":96},{"cell_type":"code","source":"#lion\ndef features_engineering_lion (df):\n    df['RVI'] = df['b8'] / df['b4']\n    df['PSSRa'] = df['b7'] / df['b4']\n    df['GOSSAN'] = df['b11'] / df['b4']\n\n    SWIRmin = 0.378\n    SWIRmax = 0.397\n    SWIIRmin = 0.027\n    df['NDVI'] = (df['b8'] - df['b4']) / (df['b8'] + df['b4'])\n    df['NDVI_2'] = (df['b8'] - df['b5']) / (df['b8'] + df['b5'])\n    df['NDVIc'] = (df['b8'] - df['b4']) / (df['b8'] + df['b4']) * (1.0 - (df['b12'] - SWIIRmin) / (SWIRmax - SWIRmin))\n\n    df['TNDVI'] = np.sqrt(df['NDVI'] + 0.5)\n    df['NDI45'] = (df['b5'] - df['b4']) / (df['b5'] + df['b4'])\n    df['GNDVI'] = (df['b8'] - df['b3']) / (df['b8'] + df['b3']) # Green Normalized Difference Vegetation Index: General formula: (NIR - [540:570]) / (NIR + [540:570])\n    df['MCARI'] = ((df['b5'] - df['b4']) - 0.2 * (df['b5'] - df['b3'])) * (df['b5'] / df['b4'])\n    df['LCI'] = (df['b8'] - df['b5']) / (df['b8'] + df['b4']) # Leaf Chlorophyll Index\n    df['GBNDVI'] = (df['b8'] - (df['b3'] + df['b2'])) / (df['b8'] + (df['b3']+ df['b2'])) # Green-Blue NDVI\n    df['GRNDVI'] = (df['b8'] - (df['b3'] + df['b4'])) / (df['b8'] + (df['b3'] + df['b4'])) # Green-Red NDVI\n    df['MVI'] = df['b9'] / df['b11'] # Mid-infrared vegetation index\n    df['MGVI'] = -0.386 * df['b3'] - 0.53 * df['b4'] + 0.535 * df['b6'] + 0.532 * df['b9'] # Misra Green Vegetation Index\n    df['MYVI'] = 0.723 * df['b3'] - 0.597 * df['b4'] + 0.206 * df['b6'] - 0.278 * df['b9'] # Misra Yellow Vegetation Index\n    df['mARI'] = (df['b3']**-1.0 - df['b5']**-1.0) * df['b8'] # Modified anthocyanin reflectance index\n    df['BRI'] = ((1.0 / df['b3']) - (1.0 / df['b5'])) / df['b8'] # Browning Reflectance Index\n    df['CCCI'] = ((df['b8'] - df['b5']) / (df['b8'] + df['b5'])) / ((df['b8'] - df['b4']) / (df['b8'] + df['b4'])) # Canopy Chlorophyll Content Index\n    df['CIgreen'] = df['b8'] / df['b3'] - 1.0 # Chlorophyll Index Green\n    df['CIrededge'] = df['b8'] / df['b5'] - 1.0 # Cholorphyll IndexRedEdge\n    df['CIred-edge'] = (df['b7'] / df['b5'])**-1.0 # Chlorophyll Red-Edge\n    df['CVI'] = df['b8'] * df['b4'] / (df['b3'])**2.0 # Chlorophyll Vegetation Index\n    df['CI'] = (df['b4'] - df['b2']) / df['b4'] # Coloration Index\n    df['CTVI'] = (((df['b4'] - df['b3']) / (df['b4'] + df['b3'])) + 0.5) / \\\n                     np.abs(((df['b4'] - df['b3']) / (df['b4'] + df['b3'])) + 0.5) * \\\n                     np.sqrt(np.abs((((df['b4'] - df['b3']) / (df['b4'] + df['b3']))) + 0.5)) # Corrected Transformed Vegetation Index\n\n    df['CARI'] = (df['b5'] / df['b4']) * np.sqrt(np.power(((df['b5'] - df['b3']) / 150.0 * 670.0 + df['b4'] + (df['b3'] - ((df['b5'] - df['b3']) / 150.0 * 550.0))), 2.0)) / \\\n                    np.power(((df['b5'] - df['b3']) / np.power(150.0, 2.0) + 1.0), 0.5) # Chlorophyll Absorption Ratio Index\n    \n    a = 0.496\n    df['CARI_2'] = (np.abs(((df['b5'] - df['b3']) / 150.0 * df['b4'] + df['b4'] + df['b3'] - (a * df['b3']))) / \\\n                    np.sqrt(np.power(a, 2.0) + 1.0)) * (df['b5'] / df['b4']) # Chlorophyll Absorption Ratio Index 2\n    df['Chlgreen'] = (df['b7'] / df['b3'])**-1.0\n\n    df['MCARI'] = ((df['b5'] - df['b4']) - 0.2 * (df['b5'] - df['b3'])) * (df['b5'] / df['b4']) # Modified Chlorophyll Absorption in Reflectance Index\n    df['MCARI_1'] = 1.2 * (2.5 * (df['b8'] - df['b4']) - 1.3 * (df['b8'] - df['b3'])) # Modified Chlorophyll Absorption in Reflectance Index 1\n    df['MCARI_2'] = 1.5 * (2.5 * (df['b8'] - df['b4']) - 1.3 * (df['b8'] - df['b3'])) / \\\n                     np.sqrt(np.power((2.0 * df['b8'] + 1.0), 2.0) - (6.0 * df['b8'] - 5.0 * np.sqrt(df['b4'])) - 0.5) # Modified Chlorophyll Absorption in Reflectance Index 2\n    df['mNDVI'] = (df['b8'] - df['b4']) / (df['b8'] + df['b4'] - 2.0 * df['b1']) # Modified Normalized Difference Vegetation Index\n\n    L = 0\n    df['SAVI'] = (1 + L) * (df['b8'] - df['b4']) / (df['b8'] + df['b4'] + L)\n    df['GSAVI'] = (df['b8'] - df['b3']) / (df['b8'] + df['b3'] + L) * (1.0 + L)\n    df['MSAVI'] = (2 * df['b8'] + 1 - np.sqrt((2 * df['b8'] + 1)**2 - 8 * (df['b8'] - df['b4']))) / 2\n    df['OSAVI'] = (1.0 + 0.16) * (df['b8'] - df['b4']) / (df['b8'] + df['b4'] + 0.16)\n\n    df['EVI'] = 2.5 * (df['b8'] - df['b4']) / (df['b8'] + 6 * df['b4'] - 7.5 * df['b2'] + 1) # General formula: 2.5 * (NIR - RED) / ((NIR + 6*RED - 7.5*BLUE) + 1)\n    df['EVI_2'] = 2.4 * (df['b8'] - df['b4']) / (df['b8'] + df['b4'] + 1) # General formula: 2.4 * (NIR - RED) / (NIR + RED + 1)\n    df['EVI_2_2'] = 2.5 * (df['b8'] - df['b4']) / (df['b8'] + 2.4 * df['b4'] + 1) #General formula: 2.5 * (NIR - RED) / (NIR + 2.4 * RED + 1)\n    df['EVI_8A'] = 2.5 * (df['b8_a'] - df['b4']) / (df['b8_a'] + 6 * df['b4'] - 7.5 * df['b2'] + 1) # General formula: 2.5 * (NIR - RED) / ((NIR + 6*RED - 7.5*BLUE) + 1)\n    df['EVI_8A_2'] = 2.4 * (df['b8_a'] - df['b4']) / (df['b8_a'] + df['b4'] + 1) # General formula: 2.4 * (NIR - RED) / (NIR + RED + 1)\n    df['EVI_8A_2_2'] = 2.5 * (df['b8_a'] - df['b4']) / (df['b8_a'] + 2.4 * df['b4'] + 1) #General formula: 2.5 * (NIR - RED) / (NIR + 2.4 * RED + 1)\n    df['GLI'] = (2.0 * df['b3'] - df['b4'] - df['b2']) / (2.0 * df['b3'] + df['b4'] + df['b2']) # Green Leaf Index: General formula: (2 * GREEN - RED - BLUE)/(2 * GREEN + RED + BLUE)\n    df['GARI'] = (df['b8'] - (df['b3'] - (df['b2'] - df['b4']))) / (df['b8'] - (df['b3'] + (df['b2'] - df['b4']))) # Green atmospherically resistant vegetation index: General formula: ( NIR - (GREEN-(BLUE- RED))) /  ( NIR- (GREEN+(BLUE - RED)))\n\n    ar = 0.374\n    b = 0.735\n    df['PVI'] = (1.0 / np.sqrt(np.power(0.149, 2.0) + 1.0)) * (df['b8'] - ar - b)\n    df['GCI'] = df['b8'] / df['b3'] - 1\n    df['PRI'] = (df['b3'] - df['b5']) / (df['b3'] + df['b5'])\n    df['MSI'] = df['b11'] / df['b8']\n    df['NBR'] = (df['b8'] - df['b12']) / (df['b8'] + df['b12'])\n    df['ARI'] = (1 / df['b3']) - (1 / df['b5'])\n    df['RDVI'] =  (df['b8'] - df['b4']) / np.power((df['b8'] + df['b4']), 0.5)\n    df['NLI'] = (np.power(df['b8'], 2.0) - df['b4']) / (np.power(df['b8'], 2.0) + df['b4']) # Nonlinear Vegetation Index\n    \n    df['DVI'] = df['b8'] - df['b4']\n    df['S2REP'] = 705 + 35 * ((df['b4'] + df['b7']) / 2 - df['b5']) / (df['b6'] - df['b5'])\n    df['IRECI'] = (df['b7'] - df['b4']) / (df['b5'] / df['b6'])\n    df['MOIS'] = ((df['b8_a'] - df['b11']) / (df['b8_a'] + df['b11'])) # Moisture Index ideal for finding water stress in plants. It uses the short-wave and near-infrared to generate an index of moisture content. In general, wetter vegetation has higher values. But lower moisture index values suggest plants are under stress from insufficient moisture.\n    df['NIR_RATIO_1'] = df['b8'] / df['b4']\n    df['NIR_RATIO_2'] =df['b7'] / df['b4']\n    df['NDSI'] = (df['b11'] - df['b12']) / (df['b11'] + df['b12']) # Normalized Difference Salinity Index  (abbrv. NDSI)\n    \n    # Global Environment Monitoring Index\n    df['GEMI'] = ((2.0 * (np.power(df['b8'], 2.0) - np.power(df['b4'], 2.0)) + 1.5 * df['b8'] + 0.5 * df['b4']) / (df['b8'] + df['b4'] + 0.5) * (1.0 - 0.25 * ((2.0 * (np.power(df['b8'], 2.0) - np.power(df['b4'], 2.0)) + 1.5 * df['b8'] + 0.5 * df['b4']) / (df['b8'] + df['b4'] + 0.5))) - ((df['b4'] - 0.125) / (1.0 - df['b4'])))\n    df['GEMI_8A'] = ((2.0 * (np.power(df['b8_a'], 2.0) - np.power(df['b4'], 2.0)) + 1.5 * df['b8_a'] + 0.5 * df['b4']) / (df['b8_a'] + df['b4'] + 0.5) * (1.0 - 0.25 * ((2.0 * (np.power(df['b8_a'], 2.0) - np.power(df['b4'], 2.0)) + 1.5 * df['b8_a'] + 0.5 * df['b4']) / (df['b8_a'] + df['b4'] + 0.5))) - ((df['b4'] - 0.125) / (1.0 - df['b4']))) # Self Engineered\n    df['GVMI'] = ((df['b8'] + 0.1) - (df['b12'] + 0.02)) / ((df['b8'] + 0.1) + (df['b12'] + 0.02)) # Global Vegetation Moisture Index\n    df['GVMI_8A'] = ((df['b8_a'] + 0.1) - (df['b12'] + 0.02)) / ((df['b8_a'] + 0.1) + (df['b12'] + 0.02))\n\n    df['b11/b12'] = df['b11'] / df['b12']\n    df['b12/b11'] = df['b12'] / df['b11']\n    df['b11-b12'] = df['b11'] - df['b12']\n    df['b12-b11'] = df['b12'] - df['b11']\n    df['b4-b5'] = df['b4'] - df['b5']\n    df['b11-b5'] = df['b11'] - df['b5']\n    df['b11/b8'] = df['b11'] / df['b8']\n                                           \n     \n    nforest_type = None\n    \n    # Remove column\n    if 'nforest_type' in df.columns:\n        forest_type = df['nforest_type']\n        df = df.drop('nforest_type',axis=1) \n    else:\n        nforest_type = None\n        \n    # Principal Component Analysis (PCA)\n    #bands = df[['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b8_a', 'b9', 'b11', 'b12']]\n    pca = PCA(n_components=3)\n    pca_features = pca.fit_transform(df)\n    df['PCA1'] = pca_features[:, 0]\n    df['PCA2'] = pca_features[:, 1]\n    df['PCA3'] = pca_features[:, 2]\n     \n    if nforest_type is not None:\n        df['nforest_type'] = nforest_type.values   \n        \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-06-06T04:50:05.579749Z","iopub.execute_input":"2024-06-06T04:50:05.580162Z","iopub.status.idle":"2024-06-06T04:50:05.649122Z","shell.execute_reply.started":"2024-06-06T04:50:05.580133Z","shell.execute_reply":"2024-06-06T04:50:05.646783Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#tong\ndef features_engineering_tong (df):\n    # Vegetation Indices\n    df['NDVI'] = (df['b8'] - df['b4']) / (df['b8'] + df['b4'])\n    df['EVI'] = 2.5 * (df['b8'] - df['b4']) / (df['b8'] + 6 * df['b4'] - 7.5 * df['b2'] + 1)\n    df['SAVI'] = (1 + 0.5) * (df['b8'] - df['b4']) / (df['b8'] + df['b4'] + 0.5)\n    df['MSAVI'] = (2 * df['b8'] + 1 - ((2 * df['b8'] + 1)**2 - 8 * (df['b8'] - df['b4']))**0.5) / 2\n    df['GNDVI'] = (df['b8'] - df['b3']) / (df['b8'] + df['b3'])\n    df['NDYI'] = (df['b4'] - df['b1']) / (df['b4'] + df['b1'])\n    df['ARVI'] = (df['b8'] - 2 * df['b4'] + df['b2']) / (df['b8'] + 2 * df['b4'] + df['b2'])\n    df['RDVI'] = (df['b8'] - df['b4']) / ((df['b8'] + df['b4'])**0.5)\n    df['TVI'] = 0.5 * (120 * (df['b4'] - df['b3']) - 200 * (df['b2'] - df['b3']))\n    df['TCI'] = 0.5 * (120 * (df['b8'] - df['b3']) - 200 * (df['b2'] - df['b3']))\n    df['ARI'] = (1 / df['b3'] - 1 / df['b5'])\n    df['CCCI'] = ((df['b8'] - df['b4']) / (df['b8'] + df['b4'])) / ((df['b5'] - df['b4']) / (df['b5'] + df['b4']))\n\n    # Water Indices\n    df['WDRVI'] = (0.1 * df['b8'] - df['b4']) / (0.1 * df['b8'] + df['b4'])\n\n    # Soil Indices\n    df['NDSI'] = (df['b3'] - df['b11']) / (df['b3'] + df['b11'])\n\n    # Other Indices\n    df['NBR'] = (df['b8'] - df['b12']) / (df['b8'] + df['b12'])\n    df['NDMI'] = (df['b8'] - df['b11']) / (df['b8'] + df['b11'])\n    df['NGRDI'] = (df['b3'] - df['b5']) / (df['b3'] + df['b5'])\n    df['Alteration'] = (df['b11'] / df['b12']) - (df['b4'] / df['b2'])\n    \n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-06-06T06:44:24.438619Z","iopub.execute_input":"2024-06-06T06:44:24.439043Z","iopub.status.idle":"2024-06-06T06:44:24.452885Z","shell.execute_reply.started":"2024-06-06T06:44:24.439014Z","shell.execute_reply":"2024-06-06T06:44:24.451622Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#tadashi\ndef features_engineering_tadashi(df):\n    # Basic indices\n    df['NDVI'] = (df['b8'] - df['b4']) / (df['b8'] + df['b4'])\n    df['ATSAVI'] = 1.22 * ((df['b8'] - 1.22 * df['b4'] - 0.03) / (1.22 * df['b8'] + df['b4'] - 1.22 * 0.03 + 0.08 * (1 + (1.22**2))))\n    df['Aerosol free vegetation index 1600'] = (df['b8']-0.66*(df['b11']/(df['b8']+0.66*df['b11'])))\n    df['Aerosol free vegetation index 2100'] = (df['b8']-0.5*(df['b12']/(df['b8']+0.56*df['b12'])))\n    df['Alteration'] = df['b11']/df['b12']\n    df['Anthocyanin reflectance index'] = (1/df['b3'])-(1/df['b5'])\n    df['Atmospherically Resistant Vegetation Index 2'] = -0.18+1.17*((df['b8']-df['b4'])/(df['b8']+df['b4']))\n    df['Blue-wide dynamic range vegetation index'] = (0.1*df['b8']-df['b2'])/(0.1*df['b8']+df['b2'])\n    df['Browning Reflectance Index'] = df['Anthocyanin reflectance index']/df['b8']\n    df['Chlorophyll Absorption Ratio Index'] = (df['b5']/df['b4'])*np.sqrt(670/150*(df['b5']-df['b3'])+df['b4']+(df['b3']-(550/150*(df['b5']-df['b3'])))**2)/np.sqrt((1+(df['b5']-df['b3'])/(150*150)))\n    df['Chlorophyll Green'] = df['b3']/df['b7']\n    df['Chlorophyll Index Green'] = (df['b8']/df['b3'])-1\n    df['Chlorophyll IndexRedEdge'] = (df['b8']/df['b5'])-1\n    df['Chlorophyll Red-Edge'] = df['b5']/df['b7']\n    df['Chlorophyll vegetation index'] = df['b8']*df['b5']/(df['b3']**2)\n    df['Coloration Index'] = (df['b4']-df['b2'])/df['b4']\n    df['CRI550'] = (1/df['b2'])-(1/df['b3'])\n    df['CRI700'] = (1/df['b2'])-(1/df['b5'])\n    df['Datt1'] = (df['b8'] - df['b5']) / (df['b8'] - df['b4'])\n    df['Datt4'] = (df['b4'])/(df['b3']*df['b5'])\n    df['Datt6'] = (df['b8_a'])/(df['b3']*df['b5'])\n    df['Difference 678/500'] = df['b4']-df['b2']\n    df['Difference 800/550'] = df['b8']-df['b3']\n    df['Difference 800/680'] = df['b8']-df['b4']\n    df['EVI'] = 2.5 * (df['b8'] - df['b4']) / (df['b8'] + 6 * df['b4'] - 7.5 * df['b2'] + 1)\n    df['EVI2'] = 2.5 * (df['b8'] - df['b4']) / (df['b8'] + 2.4 * df['b4'] + 1)\n    df['Ferrous Silicates'] = df['b12']-df['b11']\n    df['Global Environment Monitoring Index'] = ((((2*(df['b8']-df['b4'])*(df['b8']+df['b4']))+(1.5*df['b8'])+(0.5*df['b4']))/(df['b8']+df['b4']+0.5))*(1-(0.25*(((2*(df['b8']-df['b4'])*(df['b8']+df['b4']))+(1.5*df['b8'])+(0.5*df['b4']))/(df['b8']+df['b4']+0.5)))))-((df['b4']-0.125)/(1-df['b5']))\n    df['Gossan'] = df['b11']/df['b4']\n    df['Green atmospherically resistant vegetation index'] = (df['b8']-(df['b3']+df['b4']))/(df['b8']+(df['b3']+df['b4']))\n    df['Green leaf index'] = (2*df['b3']-df['b4']-df['b2'])/(2*df['b3']+df['b4']+df['b2'])\n    df['Green Normalized Difference Vegetation Index'] = (df['b8'] - df['b3']) / (df['b8'] + df['b3'])\n    df['Green Soil Adjusted Vegetation Index'] = (df['b8']-df['b3'])*(1+5)/(df['b8']+df['b3']+5)\n    df['Green-Blue NDVI'] = (df['b8']-(df['b3']+df['b2']))/(df['b8']+(df['b3']+df['b2']))\n    df['Green-Red NDVI'] = (df['b8']-(df['b3']+df['b4']))/(df['b8']+(df['b3']+df['b4']))\n    df['Hue'] = np.arctan((2*df['b4']-df['b3']-df['b2'])*(df['b3']-df['b2'])/30.5)\n    df['Infrared percentage vegetation index'] = ((df['b8']/(df['b8']+df['b4']))/2)*(df['NDVI']+1)\n    df['Intensity'] = 1/30.5*(df['b2']+df['b3']+df['b4'])\n    df['Inverse reflectance 550'] = 1/df['b3']\n    df['Inverse reflectance 700'] = 1/df['b5']\n    df['Leaf Chlorophyll Index'] = (df['b8'] - df['b5']) / (df['b8'] + df['b4'])\n    df['Log Ratio'] = np.log(df['b8']/df['b4'])\n    df['Maccioni'] = (df['b7'] - df['b5']) / (df['b7'] - df['b4'])\n    df['MCARI/MTVI2'] = (df['b5']/df['b4'])*((df['b5']-df['b4'])-0.2*(df['b5']-df['b4']))/(1.5*(1.2*(df['b8']-df['b3'])-2.5*(df['b4']-df['b3']))/np.sqrt((2*df['b8']+1)**2-((df['b6']*df['b8'])-(5*np.sqrt(df['b4'])))-0.5))\n    df['MCARI/OSAVI'] = (df['b5']/df['b4'])*((df['b5']-df['b4'])-0.2*(df['b5']-df['b4']))/((1+0.16)*(df['b8']-df['b4'])/(df['b8']+df['b4']+0.16))\n    df['mCRIG'] = ((1/df['b2'])-(1/df['b3']))*df['b8']\n    df['mCRIRE'] = ((1/df['b2'])-(1/df['b5']))*df['b8']\n    df['mND680'] = (df['b8']-df['b4'])/(df['b8']+df['b4']-2*df['b1'])\n    df['Modified anthocyanin reflectance index'] = ((1/df['b3'])-(1/df['b5']))*df['b8']\n    df['Modified Chlorophyll Absorption in Reflectance Index'] = ((df['b5']-df['b4'])-0.2*(df['b5']-df['b3']))*(df['b5']/df['b4'])\n    df['Modified Chlorophyll Absorption in Reflectance Index1'] = (2.5*(df['b8']-df['b4'])-1.3*(df['b8']-df['b3']))*(1.2)\n    df['Modified Chlorophyll Absorption in Reflectance Index2'] = 1.5*df['Modified Chlorophyll Absorption in Reflectance Index1']/np.sqrt((2*df['b8']+1)**2-((df['b6']*df['b8'])-(5*np.sqrt(df['b4'])))-0.5)\n    df['Modified Simple Ratio 670,800'] = ((df['b8']/df['b4'])-1)/np.sqrt(((df['b8']/df['b4'])+1))\n    # df['Modified Simple Ratio NIR/RED'] = ((df['b9']/df['b5'])-1)/np.sqrt(((df['b9']/df['b5'])+1))\n    df['Modified Soil Adjusted Vegetation Index'] = (2*df['b8']+1-np.sqrt((2*df['b8']+1)**2+8*(df['b8']-df['b4'])))/2\n    df['Modified Triangular Vegetation Index 1'] = 1.2 * (1.2 * (df['b8'] - df['b3']) - 2.5 * (df['b4'] - df['b3']))\n    df['Modified Triangular Vegetation Index 2'] = 1.5*df['Modified Triangular Vegetation Index 1']/np.sqrt((2*df['b8']+1)**2-((df['b6']*df['b8'])-(5*np.sqrt(df['b4'])))-0.5)\n    df['Norm G'] = df['b3']/(df['b8']+df['b4']+df['b3'])\n    df['Norm NIR'] = df['b8']/(df['b8']+df['b4']+df['b3'])\n    df['Norm R'] = df['b4']/(df['b8']+df['b4']+df['b3'])\n    df['Normalized Difference 550/450'] = (df['b3'] - df['b1']) / (df['b3'] + df['b1'])\n    df['Normalized Difference 550/650'] = (df['b3'] - df['b4']) / (df['b3'] + df['b4'])\n    df['Normalized Difference 774/677'] = (df['b7'] - df['b4']) / (df['b7'] + df['b4'])\n    df['Normalized Difference 780/550'] = (df['b7'] - df['b3']) / (df['b7'] + df['b3'])\n    df['Normalized Difference 800/2170'] = (df['b8'] - df['b12']) / (df['b8'] + df['b12'])\n    df['Normalized Difference 800/470'] = (df['b8'] - df['b2']) / (df['b8'] + df['b2'])\n    df['Normalized Difference 860/1640'] = (df['b8_a'] - df['b11']) / (df['b8_a'] + df['b11'])\n    df['Normalized Difference NIR/Rededge'] = (df['b9'] - df['b5']) / (df['b9'] + df['b5'])\n    df['Normalized Difference Red/Green'] = (df['b3'] - df['b5']) / (df['b3'] + df['b5'])\n    df['Normalized Difference Salinity Index'] = (df['b11'] - df['b12']) / (df['b11'] + df['b12'])\n    df['Optimized Soil Adjusted Vegetation Index'] = (1+0.16)*(df['b8']-df['b4'])/(df['b8']+df['b4']+0.16)\n    df['Pan NDVI'] = (df['b8']-(df['b4']+df['b3']+df['b2']))/(df['b8']+(df['b4']+df['b3']+df['b2']))\n    df['RDVI'] = (df['b8'] - df['b4']) / np.sqrt(df['b8'] + df['b4'])\n    df['Red edge 1'] = df['b5']-df['b4']\n    df['Red-Blue NDVI'] = (df['b8']-(df['b4']+df['b2']))/(df['b8']+(df['b4']+df['b2']))\n    df['Red-Edge Inflection Point 1'] = 700+40*((((df['b4']+df['b7'])/2)-5)/(df['b6']-df['b5']))\n    df['Red-Edge Inflection Point 2'] = 702+40*((((df['b4']+df['b7'])/2)-5)/(df['b6']-df['b5']))\n    df['Red-Edge Inflection Point 3'] = 705+35*((((df['b4']+df['b7'])/2)-5)/(df['b6']-df['b5']))\n    df['Reflectance at the inflexion point'] =  (df['b4']+df['b7'])/2\n    df['Simple Ratio 1600/820'] = df['b11']/df['b8']\n    df['Simple Ratio 440/740'] = df['b1']/df['b6']\n    df['Simple Ratio 450/550'] = df['b1']/df['b3']\n    df['Simple Ratio 520/670'] = df['b2']/df['b4']\n    df['Simple Ratio 550/800'] = df['b3']/df['b8']\n    df['Simple Ratio 560/658'] = df['b3']/df['b4']\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:46:36.388666Z","iopub.execute_input":"2024-06-06T09:46:36.389195Z","iopub.status.idle":"2024-06-06T09:46:36.452718Z","shell.execute_reply.started":"2024-06-06T09:46:36.389134Z","shell.execute_reply":"2024-06-06T09:46:36.451193Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def calculate_vegetation_indices(df):\n    \"\"\"Calculates a comprehensive set of vegetation indices from Sentinel-2 data.\n\n    Args:\n        df (pd.DataFrame): DataFrame containing Sentinel-2 band data. \n                          Must include columns named 'b1', 'b2', 'b3', 'b4', 'b5', 'b7', 'b8', 'b8_a', b9', 'b11', 'b12'.\n\n    Returns:\n        pd.DataFrame: DataFrame containing the calculated vegetation indices.\n    \"\"\"\n    df[\"ndvi\"] = (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"])\n\n    indices = {\n        # Vegetation Indices\n        \"ndvi\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]),                                                              # Normalized Difference Vegetation Index\n        \"evi\": 2.5 * ((df['b8'] - df['b4']) / (df['b8'] + 6 * df['b4'] - 7.5 * df['b2'] + 1.01)),                           # Enhanced Vegetation Index\n        \"savi\": ((df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"] + 0.5)) * (1 + 0.5),                                          # Soil Adjusted Vegetation Index\n        \"msavi\": ((2 * df[\"b8\"] + 1 - np.sqrt((2 * df[\"b8\"] + 1) ** 2 - 8 * (df[\"b8\"] - df[\"b4\"]))) / 2),                   # Modified Soil Adjusted Vegetation Index\n        \"gndvi\": (df[\"b8\"] - df[\"b3\"]) / (df[\"b8\"] + df[\"b3\"]),                                                             # Normalized Difference NIR/Green Green NDVI\n        \"arvi\": (df[\"b8_a\"] - (df[\"b4\"] - 1 * (df[\"b4\"] - df[\"b2\"]))) / (df[\"b8_a\"] + (df[\"b4\"] - 1 * (df[\"b2\"] - df[\"b4\"]))),  # \n        \"rdvi\": (df[\"b8\"] - df[\"b4\"]) / np.sqrt(df[\"b8\"] + df[\"b4\"]),                                                       # Renormalized Difference Vegetation Index\n        \"tvi\": (0.5 * (df[\"b8\"] - df[\"b4\"])) / (df[\"b8\"] + df[\"b4\"] + df[\"b2\"]),                                            # Transformed Vegetation Index\n        \"tci\": 1.2 * (df[\"b5\"] - df[\"b3\"]) - 1.5 * (df[\"b4\"] - df[\"b6\"]) * np.sqrt(df[\"b5\"] / df[\"b4\"]),                    # Triangular chlorophyll index\n        \"ari\": 1 / df[\"b3\"] - 1 / df[\"b5\"],\n        \"ccci\": ((df[\"b8\"] - df[\"b5\"]) / (df[\"b8\"] + df[\"b5\"])) / ((df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"])),\n        \"pvi\": (df[\"b8\"] - df[\"b4\"] - (df[\"b4\"] - df[\"b2\"])) / (df[\"b8\"] + df[\"b4\"] + (df[\"b4\"] - df[\"b2\"])),\n        \"atsavi\": (df[\"b8_a\"] - (df[\"b4\"] - 0.1 * (df[\"b4\"] - df[\"b2\"]))) / (df[\"b8_a\"] + (df[\"b4\"] - 0.1 * (df[\"b2\"] - df[\"b4\"]))), # ATSAVI\n        \"wdvi\": (df[\"b8\"] - 0.1 * df[\"b4\"]) / (df[\"b8\"] + 0.1 * df[\"b4\"]),\n        \"wdrvi\": (0.1 * df[\"b8\"] - df[\"b2\"]) / (0.1 * df[\"b8\"] + df[\"b2\"]),\n        \"ndwi\": (df[\"b3\"] - df[\"b8\"]) / (df[\"b3\"] + df[\"b8\"]),                                                              # Normalized Difference Water Index\n        # Soil Indices\n        \"ndsi\": (df[\"b11\"] - df[\"b12\"]) / (df[\"b11\"] + df[\"b12\"]),\n\n        # Other Indices\n        \"nbr\": (df[\"b8\"] - df[\"b12\"]) / (df[\"b8\"] + df[\"b12\"]),\n        \"ndmi\": (df[\"b8\"] - df[\"b11\"]) / (df[\"b8\"] + df[\"b11\"]),\n        \"ngrdri\": (df[\"b3\"] - df[\"b4\"]) / (df[\"b3\"] + df[\"b4\"]),\n        \"alteration\": (df[\"b11\"] / df[\"b12\"]),\n        \"afri1600\": (df[\"b8\"] - 0.66) / (df[\"b8\"] + 0.66),\n        \"afri2100\": (df[\"b8\"] - 0.5) / (df[\"b8\"] + 0.56),\n        \"avi\": (2 * df[\"b8\"] - df[\"b4\"]) / (2 * df[\"b8\"] + df[\"b4\"]),\n        \"arvi2\": -0.18 + 1.17 * ((df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"])),\n        \"bwdrvi\": (0.1 * df[\"b8\"] - df[\"b2\"]) / (0.1 * df[\"b8\"] + df[\"b2\"]),\n        \"bri\": (df[\"b3\"] - df[\"b5\"]) / (df[\"b3\"] + df[\"b5\"]),\n        \"cari\": ((df[\"b5\"] - df[\"b4\"]) / (df[\"b5\"] + df[\"b4\"])) * (df[\"b5\"] / (0.1 * df[\"b4\"] + df[\"b4\"])),\n        \"cari2\": ((df[\"b5\"] - df[\"b4\"]) / (df[\"b5\"] + df[\"b4\"])) * (df[\"b5\"] / (0.1 * df[\"b4\"] + df[\"b4\"])),\n        \"chlgreen\": (df[\"b7\"] - df[\"b3\"]) / (df[\"b7\"] + df[\"b3\"]),\n        \"cigreen\": (df[\"b8\"] - df[\"b3\"]) / (df[\"b8\"] + df[\"b3\"]),\n        \"cirededge\": (df[\"b8\"] - df[\"b5\"]) / (df[\"b8\"] + df[\"b5\"]),\n        \"chlred-edge\": (df[\"b7\"] - df[\"b5\"]) / (df[\"b7\"] + df[\"b5\"]),\n        \"cvi\": (df[\"b8\"] / df[\"b4\"]) / (df[\"b3\"] ** 2),\n        \"ci\": (df[\"b4\"] - df[\"b2\"]) / df[\"b4\"],\n        \"ctvi\": (df[\"ndvi\"] + 0.5) / (df[\"ndvi\"] + 0.5) * (df[\"ndvi\"] + 0.5),\n        \"cri550\": (df[\"b3\"] - df[\"b4\"]) / (df[\"b3\"] + df[\"b4\"]),\n        \"cri700\": (df[\"b3\"] - df[\"b5\"]) / (df[\"b3\"] + df[\"b5\"]),\n        \"datt1\": (df[\"b8\"] - df[\"b5\"]) / (df[\"b8\"] - df[\"b4\"]),\n        \"datt4\": df[\"b4\"] * df[\"b3\"] * df[\"b5\"],\n        \"datt6\": df[\"b8\"] * df[\"b3\"] * df[\"b5\"],\n        \"d678/500\": (df[\"b4\"] - df[\"b1\"]) / (df[\"b4\"] + df[\"b1\"]),\n        \"d800/550\": (df[\"b8\"] - df[\"b3\"]) / (df[\"b8\"] + df[\"b3\"]),\n        \"d800/680\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]),\n        \"d833/658\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]),\n        \"gdvi\": (df[\"b8\"] - df[\"b3\"]) / (df[\"b8\"] + df[\"b3\"]),\n        \"dvimss\": (2.4 * df[\"b8\"] - df[\"b4\"]) / (2.4 * df[\"b8\"] + df[\"b4\"]),\n        \"evi2\": 2.4 * ((df['b8'] - df['b4']) / (df['b8'] + df['b4'] + 1)),\n        \"epi\": (0.1 * df[\"b4\"] * df[\"b3\"] * df[\"b5\"]),\n        \"fe2+\": (df[\"b11\"] / df[\"b12\"] + (df[\"b3\"] - df[\"b5\"]) / (df[\"b3\"] + df[\"b5\"])),\n        \"fe3+\": (df[\"b5\"] - df[\"b3\"]) / (df[\"b5\"] + df[\"b3\"]),\n        \"gemi\": ((1 - 0.25 * df[\"b8\"]) - (df[\"b4\"] - 0.125)) / ((1 - df[\"b4\"])),\n        \"gvmi\": ((df[\"b8\"] + 0.1) - (df[\"b12\"] + 0.02)) / ((df[\"b8\"] + 0.1) + (df[\"b12\"] + 0.02)),\n        \"gari\": ((df[\"b8\"] - (df[\"b3\"] - (df[\"b2\"] - df[\"b4\"]))) / (df[\"b8\"] + (df[\"b3\"] - (df[\"b2\"] - df[\"b4\"])))),\n        \"gli\": (2 * df[\"b3\"] - df[\"b4\"] - df[\"b2\"]) / (2 * df[\"b3\"] + df[\"b4\"] + df[\"b2\"]),\n        \"gosavi\": (df[\"b8\"] - df[\"b3\"]) / (df[\"b8\"] + df[\"b3\"] + 1),\n        \"gsavi\": (df[\"b8\"] - df[\"b3\"]) / (df[\"b8\"] + df[\"b3\"] + 0.5) * (1 + 0.5),\n        \"gbndvi\": (df[\"b8\"] - (df[\"b3\"] + df[\"b2\"])) / (df[\"b8\"] + (df[\"b3\"] + df[\"b2\"])),\n        \"grndvi\": (df[\"b8\"] - (df[\"b3\"] + df[\"b4\"])) / (df[\"b8\"] + (df[\"b3\"] + df[\"b4\"])),\n        \"h\": np.arctan((2 * df[\"b4\"] - df[\"b3\"] - df[\"b2\"]) / (30.5 * (df[\"b3\"] - df[\"b2\"]))),\n        \"ivi\": (df[\"b8\"] - 0.1 * df[\"b4\"]) / (df[\"b8\"] + 0.1 * df[\"b4\"]),\n        \"ipvi\": (df[\"b8\"] / (df[\"b8\"] + df[\"b4\"])) * 2 * (df[\"ndvi\"] + 1),\n        \"i\": (1 / 30.5) * (df[\"b4\"] + df[\"b3\"] + df[\"b2\"]),\n        \"ir550\": (df[\"b3\"] - 1) / (df[\"b3\"] + 1),\n        \"ir700\": (df[\"b5\"] - 1) / (df[\"b5\"] + 1),\n        \"lci\": (df[\"b8\"] - df[\"b5\"]) / (df[\"b8\"] + df[\"b4\"]),\n        \"lwci\": np.log(1 - (df[\"b8\"] - df[\"b12\"])) - np.log(1 - (df[\"b8\"] - df[\"b12\"])),\n        \"logr\": np.log(df[\"b8\"] / df[\"b4\"]),\n        \"mcari/mtvi2\": ((df[\"b5\"] - df[\"b4\"]) - 0.2 * (df[\"b5\"] - df[\"b3\"])) / (df[\"b5\"] + df[\"b4\"]) * ((1.5 * (df[\"b8\"] - df[\"b3\"]) - 2.5 * (df[\"b4\"] - df[\"b3\"])) / (2 * df[\"b8\"] + 1) - (6 * df[\"b8\"] - 5 * df[\"b4\"] - 0.5)),\n        \"mcari/osavi\": ((df[\"b5\"] - df[\"b4\"]) - 0.2 * (df[\"b5\"] - df[\"b3\"])) / (df[\"b5\"] + df[\"b4\"]) * ((df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"] + 0.16)),\n        \"mcrig\": (df[\"b3\"] - df[\"b4\"]) / (df[\"b3\"] + df[\"b4\"]) * df[\"b8\"],\n        \"mcrire\": (df[\"b3\"] - df[\"b5\"]) / (df[\"b3\"] + df[\"b5\"]) * df[\"b8\"],\n        \"mgvi\": -0.386 * df[\"b3\"] - 0.530 * df[\"b4\"] + 0.535 * df[\"b5\"] + 0.532 * df[\"b8\"],\n        \"mnsi\": 0.404 * df[\"b3\"] - 0.039 * df[\"b4\"] - 0.505 * df[\"b5\"] + 0.762 * df[\"b8\"],\n        \"msbi\": 0.406 * df[\"b3\"] + 0.600 * df[\"b4\"] + 0.645 * df[\"b5\"] + 0.243 * df[\"b8\"],\n        \"myvi\": 0.723 * df[\"b3\"] - 0.597 * df[\"b4\"] + 0.206 * df[\"b5\"] - 0.278 * df[\"b8\"],\n        \"mnd680\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"] - 2 * df[\"b1\"]),\n        \"mari\": (df[\"b3\"] - df[\"b5\"]) / (df[\"b3\"] + df[\"b5\"]) * df[\"b8\"],\n        \"mcari\": ((df[\"b5\"] - df[\"b4\"]) - 0.2 * (df[\"b5\"] - df[\"b3\"])) / (df[\"b5\"] + df[\"b4\"]),\n        \"mcari1\": 1.2 * (2.5 * (df[\"b8\"] - df[\"b4\"]) - 1.3 * (df[\"b8\"] - df[\"b3\"])),\n        \"mcari2\": ((1.5 * (df[\"b8\"] - df[\"b4\"]) - 1.3 * (df[\"b8\"] - df[\"b3\"])) / (2 * df[\"b8\"] + 1) - (6 * df[\"b8\"] - 5 * df[\"b4\"] - 0.5)),\n        \"mndvi\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"] - 2 * df[\"b1\"]),\n        \"msr\": (df[\"b8\"] - df[\"b1\"]) / (df[\"b4\"] - df[\"b1\"]),\n        \"msrnir/red\": (df[\"b8\"] / df[\"b4\"] - 1) / (df[\"b8\"] / df[\"b4\"] + 1),\n        \"msavi\": (2 * df[\"b8\"] + 1 - np.sqrt((2 * df[\"b8\"] + 1) ** 2 - 8 * (df[\"b8\"] - df[\"b4\"]))) / 2,\n        \"msavihyper\": 0.5 * ((2 * df[\"b8\"] + 1 - np.sqrt((2 * df[\"b8\"] + 1) ** 2 - 8 * (df[\"b8\"] - df[\"b4\"]))) / 2),\n        \"mtvi1\": 1.2 * (1.2 * (df[\"b8\"] - df[\"b3\"]) - 2.5 * (df[\"b4\"] - df[\"b3\"])),\n        \"mtvi2\": ((1.5 * (df[\"b8\"] - df[\"b3\"]) - 2.5 * (df[\"b4\"] - df[\"b3\"])) / (2 * df[\"b8\"] + 1) - (6 * df[\"b8\"] - 5 * df[\"b4\"] - 0.5)),\n        \"nli\": (df[\"b8\"] * 2 - df[\"b4\"]) / (df[\"b8\"] * 2 + df[\"b4\"]),\n        \"norm g\": df[\"b3\"] / (df[\"b8\"] + df[\"b4\"] + df[\"b3\"]),\n        \"norm nir\": df[\"b8\"] / (df[\"b8\"] + df[\"b4\"] + df[\"b3\"]),\n        \"norm r\": df[\"b4\"] / (df[\"b8\"] + df[\"b4\"] + df[\"b3\"]),\n        \"ppr\": (df[\"b3\"] - df[\"b1\"]) / (df[\"b3\"] + df[\"b1\"]),\n        \"pvr\": (df[\"b3\"] - df[\"b4\"]) / (df[\"b3\"] + df[\"b4\"]),\n        \"nd774/677\": (df[\"b7\"] - df[\"b4\"]) / (df[\"b7\"] + df[\"b4\"]),\n        \"gndvihyper\": (df[\"b8\"] - df[\"b3\"]) / (df[\"b8\"] + df[\"b3\"]),\n        \"nd782/666\": (df[\"b7\"] - df[\"b4\"]) / (df[\"b7\"] + df[\"b4\"]),\n        \"nd790/670\": (df[\"b7\"] - df[\"b4\"]) / (df[\"b7\"] + df[\"b4\"]),\n        \"nd800/2170\": (df[\"b8\"] - df[\"b11\"]) / (df[\"b8\"] + df[\"b11\"]),\n        \"psndc2\": (df[\"b8\"] - df[\"b2\"]) / (df[\"b8\"] + df[\"b2\"]),\n        \"psndc1\": (df[\"b8\"] - df[\"b1\"]) / (df[\"b8\"] + df[\"b1\"]),\n        \"gndvihyper2\": (df[\"b8\"] - df[\"b3\"]) / (df[\"b8\"] + df[\"b3\"]),\n        \"psndb1\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]),\n        \"psnda1\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]),\n        \"nd800/680\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]),\n        \"ndii\": (df[\"b8\"] - df[\"b11\"]) / (df[\"b8\"] + df[\"b11\"]),\n        \"ndii2\": (df[\"b8\"] - df[\"b12\"]) / (df[\"b8\"] + df[\"b12\"]),\n        \"ndmi\": (df[\"b8\"] - df[\"b11\"]) / (df[\"b8\"] + df[\"b11\"]),\n        \"nd827/668\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]),\n        \"nd833/1649\": (df[\"b8\"] - df[\"b12\"]) / (df[\"b8\"] + df[\"b12\"]),\n        \"nd833/658\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]),\n        \"siwsi\": (df[\"b8\"] - df[\"b12\"]) / (df[\"b8\"] + df[\"b12\"]),\n        \"nd895/675\": (df[\"b9\"] - df[\"b4\"]) / (df[\"b9\"] + df[\"b4\"]),\n        \"ngrdi\": (df[\"b3\"] - df[\"b4\"]) / (df[\"b3\"] + df[\"b4\"]),\n        \"ndvi\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]),\n        \"bndvi\": (df[\"b8\"] - df[\"b2\"]) / (df[\"b8\"] + df[\"b2\"]),\n        \"gndvi\": (df[\"b8\"] - df[\"b3\"]) / (df[\"b8\"] + df[\"b3\"]),\n        \"mndvi\": (df[\"b8\"] - df[\"b12\"]) / (df[\"b8\"] + df[\"b12\"]),\n        \"ndvi\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]),\n        \"ndre\": (df[\"b8\"] - df[\"b5\"]) / (df[\"b8\"] + df[\"b5\"]),\n        \"nbr\": (df[\"b8\"] - df[\"b12\"]) / (df[\"b8\"] + df[\"b12\"]),\n        \"ri\": (df[\"b4\"] - df[\"b3\"]) / (df[\"b4\"] + df[\"b3\"]),\n        \"ndsi\": (df[\"b11\"] - df[\"b12\"]) / (df[\"b11\"] + df[\"b12\"]),\n        \"ndvi690-710\": (df[\"b8\"] - df[\"b5\"]) / (df[\"b8\"] + df[\"b5\"]),\n        \"ndvic\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]) * (1 - (df[\"b12\"] - df[\"b12\"]) / (df[\"b12\"] - df[\"b12\"])),\n        \"osavi\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"] + 0.16) * (1 + 0.16),\n        \"pndvi\": (df[\"b8\"] - (df[\"b3\"] + df[\"b4\"] + df[\"b2\"])) / (df[\"b8\"] + (df[\"b3\"] + df[\"b4\"] + df[\"b2\"])),\n        \"pvi\": (df[\"b8\"] - df[\"b4\"] - (df[\"b4\"] - df[\"b2\"])) / (df[\"b8\"] + df[\"b4\"] + (df[\"b4\"] - df[\"b2\"])),\n        \"rarSa1\": (df[\"b4\"] / df[\"b5\"]),\n        \"rarSa2\": (df[\"b4\"] / df[\"b5\"]),\n        \"rarSa3\": (df[\"b4\"] / df[\"b8\"]),\n        \"rarSa4\": (df[\"b4\"] / df[\"b8\"]),\n        \"rarSc4\": (df[\"b8\"] / df[\"b2\"]),\n        \"rdvi\": (df[\"b8\"] - df[\"b4\"]) / np.sqrt(df[\"b8\"] + df[\"b4\"]),\n        \"rdvi2\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]),\n        \"rededge1\": (df[\"b5\"] / df[\"b4\"]),\n        \"rededge2\": (df[\"b5\"] - df[\"b4\"]) / (df[\"b5\"] + df[\"b4\"]),\n        \"rbndvi\": (df[\"b8\"] - (df[\"b4\"] + df[\"b2\"])) / (df[\"b8\"] + (df[\"b4\"] + df[\"b2\"])),\n        \"reip1\": (df[\"b5\"] + df[\"b7\"]) / 2 - df[\"b5\"] * (df[\"b6\"] - df[\"b5\"]) / (df[\"b7\"] - df[\"b5\"]),\n        \"reip2\": (df[\"b4\"] + df[\"b7\"]) / 2 - df[\"b4\"] * (df[\"b6\"] - df[\"b4\"]) / (df[\"b7\"] - df[\"b4\"]),\n        \"reip3\": (df[\"b4\"] + df[\"b7\"]) / 2 - df[\"b4\"] * (df[\"b6\"] - df[\"b4\"]) / (df[\"b7\"] - df[\"b4\"]),\n        \"rep\": (df[\"b5\"] + df[\"b7\"]) / 2 - df[\"b5\"] * (df[\"b6\"] - df[\"b5\"]) / (df[\"b7\"] - df[\"b5\"]),\n        \"rsr\": df[\"b8\"] * (df[\"b12\"] - df[\"b12\"]) / (df[\"b12\"] - df[\"b12\"]),\n        \"rre\": (df[\"b4\"] + df[\"b7\"]) / 2,\n        \"rdvi\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"]),\n        \"savimir\": (df[\"b8\"] - df[\"b12\"]) / (df[\"b8\"] + df[\"b12\"] + 0.5) * (1 + 0.5),\n        \"msi2\": (df[\"b11\"] / df[\"b8\"]),\n        \"msi\": (df[\"b11\"] / df[\"b8\"]),\n        \"tm5/tm7\": (df[\"b12\"] / df[\"b11\"]),\n        \"sr440/740\": (df[\"b1\"] / df[\"b5\"]),\n        \"bgi\": (df[\"b1\"] / df[\"b3\"]),\n        \"sr520/670\": (df[\"b2\"] / df[\"b4\"]),\n        \"sr550/670\": (df[\"b3\"] / df[\"b4\"]),\n        \"dswi-4\": (df[\"b3\"] / df[\"b4\"]),\n        \"sr550/800\": (df[\"b3\"] / df[\"b8\"]),\n        \"gi\": (df[\"b3\"] / df[\"b4\"]),\n        \"sr560/658\": (df[\"b3\"] / df[\"b4\"]),\n        \"sr672/550\": (df[\"b4\"] / df[\"b3\"]),\n        \"sr672/708\": (df[\"b4\"] / df[\"b5\"]),\n        \"sr674/553\": (df[\"b4\"] / df[\"b3\"]),\n        \"sr675/555\": (df[\"b4\"] / df[\"b3\"]),\n        \"sr675/700\": (df[\"b4\"] / df[\"b5\"]),\n        \"sr675/705\": (df[\"b4\"] / df[\"b5\"]),\n        \"sr700\": df[\"b5\"],\n        \"sr700/670\": (df[\"b5\"] / df[\"b4\"]),\n        \"sr710/670\": (df[\"b5\"] / df[\"b4\"]),\n        \"sr735/710\": (df[\"b6\"] / df[\"b5\"]),\n        \"sr774/677\": (df[\"b7\"] / df[\"b4\"]),\n        \"sr800/2170\": (df[\"b8\"] / df[\"b11\"]),\n        \"pssrc2\": (df[\"b8\"] / df[\"b2\"]),\n        \"sr800/550\": (df[\"b8\"] / df[\"b3\"]),\n        \"pssrb1\": (df[\"b8\"] / df[\"b4\"]),\n        \"rvi\": (df[\"b8\"] / df[\"b4\"]),\n        \"pssra1\": (df[\"b8\"] / df[\"b4\"]),\n        \"sr800/680\": (df[\"b8\"] / df[\"b4\"]),\n        \"sr801/550\": (df[\"b8\"] / df[\"b3\"]),\n        \"sr801/670\": (df[\"b8\"] / df[\"b4\"]),\n        \"pbi\": (df[\"b8\"] / df[\"b3\"]),\n        \"sr833/1649\": (df[\"b8\"] / df[\"b12\"]),\n        \"sr833/658\": (df[\"b8\"] / df[\"b4\"]),\n        \"datt2\": (df[\"b8\"] / df[\"b5\"]),\n        \"sr860/550\": (df[\"b8\"] / df[\"b3\"]),\n        \"sr860/708\": (df[\"b8\"] / df[\"b5\"]),\n        \"rdi\": (df[\"b12\"] / df[\"b8\"]),\n        \"srmir/red\": (df[\"b12\"] / df[\"b4\"]),\n        \"srnir/700-715\": (df[\"b8\"] / df[\"b5\"]),\n        \"grvi\": (df[\"b8\"] / df[\"b3\"]),\n        \"srnir/mir\": (df[\"b8\"] / df[\"b12\"]),\n        \"dvi\": (df[\"b8\"] - df[\"b4\"]),\n        \"rri1\": (df[\"b8\"] / df[\"b5\"]),\n        \"io\": (df[\"b4\"] / df[\"b2\"]),\n        \"rgr\": (df[\"b4\"] / df[\"b3\"]),\n        \"srred/nir\": (df[\"b4\"] / df[\"b8\"]),\n        \"srswiri/nir\": (df[\"b11\"] / df[\"b8\"]),\n        \"sb1580\": df[\"b11\"],\n        \"sb2100\": df[\"b11\"],\n        \"sb2130\": df[\"b11\"],\n        \"sb2180\": df[\"b11\"],\n        \"sb2218\": df[\"b12\"],\n        \"sb2240\": df[\"b12\"],\n        \"sb2250\": df[\"b12\"],\n        \"sb2270\": df[\"b12\"],\n        \"sb2280\": df[\"b12\"],\n        \"sb460\": df[\"b1\"],\n        \"bb3\": df[\"b2\"],\n        \"sr495\": df[\"b2\"],\n        \"sb550\": df[\"b3\"],\n        \"sb555\": df[\"b3\"],\n        \"sb655\": df[\"b4\"],\n        \"sb660\": df[\"b4\"],\n        \"sb670\": df[\"b4\"],\n        \"sb675\": df[\"b4\"],\n        \"bb1\": df[\"b4\"],\n        \"sb700\": df[\"b5\"],\n        \"sb703\": df[\"b5\"],\n        \"sb705\": df[\"b5\"],\n        \"sb735\": df[\"b6\"],\n        \"sb801\": df[\"b8\"],\n        \"sb850\": df[\"b8\"],\n        \"sb885\": df[\"b9\"],\n        \"savi\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"] + 0.5) * (1 + 0.5),\n        \"sarvi\": (df[\"b8\"] - (df[\"b4\"] - 0.1 * (df[\"b4\"] - df[\"b2\"]))) / (df[\"b8\"] + (df[\"b4\"] - 0.1 * (df[\"b2\"] - df[\"b4\"])) + 0.5) * (1 + 0.5),\n        \"sarvi2\": 2.5 * ((df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + 6 * df[\"b4\"] - 7.5 * df[\"b2\"] + 1)),\n        \"savi3\": (df[\"b8\"] - df[\"b4\"]) / (df[\"b8\"] + df[\"b4\"] + 0.5) * (1 + 0.5),\n        \"sbl\": (2.4 * df[\"b8\"] - df[\"b4\"]) / (2.4 * df[\"b8\"] + df[\"b4\"]),\n        \"savi2\": (df[\"b8\"] / (df[\"b4\"] + 0.1 * df[\"b4\"])),\n        \"slavi\": (df[\"b8\"] / (df[\"b4\"] + df[\"b12\"])),\n        \"sqrt(ir/r)\": np.sqrt(df[\"b8\"] / df[\"b4\"]),\n        \"sipi1\": (df[\"b8\"] - df[\"b2\"]) / (df[\"b8\"] - df[\"b4\"]),\n        \"sipi3\": (df[\"b8\"] - df[\"b2\"]) / (df[\"b8\"] - df[\"b4\"]),\n        \"sbi\": 0.3037 * df[\"b1\"] + 0.2793 * df[\"b2\"] + 0.4743 * df[\"b4\"] + 0.5585 * df[\"b8\"] + 0.5082 * df[\"b11\"] + 0.1863 * df[\"b12\"],\n        \"gvimss\": -0.283 * df[\"b3\"] - 0.660 * df[\"b4\"] + 0.577 * df[\"b5\"] + 0.388 * df[\"b8\"],\n    }\n    # Add indices to the original DataFrame\n    for key, value in indices.items():\n        df[key] = value\n\n    return df\n    #return pd.DataFrame(indices)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:24:16.034259Z","iopub.execute_input":"2024-06-06T10:24:16.035011Z","iopub.status.idle":"2024-06-06T10:24:16.160693Z","shell.execute_reply.started":"2024-06-06T10:24:16.034972Z","shell.execute_reply":"2024-06-06T10:24:16.159590Z"},"trusted":true},"outputs":[],"execution_count":46},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:11:27.388312Z","iopub.execute_input":"2024-06-06T10:11:27.388903Z","iopub.status.idle":"2024-06-06T10:11:27.414747Z","shell.execute_reply.started":"2024-06-06T10:11:27.388863Z","shell.execute_reply":"2024-06-06T10:11:27.412701Z"},"trusted":true},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"          id    b1   b11   b12    b2    b3    b4    b5    b6    b7    b8  \\\n0       2002   293  1927  1038   278   475   453   987  1773  2184  1900   \n1       3212   197  1598   697   201   347   228   682  1982  2449  2254   \n2      13312   929  1975  1031   982  1020   856  1220  2051  2421  2392   \n3      17020   132  1560   689   189   408   175   609  2117  2907  3024   \n4       5967   241  1944  1131   362   538   487   918  1549  1844  1702   \n...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n13048   9185   374  1940  1054   382   565   498   977  1678  1929  2109   \n13049  13977  1983  3602  2720  1622  1782  1766  2314  3488  3900  3924   \n13050    755   940  2007  1148   975  1080   968  1252  1780  1983  1942   \n13051   1616  1174  2312  1190  1112  1126   889  1310  2511  3085  3050   \n13052  15634   193  2091  1084   274   502   452   881  1953  2427  2830   \n\n       b8_a    b9 nforest_type      ndvi  \n0      2343  3039          MDF  0.614960  \n1      2685  2690          DDF  0.816277  \n2      2671  2683          MDF  0.472906  \n3      3005  2955          MDF  0.890591  \n4      2077  2043          MDF  0.555048  \n...     ...   ...          ...       ...  \n13048  2291  2100          DDF  0.617952  \n13049  4097  6053          DDF  0.379262  \n13050  2247  2170          DDF  0.334708  \n13051  3396  3380          MDF  0.548616  \n13052  2863  2586          MDF  0.724558  \n\n[13053 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>b1</th>\n      <th>b11</th>\n      <th>b12</th>\n      <th>b2</th>\n      <th>b3</th>\n      <th>b4</th>\n      <th>b5</th>\n      <th>b6</th>\n      <th>b7</th>\n      <th>b8</th>\n      <th>b8_a</th>\n      <th>b9</th>\n      <th>nforest_type</th>\n      <th>ndvi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2002</td>\n      <td>293</td>\n      <td>1927</td>\n      <td>1038</td>\n      <td>278</td>\n      <td>475</td>\n      <td>453</td>\n      <td>987</td>\n      <td>1773</td>\n      <td>2184</td>\n      <td>1900</td>\n      <td>2343</td>\n      <td>3039</td>\n      <td>MDF</td>\n      <td>0.614960</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3212</td>\n      <td>197</td>\n      <td>1598</td>\n      <td>697</td>\n      <td>201</td>\n      <td>347</td>\n      <td>228</td>\n      <td>682</td>\n      <td>1982</td>\n      <td>2449</td>\n      <td>2254</td>\n      <td>2685</td>\n      <td>2690</td>\n      <td>DDF</td>\n      <td>0.816277</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13312</td>\n      <td>929</td>\n      <td>1975</td>\n      <td>1031</td>\n      <td>982</td>\n      <td>1020</td>\n      <td>856</td>\n      <td>1220</td>\n      <td>2051</td>\n      <td>2421</td>\n      <td>2392</td>\n      <td>2671</td>\n      <td>2683</td>\n      <td>MDF</td>\n      <td>0.472906</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17020</td>\n      <td>132</td>\n      <td>1560</td>\n      <td>689</td>\n      <td>189</td>\n      <td>408</td>\n      <td>175</td>\n      <td>609</td>\n      <td>2117</td>\n      <td>2907</td>\n      <td>3024</td>\n      <td>3005</td>\n      <td>2955</td>\n      <td>MDF</td>\n      <td>0.890591</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5967</td>\n      <td>241</td>\n      <td>1944</td>\n      <td>1131</td>\n      <td>362</td>\n      <td>538</td>\n      <td>487</td>\n      <td>918</td>\n      <td>1549</td>\n      <td>1844</td>\n      <td>1702</td>\n      <td>2077</td>\n      <td>2043</td>\n      <td>MDF</td>\n      <td>0.555048</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13048</th>\n      <td>9185</td>\n      <td>374</td>\n      <td>1940</td>\n      <td>1054</td>\n      <td>382</td>\n      <td>565</td>\n      <td>498</td>\n      <td>977</td>\n      <td>1678</td>\n      <td>1929</td>\n      <td>2109</td>\n      <td>2291</td>\n      <td>2100</td>\n      <td>DDF</td>\n      <td>0.617952</td>\n    </tr>\n    <tr>\n      <th>13049</th>\n      <td>13977</td>\n      <td>1983</td>\n      <td>3602</td>\n      <td>2720</td>\n      <td>1622</td>\n      <td>1782</td>\n      <td>1766</td>\n      <td>2314</td>\n      <td>3488</td>\n      <td>3900</td>\n      <td>3924</td>\n      <td>4097</td>\n      <td>6053</td>\n      <td>DDF</td>\n      <td>0.379262</td>\n    </tr>\n    <tr>\n      <th>13050</th>\n      <td>755</td>\n      <td>940</td>\n      <td>2007</td>\n      <td>1148</td>\n      <td>975</td>\n      <td>1080</td>\n      <td>968</td>\n      <td>1252</td>\n      <td>1780</td>\n      <td>1983</td>\n      <td>1942</td>\n      <td>2247</td>\n      <td>2170</td>\n      <td>DDF</td>\n      <td>0.334708</td>\n    </tr>\n    <tr>\n      <th>13051</th>\n      <td>1616</td>\n      <td>1174</td>\n      <td>2312</td>\n      <td>1190</td>\n      <td>1112</td>\n      <td>1126</td>\n      <td>889</td>\n      <td>1310</td>\n      <td>2511</td>\n      <td>3085</td>\n      <td>3050</td>\n      <td>3396</td>\n      <td>3380</td>\n      <td>MDF</td>\n      <td>0.548616</td>\n    </tr>\n    <tr>\n      <th>13052</th>\n      <td>15634</td>\n      <td>193</td>\n      <td>2091</td>\n      <td>1084</td>\n      <td>274</td>\n      <td>502</td>\n      <td>452</td>\n      <td>881</td>\n      <td>1953</td>\n      <td>2427</td>\n      <td>2830</td>\n      <td>2863</td>\n      <td>2586</td>\n      <td>MDF</td>\n      <td>0.724558</td>\n    </tr>\n  </tbody>\n</table>\n<p>13053 rows × 15 columns</p>\n</div>"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"#features_engineering(train)\ncalculate_vegetation_indices(train)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:24:20.095443Z","iopub.execute_input":"2024-06-06T10:24:20.095879Z","iopub.status.idle":"2024-06-06T10:24:20.323765Z","shell.execute_reply.started":"2024-06-06T10:24:20.095846Z","shell.execute_reply":"2024-06-06T10:24:20.322600Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning:\n\ninvalid value encountered in log\n\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning:\n\ninvalid value encountered in log\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"          id    b1   b11   b12    b2    b3    b4    b5    b6    b7  ...  \\\n0       2002   293  1927  1038   278   475   453   987  1773  2184  ...   \n1       3212   197  1598   697   201   347   228   682  1982  2449  ...   \n2      13312   929  1975  1031   982  1020   856  1220  2051  2421  ...   \n3      17020   132  1560   689   189   408   175   609  2117  2907  ...   \n4       5967   241  1944  1131   362   538   487   918  1549  1844  ...   \n...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n13048   9185   374  1940  1054   382   565   498   977  1678  1929  ...   \n13049  13977  1983  3602  2720  1622  1782  1766  2314  3488  3900  ...   \n13050    755   940  2007  1148   975  1080   968  1252  1780  1983  ...   \n13051   1616  1174  2312  1190  1112  1126   889  1310  2511  3085  ...   \n13052  15634   193  2091  1084   274   502   452   881  1953  2427  ...   \n\n           sarvi2     savi3       sbl      savi2     slavi  sqrt(ir/r)  \\\n0        1.427585  0.922243  0.819270   3.812964  1.274313    2.047989   \n1        2.394233  1.224169  0.919115   8.987241  2.436757    3.144195   \n2       23.414634  0.709250  0.740480   2.540357  1.267621    1.671644   \n3        2.680151  1.335677  0.952910  15.709091  3.500000    4.156922   \n4        1.590314  0.832382  0.786955   3.177151  1.051916    1.869456   \n...           ...       ...       ...        ...       ...         ...   \n13048    1.803627  0.926750  0.820850   3.849945  1.358892    2.057897   \n13049    2.289898  0.568843  0.684180   2.019973  0.874721    1.490628   \n13050    5.553022  0.501976  0.656055   1.823817  0.917769    1.416403   \n13051  120.055556  0.822820  0.783408   3.118928  1.467051    1.852248   \n13052    1.704415  1.086672  0.875207   5.691874  1.842448    2.502211   \n\n          sipi1     sipi3        sbi    gvimss  \n0      1.120940  1.120940  2615.3182   873.294  \n1      1.013327  1.013327  2424.9223  1019.385  \n2      0.917969  0.917969  3494.1130   778.416  \n3      0.995086  0.995086  2785.9353  1293.741  \n4      1.102881  1.102881  2554.4955   716.388  \n...         ...       ...        ...       ...  \n13048  1.072005  1.072005  2816.6225   893.446  \n13049  1.066728  1.066728  6421.7019  1187.824  \n13050  0.992813  0.992813  3335.3547   531.380  \n13051  0.896807  0.896807  4188.8585  1033.872  \n13052  1.074853  1.074853  3194.6763  1165.991  \n\n[13053 rows x 234 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>b1</th>\n      <th>b11</th>\n      <th>b12</th>\n      <th>b2</th>\n      <th>b3</th>\n      <th>b4</th>\n      <th>b5</th>\n      <th>b6</th>\n      <th>b7</th>\n      <th>...</th>\n      <th>sarvi2</th>\n      <th>savi3</th>\n      <th>sbl</th>\n      <th>savi2</th>\n      <th>slavi</th>\n      <th>sqrt(ir/r)</th>\n      <th>sipi1</th>\n      <th>sipi3</th>\n      <th>sbi</th>\n      <th>gvimss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2002</td>\n      <td>293</td>\n      <td>1927</td>\n      <td>1038</td>\n      <td>278</td>\n      <td>475</td>\n      <td>453</td>\n      <td>987</td>\n      <td>1773</td>\n      <td>2184</td>\n      <td>...</td>\n      <td>1.427585</td>\n      <td>0.922243</td>\n      <td>0.819270</td>\n      <td>3.812964</td>\n      <td>1.274313</td>\n      <td>2.047989</td>\n      <td>1.120940</td>\n      <td>1.120940</td>\n      <td>2615.3182</td>\n      <td>873.294</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3212</td>\n      <td>197</td>\n      <td>1598</td>\n      <td>697</td>\n      <td>201</td>\n      <td>347</td>\n      <td>228</td>\n      <td>682</td>\n      <td>1982</td>\n      <td>2449</td>\n      <td>...</td>\n      <td>2.394233</td>\n      <td>1.224169</td>\n      <td>0.919115</td>\n      <td>8.987241</td>\n      <td>2.436757</td>\n      <td>3.144195</td>\n      <td>1.013327</td>\n      <td>1.013327</td>\n      <td>2424.9223</td>\n      <td>1019.385</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13312</td>\n      <td>929</td>\n      <td>1975</td>\n      <td>1031</td>\n      <td>982</td>\n      <td>1020</td>\n      <td>856</td>\n      <td>1220</td>\n      <td>2051</td>\n      <td>2421</td>\n      <td>...</td>\n      <td>23.414634</td>\n      <td>0.709250</td>\n      <td>0.740480</td>\n      <td>2.540357</td>\n      <td>1.267621</td>\n      <td>1.671644</td>\n      <td>0.917969</td>\n      <td>0.917969</td>\n      <td>3494.1130</td>\n      <td>778.416</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17020</td>\n      <td>132</td>\n      <td>1560</td>\n      <td>689</td>\n      <td>189</td>\n      <td>408</td>\n      <td>175</td>\n      <td>609</td>\n      <td>2117</td>\n      <td>2907</td>\n      <td>...</td>\n      <td>2.680151</td>\n      <td>1.335677</td>\n      <td>0.952910</td>\n      <td>15.709091</td>\n      <td>3.500000</td>\n      <td>4.156922</td>\n      <td>0.995086</td>\n      <td>0.995086</td>\n      <td>2785.9353</td>\n      <td>1293.741</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5967</td>\n      <td>241</td>\n      <td>1944</td>\n      <td>1131</td>\n      <td>362</td>\n      <td>538</td>\n      <td>487</td>\n      <td>918</td>\n      <td>1549</td>\n      <td>1844</td>\n      <td>...</td>\n      <td>1.590314</td>\n      <td>0.832382</td>\n      <td>0.786955</td>\n      <td>3.177151</td>\n      <td>1.051916</td>\n      <td>1.869456</td>\n      <td>1.102881</td>\n      <td>1.102881</td>\n      <td>2554.4955</td>\n      <td>716.388</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13048</th>\n      <td>9185</td>\n      <td>374</td>\n      <td>1940</td>\n      <td>1054</td>\n      <td>382</td>\n      <td>565</td>\n      <td>498</td>\n      <td>977</td>\n      <td>1678</td>\n      <td>1929</td>\n      <td>...</td>\n      <td>1.803627</td>\n      <td>0.926750</td>\n      <td>0.820850</td>\n      <td>3.849945</td>\n      <td>1.358892</td>\n      <td>2.057897</td>\n      <td>1.072005</td>\n      <td>1.072005</td>\n      <td>2816.6225</td>\n      <td>893.446</td>\n    </tr>\n    <tr>\n      <th>13049</th>\n      <td>13977</td>\n      <td>1983</td>\n      <td>3602</td>\n      <td>2720</td>\n      <td>1622</td>\n      <td>1782</td>\n      <td>1766</td>\n      <td>2314</td>\n      <td>3488</td>\n      <td>3900</td>\n      <td>...</td>\n      <td>2.289898</td>\n      <td>0.568843</td>\n      <td>0.684180</td>\n      <td>2.019973</td>\n      <td>0.874721</td>\n      <td>1.490628</td>\n      <td>1.066728</td>\n      <td>1.066728</td>\n      <td>6421.7019</td>\n      <td>1187.824</td>\n    </tr>\n    <tr>\n      <th>13050</th>\n      <td>755</td>\n      <td>940</td>\n      <td>2007</td>\n      <td>1148</td>\n      <td>975</td>\n      <td>1080</td>\n      <td>968</td>\n      <td>1252</td>\n      <td>1780</td>\n      <td>1983</td>\n      <td>...</td>\n      <td>5.553022</td>\n      <td>0.501976</td>\n      <td>0.656055</td>\n      <td>1.823817</td>\n      <td>0.917769</td>\n      <td>1.416403</td>\n      <td>0.992813</td>\n      <td>0.992813</td>\n      <td>3335.3547</td>\n      <td>531.380</td>\n    </tr>\n    <tr>\n      <th>13051</th>\n      <td>1616</td>\n      <td>1174</td>\n      <td>2312</td>\n      <td>1190</td>\n      <td>1112</td>\n      <td>1126</td>\n      <td>889</td>\n      <td>1310</td>\n      <td>2511</td>\n      <td>3085</td>\n      <td>...</td>\n      <td>120.055556</td>\n      <td>0.822820</td>\n      <td>0.783408</td>\n      <td>3.118928</td>\n      <td>1.467051</td>\n      <td>1.852248</td>\n      <td>0.896807</td>\n      <td>0.896807</td>\n      <td>4188.8585</td>\n      <td>1033.872</td>\n    </tr>\n    <tr>\n      <th>13052</th>\n      <td>15634</td>\n      <td>193</td>\n      <td>2091</td>\n      <td>1084</td>\n      <td>274</td>\n      <td>502</td>\n      <td>452</td>\n      <td>881</td>\n      <td>1953</td>\n      <td>2427</td>\n      <td>...</td>\n      <td>1.704415</td>\n      <td>1.086672</td>\n      <td>0.875207</td>\n      <td>5.691874</td>\n      <td>1.842448</td>\n      <td>2.502211</td>\n      <td>1.074853</td>\n      <td>1.074853</td>\n      <td>3194.6763</td>\n      <td>1165.991</td>\n    </tr>\n  </tbody>\n</table>\n<p>13053 rows × 234 columns</p>\n</div>"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"# features_engineering(test)\ncalculate_vegetation_indices(test)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:26:40.936816Z","iopub.execute_input":"2024-06-06T10:26:40.937207Z","iopub.status.idle":"2024-06-06T10:26:41.139814Z","shell.execute_reply.started":"2024-06-06T10:26:40.937178Z","shell.execute_reply":"2024-06-06T10:26:41.138767Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning:\n\ninvalid value encountered in log\n\n/opt/conda/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning:\n\ninvalid value encountered in log\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n/tmp/ipykernel_33/1818109341.py:253: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"         id   b1   b11   b12   b2   b3   b4    b5    b6    b7  ...    sarvi2  \\\n0     13467   69  1425   693  312  524  376   847  1821  2356  ...  2.180828   \n1     12719  242  1514   691  343  522  324   718  1730  2178  ...  2.911358   \n2      1054  218  2354  1118  292  596  410   965  2586  3226  ...  2.032537   \n3     13747  350  2013  1134  306  572  475   982  1754  1935  ...  1.589544   \n4      9453  185  1450   712  293  440  384   673  1487  1965  ...  1.970480   \n...     ...  ...   ...   ...  ...  ...  ...   ...   ...   ...  ...       ...   \n3995    115  447  1686   811  425  661  441   958  2432  2891  ...  2.602556   \n3996  10654  252  2694  1503  470  778  753  1294  2334  2656  ...  1.310918   \n3997   5718  233  1486   618  249  409  260   699  2188  2831  ...  2.542684   \n3998  13054  221  1840   774  245  441  231   703  2491  3453  ...  2.693665   \n3999   6539    2  1431   629  140  373  254   596  1740  2436  ...  1.795788   \n\n         savi3       sbl      savi2     slavi  sqrt(ir/r)     sipi1     sipi3  \\\n0     1.090216  0.876381   5.749516  2.224509    2.514850  1.031968  1.031968   \n1     1.152154  0.896433   6.936027  2.435468    2.762178  0.991155  0.991155   \n2     1.174534  0.903534   7.474501  2.206152    2.867395  1.039851  1.039851   \n3     0.981640  0.839933   4.354067  1.413922    2.188487  1.093889  1.093889   \n4     1.056208  0.865150   5.239110  2.019161    2.400629  1.049754  1.049754   \n...        ...       ...        ...       ...         ...       ...       ...   \n3995  1.111519  0.883324   6.114203  2.369010    2.593381  1.006337  1.006337   \n3996  0.841661  0.790327   3.234335  1.187500    1.886205  1.146937  1.146937   \n3997  1.262726  0.930961  10.594406  3.451025    3.413773  1.003971  1.003971   \n3998  1.302660  0.943052  12.924046  3.267662    3.770471  0.995414  0.995414   \n3999  1.177825  0.904605   7.562634  2.392978    2.884250  1.061323  1.061323   \n\n            sbi    gvimss  \n0     2467.8376  1014.931  \n1     2601.7286  1011.856  \n2     3629.5149  1425.485  \n3     2921.9116   973.938  \n4     2425.6467   869.005  \n...         ...       ...  \n3995  3128.0482  1225.451  \n3996  3710.2725  1068.936  \n3997  2826.1994  1291.616  \n3998  3158.5077  1402.560  \n3999  2184.7090   890.537  \n\n[4000 rows x 233 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>b1</th>\n      <th>b11</th>\n      <th>b12</th>\n      <th>b2</th>\n      <th>b3</th>\n      <th>b4</th>\n      <th>b5</th>\n      <th>b6</th>\n      <th>b7</th>\n      <th>...</th>\n      <th>sarvi2</th>\n      <th>savi3</th>\n      <th>sbl</th>\n      <th>savi2</th>\n      <th>slavi</th>\n      <th>sqrt(ir/r)</th>\n      <th>sipi1</th>\n      <th>sipi3</th>\n      <th>sbi</th>\n      <th>gvimss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13467</td>\n      <td>69</td>\n      <td>1425</td>\n      <td>693</td>\n      <td>312</td>\n      <td>524</td>\n      <td>376</td>\n      <td>847</td>\n      <td>1821</td>\n      <td>2356</td>\n      <td>...</td>\n      <td>2.180828</td>\n      <td>1.090216</td>\n      <td>0.876381</td>\n      <td>5.749516</td>\n      <td>2.224509</td>\n      <td>2.514850</td>\n      <td>1.031968</td>\n      <td>1.031968</td>\n      <td>2467.8376</td>\n      <td>1014.931</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12719</td>\n      <td>242</td>\n      <td>1514</td>\n      <td>691</td>\n      <td>343</td>\n      <td>522</td>\n      <td>324</td>\n      <td>718</td>\n      <td>1730</td>\n      <td>2178</td>\n      <td>...</td>\n      <td>2.911358</td>\n      <td>1.152154</td>\n      <td>0.896433</td>\n      <td>6.936027</td>\n      <td>2.435468</td>\n      <td>2.762178</td>\n      <td>0.991155</td>\n      <td>0.991155</td>\n      <td>2601.7286</td>\n      <td>1011.856</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1054</td>\n      <td>218</td>\n      <td>2354</td>\n      <td>1118</td>\n      <td>292</td>\n      <td>596</td>\n      <td>410</td>\n      <td>965</td>\n      <td>2586</td>\n      <td>3226</td>\n      <td>...</td>\n      <td>2.032537</td>\n      <td>1.174534</td>\n      <td>0.903534</td>\n      <td>7.474501</td>\n      <td>2.206152</td>\n      <td>2.867395</td>\n      <td>1.039851</td>\n      <td>1.039851</td>\n      <td>3629.5149</td>\n      <td>1425.485</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13747</td>\n      <td>350</td>\n      <td>2013</td>\n      <td>1134</td>\n      <td>306</td>\n      <td>572</td>\n      <td>475</td>\n      <td>982</td>\n      <td>1754</td>\n      <td>1935</td>\n      <td>...</td>\n      <td>1.589544</td>\n      <td>0.981640</td>\n      <td>0.839933</td>\n      <td>4.354067</td>\n      <td>1.413922</td>\n      <td>2.188487</td>\n      <td>1.093889</td>\n      <td>1.093889</td>\n      <td>2921.9116</td>\n      <td>973.938</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9453</td>\n      <td>185</td>\n      <td>1450</td>\n      <td>712</td>\n      <td>293</td>\n      <td>440</td>\n      <td>384</td>\n      <td>673</td>\n      <td>1487</td>\n      <td>1965</td>\n      <td>...</td>\n      <td>1.970480</td>\n      <td>1.056208</td>\n      <td>0.865150</td>\n      <td>5.239110</td>\n      <td>2.019161</td>\n      <td>2.400629</td>\n      <td>1.049754</td>\n      <td>1.049754</td>\n      <td>2425.6467</td>\n      <td>869.005</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>115</td>\n      <td>447</td>\n      <td>1686</td>\n      <td>811</td>\n      <td>425</td>\n      <td>661</td>\n      <td>441</td>\n      <td>958</td>\n      <td>2432</td>\n      <td>2891</td>\n      <td>...</td>\n      <td>2.602556</td>\n      <td>1.111519</td>\n      <td>0.883324</td>\n      <td>6.114203</td>\n      <td>2.369010</td>\n      <td>2.593381</td>\n      <td>1.006337</td>\n      <td>1.006337</td>\n      <td>3128.0482</td>\n      <td>1225.451</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>10654</td>\n      <td>252</td>\n      <td>2694</td>\n      <td>1503</td>\n      <td>470</td>\n      <td>778</td>\n      <td>753</td>\n      <td>1294</td>\n      <td>2334</td>\n      <td>2656</td>\n      <td>...</td>\n      <td>1.310918</td>\n      <td>0.841661</td>\n      <td>0.790327</td>\n      <td>3.234335</td>\n      <td>1.187500</td>\n      <td>1.886205</td>\n      <td>1.146937</td>\n      <td>1.146937</td>\n      <td>3710.2725</td>\n      <td>1068.936</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>5718</td>\n      <td>233</td>\n      <td>1486</td>\n      <td>618</td>\n      <td>249</td>\n      <td>409</td>\n      <td>260</td>\n      <td>699</td>\n      <td>2188</td>\n      <td>2831</td>\n      <td>...</td>\n      <td>2.542684</td>\n      <td>1.262726</td>\n      <td>0.930961</td>\n      <td>10.594406</td>\n      <td>3.451025</td>\n      <td>3.413773</td>\n      <td>1.003971</td>\n      <td>1.003971</td>\n      <td>2826.1994</td>\n      <td>1291.616</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>13054</td>\n      <td>221</td>\n      <td>1840</td>\n      <td>774</td>\n      <td>245</td>\n      <td>441</td>\n      <td>231</td>\n      <td>703</td>\n      <td>2491</td>\n      <td>3453</td>\n      <td>...</td>\n      <td>2.693665</td>\n      <td>1.302660</td>\n      <td>0.943052</td>\n      <td>12.924046</td>\n      <td>3.267662</td>\n      <td>3.770471</td>\n      <td>0.995414</td>\n      <td>0.995414</td>\n      <td>3158.5077</td>\n      <td>1402.560</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>6539</td>\n      <td>2</td>\n      <td>1431</td>\n      <td>629</td>\n      <td>140</td>\n      <td>373</td>\n      <td>254</td>\n      <td>596</td>\n      <td>1740</td>\n      <td>2436</td>\n      <td>...</td>\n      <td>1.795788</td>\n      <td>1.177825</td>\n      <td>0.904605</td>\n      <td>7.562634</td>\n      <td>2.392978</td>\n      <td>2.884250</td>\n      <td>1.061323</td>\n      <td>1.061323</td>\n      <td>2184.7090</td>\n      <td>890.537</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows × 233 columns</p>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"markdown","source":"## Normalizetion","metadata":{}},{"cell_type":"code","source":"#Power Transformer\nfrom sklearn.preprocessing import PowerTransformer\n\nnforest_type = train['nforest_type']\ntrain = train.drop(columns=['nforest_type'])\n\npt = PowerTransformer(method='yeo-johnson', standardize=True)\npt.fit(train)\npt.fit(test)\n\ntrain['nforest_type'] = nforest_type\ntrain","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:46:50.394033Z","iopub.execute_input":"2024-06-06T09:46:50.394528Z","iopub.status.idle":"2024-06-06T09:46:52.770323Z","shell.execute_reply.started":"2024-06-06T09:46:50.394481Z","shell.execute_reply":"2024-06-06T09:46:52.768933Z"},"trusted":true},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"          id    b1   b11   b12    b2    b3    b4    b5    b6    b7  ...  \\\n0       2002   293  1927  1038   278   475   453   987  1773  2184  ...   \n1       3212   197  1598   697   201   347   228   682  1982  2449  ...   \n2      13312   929  1975  1031   982  1020   856  1220  2051  2421  ...   \n3      17020   132  1560   689   189   408   175   609  2117  2907  ...   \n4       5967   241  1944  1131   362   538   487   918  1549  1844  ...   \n...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n13048   9185   374  1940  1054   382   565   498   977  1678  1929  ...   \n13049  13977  1983  3602  2720  1622  1782  1766  2314  3488  3900  ...   \n13050    755   940  2007  1148   975  1080   968  1252  1780  1983  ...   \n13051   1616  1174  2312  1190  1112  1126   889  1310  2511  3085  ...   \n13052  15634   193  2091  1084   274   502   452   881  1953  2427  ...   \n\n       Red-Edge Inflection Point 2  Red-Edge Inflection Point 3  \\\n0                       768.844784                   763.489186   \n1                       743.030769                   740.901923   \n2                       780.628159                   773.799639   \n3                       742.742706                   740.649867   \n4                       775.565769                   769.370048   \n...                            ...                          ...   \n13048                   770.958631                   765.338802   \n13049                   798.354344                   789.310051   \n13050                   813.401515                   802.476326   \n13051                   768.011657                   762.760200   \n13052                   755.526119                   751.835354   \n\n       Reflectance at the inflexion point  Simple Ratio 1600/820  \\\n0                                  1318.5               1.014211   \n1                                  1338.5               0.708962   \n2                                  1638.5               0.825669   \n3                                  1541.0               0.515873   \n4                                  1165.5               1.142186   \n...                                   ...                    ...   \n13048                              1213.5               0.919867   \n13049                              2833.0               0.917941   \n13050                              1475.5               1.033471   \n13051                              1987.0               0.758033   \n13052                              1439.5               0.738869   \n\n       Simple Ratio 440/740  Simple Ratio 450/550  Simple Ratio 520/670  \\\n0                  0.165257              0.616842              0.613687   \n1                  0.099395              0.567723              0.881579   \n2                  0.452950              0.910784              1.147196   \n3                  0.062352              0.323529              1.080000   \n4                  0.155584              0.447955              0.743326   \n...                     ...                   ...                   ...   \n13048              0.222884              0.661947              0.767068   \n13049              0.568521              1.112795              0.918460   \n13050              0.528090              0.870370              1.007231   \n13051              0.467543              1.042629              1.250844   \n13052              0.098822              0.384462              0.606195   \n\n       Simple Ratio 550/800  Simple Ratio 560/658  nforest_type  \n0                  0.250000              1.048565           MDF  \n1                  0.153949              1.521930           DDF  \n2                  0.426421              1.191589           MDF  \n3                  0.134921              2.331429           MDF  \n4                  0.316099              1.104723           MDF  \n...                     ...                   ...           ...  \n13048              0.267899              1.134538           DDF  \n13049              0.454128              1.009060           DDF  \n13050              0.556128              1.115702           DDF  \n13051              0.369180              1.266592           MDF  \n13052              0.177385              1.110619           MDF  \n\n[13053 rows x 98 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>b1</th>\n      <th>b11</th>\n      <th>b12</th>\n      <th>b2</th>\n      <th>b3</th>\n      <th>b4</th>\n      <th>b5</th>\n      <th>b6</th>\n      <th>b7</th>\n      <th>...</th>\n      <th>Red-Edge Inflection Point 2</th>\n      <th>Red-Edge Inflection Point 3</th>\n      <th>Reflectance at the inflexion point</th>\n      <th>Simple Ratio 1600/820</th>\n      <th>Simple Ratio 440/740</th>\n      <th>Simple Ratio 450/550</th>\n      <th>Simple Ratio 520/670</th>\n      <th>Simple Ratio 550/800</th>\n      <th>Simple Ratio 560/658</th>\n      <th>nforest_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2002</td>\n      <td>293</td>\n      <td>1927</td>\n      <td>1038</td>\n      <td>278</td>\n      <td>475</td>\n      <td>453</td>\n      <td>987</td>\n      <td>1773</td>\n      <td>2184</td>\n      <td>...</td>\n      <td>768.844784</td>\n      <td>763.489186</td>\n      <td>1318.5</td>\n      <td>1.014211</td>\n      <td>0.165257</td>\n      <td>0.616842</td>\n      <td>0.613687</td>\n      <td>0.250000</td>\n      <td>1.048565</td>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3212</td>\n      <td>197</td>\n      <td>1598</td>\n      <td>697</td>\n      <td>201</td>\n      <td>347</td>\n      <td>228</td>\n      <td>682</td>\n      <td>1982</td>\n      <td>2449</td>\n      <td>...</td>\n      <td>743.030769</td>\n      <td>740.901923</td>\n      <td>1338.5</td>\n      <td>0.708962</td>\n      <td>0.099395</td>\n      <td>0.567723</td>\n      <td>0.881579</td>\n      <td>0.153949</td>\n      <td>1.521930</td>\n      <td>DDF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13312</td>\n      <td>929</td>\n      <td>1975</td>\n      <td>1031</td>\n      <td>982</td>\n      <td>1020</td>\n      <td>856</td>\n      <td>1220</td>\n      <td>2051</td>\n      <td>2421</td>\n      <td>...</td>\n      <td>780.628159</td>\n      <td>773.799639</td>\n      <td>1638.5</td>\n      <td>0.825669</td>\n      <td>0.452950</td>\n      <td>0.910784</td>\n      <td>1.147196</td>\n      <td>0.426421</td>\n      <td>1.191589</td>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17020</td>\n      <td>132</td>\n      <td>1560</td>\n      <td>689</td>\n      <td>189</td>\n      <td>408</td>\n      <td>175</td>\n      <td>609</td>\n      <td>2117</td>\n      <td>2907</td>\n      <td>...</td>\n      <td>742.742706</td>\n      <td>740.649867</td>\n      <td>1541.0</td>\n      <td>0.515873</td>\n      <td>0.062352</td>\n      <td>0.323529</td>\n      <td>1.080000</td>\n      <td>0.134921</td>\n      <td>2.331429</td>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5967</td>\n      <td>241</td>\n      <td>1944</td>\n      <td>1131</td>\n      <td>362</td>\n      <td>538</td>\n      <td>487</td>\n      <td>918</td>\n      <td>1549</td>\n      <td>1844</td>\n      <td>...</td>\n      <td>775.565769</td>\n      <td>769.370048</td>\n      <td>1165.5</td>\n      <td>1.142186</td>\n      <td>0.155584</td>\n      <td>0.447955</td>\n      <td>0.743326</td>\n      <td>0.316099</td>\n      <td>1.104723</td>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13048</th>\n      <td>9185</td>\n      <td>374</td>\n      <td>1940</td>\n      <td>1054</td>\n      <td>382</td>\n      <td>565</td>\n      <td>498</td>\n      <td>977</td>\n      <td>1678</td>\n      <td>1929</td>\n      <td>...</td>\n      <td>770.958631</td>\n      <td>765.338802</td>\n      <td>1213.5</td>\n      <td>0.919867</td>\n      <td>0.222884</td>\n      <td>0.661947</td>\n      <td>0.767068</td>\n      <td>0.267899</td>\n      <td>1.134538</td>\n      <td>DDF</td>\n    </tr>\n    <tr>\n      <th>13049</th>\n      <td>13977</td>\n      <td>1983</td>\n      <td>3602</td>\n      <td>2720</td>\n      <td>1622</td>\n      <td>1782</td>\n      <td>1766</td>\n      <td>2314</td>\n      <td>3488</td>\n      <td>3900</td>\n      <td>...</td>\n      <td>798.354344</td>\n      <td>789.310051</td>\n      <td>2833.0</td>\n      <td>0.917941</td>\n      <td>0.568521</td>\n      <td>1.112795</td>\n      <td>0.918460</td>\n      <td>0.454128</td>\n      <td>1.009060</td>\n      <td>DDF</td>\n    </tr>\n    <tr>\n      <th>13050</th>\n      <td>755</td>\n      <td>940</td>\n      <td>2007</td>\n      <td>1148</td>\n      <td>975</td>\n      <td>1080</td>\n      <td>968</td>\n      <td>1252</td>\n      <td>1780</td>\n      <td>1983</td>\n      <td>...</td>\n      <td>813.401515</td>\n      <td>802.476326</td>\n      <td>1475.5</td>\n      <td>1.033471</td>\n      <td>0.528090</td>\n      <td>0.870370</td>\n      <td>1.007231</td>\n      <td>0.556128</td>\n      <td>1.115702</td>\n      <td>DDF</td>\n    </tr>\n    <tr>\n      <th>13051</th>\n      <td>1616</td>\n      <td>1174</td>\n      <td>2312</td>\n      <td>1190</td>\n      <td>1112</td>\n      <td>1126</td>\n      <td>889</td>\n      <td>1310</td>\n      <td>2511</td>\n      <td>3085</td>\n      <td>...</td>\n      <td>768.011657</td>\n      <td>762.760200</td>\n      <td>1987.0</td>\n      <td>0.758033</td>\n      <td>0.467543</td>\n      <td>1.042629</td>\n      <td>1.250844</td>\n      <td>0.369180</td>\n      <td>1.266592</td>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>13052</th>\n      <td>15634</td>\n      <td>193</td>\n      <td>2091</td>\n      <td>1084</td>\n      <td>274</td>\n      <td>502</td>\n      <td>452</td>\n      <td>881</td>\n      <td>1953</td>\n      <td>2427</td>\n      <td>...</td>\n      <td>755.526119</td>\n      <td>751.835354</td>\n      <td>1439.5</td>\n      <td>0.738869</td>\n      <td>0.098822</td>\n      <td>0.384462</td>\n      <td>0.606195</td>\n      <td>0.177385</td>\n      <td>1.110619</td>\n      <td>MDF</td>\n    </tr>\n  </tbody>\n</table>\n<p>13053 rows × 98 columns</p>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"#StandardScaler\nscaler = StandardScaler()\nscaler_band = scaler.fit_transform(train)\n\n# Principal Component Analysis (PCA)\nbands = train[['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b8_a', 'b9', 'b11', 'b12']]\npca = PCA(n_components=3)\npca_features = pca.fit_transform(bands)\ntrain['PCA1'] = pca_features[:, 0]\ntrain['PCA2'] = pca_features[:, 1]\ntrain['PCA3'] = pca_features[:, 2]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_cols = train.select_dtypes(include=[np.number])\n\n# Band-wise maximum normalization\nBand_wise = numeric_cols.max()\nX_band_normalized = numeric_cols / Band_wise\ntrain_normalized = pd.concat([X_band_normalized, train.select_dtypes(exclude=[np.number])], axis=1)\n\nprint(\"Original Data:\\n\", train)\nprint(\"\\nBand-wise Maximum Normalized Data:\\n\", train_normalized)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T18:42:35.850326Z","iopub.execute_input":"2024-06-04T18:42:35.850857Z","iopub.status.idle":"2024-06-04T18:42:35.932111Z","shell.execute_reply.started":"2024-06-04T18:42:35.850818Z","shell.execute_reply":"2024-06-04T18:42:35.930823Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Original Data:\n           id    b1   b11   b12    b2    b3    b4    b5    b6    b7  ...  \\\n0       2002   293  1927  1038   278   475   453   987  1773  2184  ...   \n1       3212   197  1598   697   201   347   228   682  1982  2449  ...   \n2      13312   929  1975  1031   982  1020   856  1220  2051  2421  ...   \n3      17020   132  1560   689   189   408   175   609  2117  2907  ...   \n4       5967   241  1944  1131   362   538   487   918  1549  1844  ...   \n...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n13048   9185   374  1940  1054   382   565   498   977  1678  1929  ...   \n13049  13977  1983  3602  2720  1622  1782  1766  2314  3488  3900  ...   \n13050    755   940  2007  1148   975  1080   968  1252  1780  1983  ...   \n13051   1616  1174  2312  1190  1112  1126   889  1310  2511  3085  ...   \n13052  15634   193  2091  1084   274   502   452   881  1953  2427  ...   \n\n            CWSI    GBNDVI    GRNDVI     mNDVI  NDVI750_650   NDVI705  \\\n0      -0.125714  0.432341  0.343706  3.396714     0.614960  0.034577   \n1      -4.407407  0.608851  0.593496  2.291855     0.816277  0.064212   \n2       1.301587  0.088757  0.120900  1.206599     0.472906  0.076750   \n3      16.642857  0.670257  0.676740  1.738255     0.890591  0.176425   \n4      -0.408000  0.308224  0.248258  4.959184     0.555048  0.047062   \n...          ...       ...       ...       ...          ...       ...   \n13048  -0.577586  0.380236  0.329760  2.415292     0.617952  0.113810   \n13049  -0.111111  0.070961  0.050321  1.033525     0.379262  0.058824   \n13050  16.000000 -0.028271 -0.026566  1.078627     0.334708  0.043525   \n13051   1.062780  0.153555  0.204344  1.328211     0.548616  0.096925   \n13052  -0.280899  0.569606  0.495772  1.996641     0.724558  0.183358   \n\n          BNDVI         PCA1         PCA2        PCA3  \n0      0.744720  -690.036125   163.599803 -216.061962  \n1      0.836253  -446.551249  -422.101998   24.866739  \n2      0.417902    -9.753655  1076.920288  302.257004  \n3      0.882353   406.098925  -730.876614   90.372846  \n4      0.649225 -1503.491734   478.454826 -421.529957  \n...         ...          ...          ...         ...  \n13048  0.693296 -1086.776524   450.061107 -314.767961  \n13049  0.415074  4622.184453  2682.181216 -206.329716  \n13050  0.331505  -882.201515  1448.432400  149.974002  \n13051  0.465642  1494.912797  1085.310483  288.722605  \n13052  0.823454    17.707802     8.035725 -456.136752  \n\n[13053 rows x 86 columns]\n\nBand-wise Maximum Normalized Data:\n              id        b1       b11       b12        b2        b3        b4  \\\n0      0.117412  0.112003  0.468856  0.207849  0.112097  0.178036  0.180911   \n1      0.188376  0.075306  0.388808  0.139567  0.081048  0.130060  0.091054   \n2      0.780717  0.355122  0.480535  0.206448  0.395968  0.382309  0.341853   \n3      0.998182  0.050459  0.379562  0.137966  0.076210  0.152924  0.069888   \n4      0.349950  0.092125  0.472993  0.226472  0.145968  0.201649  0.194489   \n...         ...       ...       ...       ...       ...       ...       ...   \n13048  0.538678  0.142966  0.472019  0.211053  0.154032  0.211769  0.198882   \n13049  0.819717  0.758028  0.876399  0.544654  0.654032  0.667916  0.705272   \n13050  0.044279  0.359327  0.488321  0.229876  0.393145  0.404798  0.386581   \n13051  0.094775  0.448777  0.562530  0.238286  0.448387  0.422039  0.355032   \n13052  0.916896  0.073777  0.508759  0.217060  0.110484  0.188156  0.180511   \n\n             b5        b6        b7  ...    GBNDVI    GRNDVI     mNDVI  \\\n0      0.317874  0.445701  0.442105  ...  0.542133  0.442248  0.006996   \n1      0.219646  0.498240  0.495749  ...  0.763467  0.763655  0.004721   \n2      0.392915  0.515586  0.490081  ...  0.111297  0.155562  0.002485   \n3      0.196135  0.532177  0.588462  ...  0.840467  0.870765  0.003580   \n4      0.295652  0.389392  0.373279  ...  0.386497  0.319435  0.010215   \n...         ...       ...       ...  ...       ...       ...       ...   \n13048  0.314654  0.421820  0.390486  ...  0.476796  0.424305  0.004975   \n13049  0.745250  0.876823  0.789474  ...  0.088981  0.064749  0.002129   \n13050  0.403221  0.447461  0.401417  ... -0.035451 -0.034183  0.002222   \n13051  0.421900  0.631222  0.624494  ...  0.192550  0.262930  0.002736   \n13052  0.283736  0.490950  0.491296  ...  0.714257  0.637913  0.004113   \n\n       NDVI750_650   NDVI705     BNDVI      PCA1      PCA2      PCA3  \\\n0         0.664343  0.104988  0.745329 -0.106906  0.035439 -0.123954   \n1         0.881827  0.194971  0.836936 -0.069183 -0.091435  0.014266   \n2         0.510882  0.233042  0.418243 -0.001511  0.233280  0.173403   \n3         0.962108  0.535694  0.883074  0.062916 -0.158321  0.051846   \n4         0.599620  0.142900  0.649756 -0.232934  0.103642 -0.241830   \n...            ...       ...       ...       ...       ...       ...   \n13048     0.667575  0.345572  0.693863 -0.168373  0.097491 -0.180581   \n13049     0.409718  0.178611  0.415413  0.716108  0.581008 -0.118370   \n13050     0.361586  0.132159  0.331776 -0.136678  0.313756  0.086039   \n13051     0.592672  0.294302  0.466022  0.231604  0.235098  0.165639   \n13052     0.782742  0.556745  0.824127  0.002743  0.001741 -0.261683   \n\n       nforest_type  \n0               MDF  \n1               DDF  \n2               MDF  \n3               MDF  \n4               MDF  \n...             ...  \n13048           DDF  \n13049           DDF  \n13050           DDF  \n13051           MDF  \n13052           MDF  \n\n[13053 rows x 86 columns]\n","output_type":"stream"}],"execution_count":95},{"cell_type":"markdown","source":"##  Imbalanced","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nfrom imblearn.combine import SMOTETomek\nfrom sklearn.preprocessing import StandardScaler\n\n\nX = train.drop(columns=['nforest_type', 'id']) \ny = train['nforest_type'] \n\n\ninf_cols = X.columns[np.isinf(X).any()]\nif len(inf_cols) > 0:\n  X.replace([np.inf, -np.inf], 1e8, inplace=True)\n    \nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n\nprint('Original dataset shape %s' % Counter(y))\nsmt = SMOTETomek(random_state=42)\nX_res, y_res = smt.fit_resample(X_scaled, y)\nprint('Resampled dataset shape %s' % Counter(y_res))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T16:45:43.931232Z","iopub.execute_input":"2024-06-04T16:45:43.931652Z","iopub.status.idle":"2024-06-04T16:45:45.735274Z","shell.execute_reply.started":"2024-06-04T16:45:43.931621Z","shell.execute_reply":"2024-06-04T16:45:45.733963Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Original dataset shape Counter({'MDF': 5865, 'DDF': 4603, 'DEF': 2585})\nResampled dataset shape Counter({'DEF': 5782, 'DDF': 5379, 'MDF': 5346})\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from collections import Counter\nfrom imblearn.over_sampling import SMOTE\n\nX = train.drop(columns=['nforest_type', 'id']) \ny = train['nforest_type'] \n\ninf_cols = X.columns[np.isinf(X).any()]\nif len(inf_cols) > 0:\n    X.replace([np.inf, -np.inf], 1e8, inplace=True)\n    \nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nprint('Original dataset shape %s' % Counter(y))\nsm = SMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(X, y)\nprint('Resampled dataset shape %s' % Counter(y_res))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T18:09:55.952452Z","iopub.execute_input":"2024-06-04T18:09:55.952925Z","iopub.status.idle":"2024-06-04T18:09:56.309525Z","shell.execute_reply.started":"2024-06-04T18:09:55.952894Z","shell.execute_reply":"2024-06-04T18:09:56.308038Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Original dataset shape Counter({'MDF': 5865, 'DDF': 4603, 'DEF': 2585})\nResampled dataset shape Counter({'MDF': 5865, 'DDF': 5865, 'DEF': 5865})\n","output_type":"stream"}],"execution_count":72},{"cell_type":"markdown","source":"## Catboost with Optuna 1","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import f1_score, confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import KFold, cross_val_predict, train_test_split,GridSearchCV,cross_val_score\nfrom sklearn.metrics import accuracy_score,classification_report\n\nfrom catboost import CatBoostClassifier","metadata":{"execution":{"iopub.status.busy":"2024-06-04T16:48:32.224296Z","iopub.execute_input":"2024-06-04T16:48:32.224703Z","iopub.status.idle":"2024-06-04T16:48:32.361400Z","shell.execute_reply.started":"2024-06-04T16:48:32.224670Z","shell.execute_reply":"2024-06-04T16:48:32.360150Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def objective(trial):\n    feature_names = train.drop(columns=['nforest_type']).columns\n    X = train.drop(columns=['nforest_type']) \n    y = train['nforest_type'] \n    categorical_features_indices = np.where((X.dtypes == 'object') | (X.dtypes == 'int'))[0]\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n    param = {\n        \"objective\": trial.suggest_categorical(\"objective\", [\"MultiClass\"]),\n        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n        \"bootstrap_type\": trial.suggest_categorical(\n            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n        ),\n        \"used_ram_limit\": \"30gb\",\n    }\n\n    if param[\"bootstrap_type\"] == \"Bayesian\":\n        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n\n    cat_cls = CatBoostClassifier(**param)\n    cat_cls.fit(X_train, y_train, eval_set=[(X_test, y_test)], cat_features=categorical_features_indices, verbose=0, early_stopping_rounds=100)\n    preds = cat_cls.predict(X_test)\n    accuracy = accuracy_score(y_test, preds)\n    return accuracy\n\n\nif __name__ == \"__main__\":\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=50)\n\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\n\n    print(\"Best trial:\")\n    trial = study.best_trial\n\n    print(\"  Value: {}\".format(trial.value))\n\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T10:54:33.873819Z","iopub.execute_input":"2024-06-03T10:54:33.874307Z","iopub.status.idle":"2024-06-03T11:32:25.273652Z","shell.execute_reply.started":"2024-06-03T10:54:33.874268Z","shell.execute_reply":"2024-06-03T11:32:25.272271Z"},"trusted":true},"outputs":[{"name":"stderr","text":"[I 2024-06-03 10:54:33,887] A new study created in memory with name: no-name-ac443010-f4b0-4a8a-b23f-1c10bd1ef424\n[I 2024-06-03 10:55:13,077] Trial 0 finished with value: 0.5181307456588355 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.05467645713624847, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8184828446598161}. Best is trial 0 with value: 0.5181307456588355.\n[I 2024-06-03 10:55:32,794] Trial 1 finished with value: 0.5091930541368743 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.06257209880914691, 'depth': 6, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 3.956935999400233}. Best is trial 0 with value: 0.5181307456588355.\n[I 2024-06-03 10:57:45,309] Trial 2 finished with value: 0.5291113381001021 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.09147694809157897, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.21421228568545153}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 10:58:08,590] Trial 3 finished with value: 0.5038304392236976 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.09528092825389171, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 3.217683090476715}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 10:58:13,865] Trial 4 finished with value: 0.49055158324821246 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.02166931453991844, 'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 10:59:34,350] Trial 5 finished with value: 0.5222165474974464 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.09000920210689148, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 4.041843315806797}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 10:59:45,049] Trial 6 finished with value: 0.515832482124617 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.05970237513488662, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.6906423390748215}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:01:36,654] Trial 7 finished with value: 0.5250255362614913 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.07788113702341681, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:01:45,150] Trial 8 finished with value: 0.5171092951991828 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.03695318573020801, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:02:10,678] Trial 9 finished with value: 0.5063840653728294 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.0609901389829844, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 8.101238531551504}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:02:24,129] Trial 10 finished with value: 0.48493360572012256 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.07905792501867782, 'depth': 1, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.12341815117868166}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:02:51,102] Trial 11 finished with value: 0.5196629213483146 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.07771145777824658, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.19469668011254787}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:03:05,799] Trial 12 finished with value: 0.49591419816138915 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.09792285880526343, 'depth': 1, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:03:32,566] Trial 13 finished with value: 0.5194075587334014 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.0756999208711949, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.4969521782262332}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:03:51,255] Trial 14 finished with value: 0.5237487231869254 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.08614165235888098, 'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:05:40,704] Trial 15 finished with value: 0.5240040858018387 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.07129852419554794, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.44242914267891564}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:06:18,532] Trial 16 finished with value: 0.5278345250255363 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.08510219891828079, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:06:38,842] Trial 17 finished with value: 0.5160878447395302 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.041234199398292044, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:06:48,905] Trial 18 finished with value: 0.5204290091930541 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.08852466379360978, 'depth': 4, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9294408941929273}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:07:18,504] Trial 19 finished with value: 0.5255362614913177 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.09938961880882508, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:07:42,635] Trial 20 finished with value: 0.5283452502553626 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.050707667229752, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.34456382722330325}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:08:02,560] Trial 21 finished with value: 0.5196629213483146 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.046765966179355314, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.32331462393906996}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:08:17,312] Trial 22 finished with value: 0.5048518896833504 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.02751002703127813, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.311265130968554}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:09:02,403] Trial 23 finished with value: 0.5286006128702758 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.0685388416804523, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6338528628088396}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:09:47,291] Trial 24 finished with value: 0.5242594484167518 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.06754121544367923, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6773484733358532}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:10:06,543] Trial 25 finished with value: 0.5255362614913177 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.05288981148720602, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6530063164402813}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:10:13,511] Trial 26 finished with value: 0.5114913176710929 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.03530084618571085, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.33551552888253294}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:10:26,887] Trial 27 finished with value: 0.47880490296220635 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.012779800449894095, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6028357889693077}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:10:49,512] Trial 28 finished with value: 0.5127681307456589 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.04762278788315645, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.21810964884777537}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:11:48,072] Trial 29 finished with value: 0.5211950970377937 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.05550191581828821, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.42578368219316504}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:12:06,325] Trial 30 finished with value: 0.5242594484167518 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.06850078573815432, 'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7540438232487476}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:12:43,769] Trial 31 finished with value: 0.5214504596527069 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.08633319547933781, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5069301054474753}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:13:18,415] Trial 32 finished with value: 0.5191521961184883 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.0834268145599438, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:14:26,626] Trial 33 finished with value: 0.5181307456588355 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.09377990373375023, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.22466474218776616}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:15:19,128] Trial 34 finished with value: 0.508682328907048 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.07251975451297439, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.706768444734351}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:15:28,334] Trial 35 finished with value: 0.5268130745658836 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.06504808697755582, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:17:13,950] Trial 36 finished with value: 0.5270684371807968 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.0921869051466983, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.2970620803875299}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:17:32,201] Trial 37 finished with value: 0.5183861082737488 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.08116715147029158, 'depth': 5, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.1070257335709826}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:17:43,866] Trial 38 finished with value: 0.515832482124617 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.05785630748540149, 'depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:18:13,513] Trial 39 finished with value: 0.5002553626149132 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.05231724653131354, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 6.6327221124560936}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:18:31,780] Trial 40 finished with value: 0.5140449438202247 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.06184993963013786, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.40301458334919843}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:20:34,066] Trial 41 finished with value: 0.524514811031665 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.0926026016643146, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.08561131829205948}. Best is trial 2 with value: 0.5291113381001021.\n[I 2024-06-03 11:23:18,052] Trial 42 finished with value: 0.5314096016343207 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.09104515516880353, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.3225402273916668}. Best is trial 42 with value: 0.5314096016343207.\n[I 2024-06-03 11:25:35,052] Trial 43 finished with value: 0.5005107252298263 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.08269076145690449, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 5.976512330199279}. Best is trial 42 with value: 0.5314096016343207.\n[I 2024-06-03 11:26:43,361] Trial 44 finished with value: 0.5229826353421859 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.09515925174705998, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 2.4319490838681332}. Best is trial 42 with value: 0.5314096016343207.\n[I 2024-06-03 11:28:15,166] Trial 45 finished with value: 0.5250255362614913 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.09017143058653043, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.349384678660189}. Best is trial 42 with value: 0.5314096016343207.\n[I 2024-06-03 11:28:39,616] Trial 46 finished with value: 0.5263023493360572 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.07412244227481363, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 42 with value: 0.5314096016343207.\n[I 2024-06-03 11:30:03,255] Trial 47 finished with value: 0.508682328907048 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.08522452030929618, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 5.390565933449328}. Best is trial 42 with value: 0.5314096016343207.\n[I 2024-06-03 11:32:09,087] Trial 48 finished with value: 0.5214504596527069 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.07948438195993113, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 42 with value: 0.5314096016343207.\n[I 2024-06-03 11:32:25,255] Trial 49 finished with value: 0.515832482124617 and parameters: {'objective': 'MultiClass', 'colsample_bylevel': 0.09996299774312355, 'depth': 2, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5686348580281092}. Best is trial 42 with value: 0.5314096016343207.\n","output_type":"stream"},{"name":"stdout","text":"Number of finished trials: 50\nBest trial:\n  Value: 0.5314096016343207\n  Params: \n    objective: MultiClass\n    colsample_bylevel: 0.09104515516880353\n    depth: 12\n    boosting_type: Ordered\n    bootstrap_type: Bayesian\n    bagging_temperature: 0.3225402273916668\n","output_type":"stream"}],"execution_count":121},{"cell_type":"code","source":"accuracy =[]\nmodel_names =[]\n\n\nfeature_names = train.drop(columns=['nforest_type']).columns\nX = train.drop(columns=['nforest_type']) \ny = train['nforest_type']\ncategorical_features_indices = np.where((X.dtypes == 'object') | (X.dtypes == 'int'))[0]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nmodel = CatBoostClassifier(verbose=False,random_state=0,\n                          objective= 'MultiClass',\n    colsample_bylevel= 0.09104515516880353,\n    depth= 12,\n    boosting_type= 'Ordered',\n    bootstrap_type= 'Bayesian',\n    bagging_temperature= 0.3225402273916668)\n\nmodel.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_test, y_test))\ny_pred = model.predict(X_test)\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nprint(classification_report(y_test, y_pred))\n\nmodel_names = ['Catboost_tuned']\nresult_df6 = pd.DataFrame({'Accuracy':accuracy}, index=model_names)\nresult_df6","metadata":{"execution":{"iopub.status.busy":"2024-06-03T15:22:11.888246Z","iopub.execute_input":"2024-06-03T15:22:11.888714Z","iopub.status.idle":"2024-06-03T15:25:21.916430Z","shell.execute_reply.started":"2024-06-03T15:22:11.888678Z","shell.execute_reply":"2024-06-03T15:25:21.915088Z"},"trusted":true},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         DDF       0.51      0.37      0.43      1414\n         DEF       0.56      0.33      0.41       765\n         MDF       0.54      0.76      0.63      1737\n\n    accuracy                           0.53      3916\n   macro avg       0.53      0.48      0.49      3916\nweighted avg       0.53      0.53      0.51      3916\n\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                Accuracy\nCatboost_tuned    0.5314","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Catboost_tuned</th>\n      <td>0.5314</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"feature_importance = np.array(model.get_feature_importance())\nfeatures = np.array(X_train.columns)\nfi={'features':features,'feature_importance':feature_importance}\ndf_fi = pd.DataFrame(fi)\ndf_fi.sort_values(by=['feature_importance'], ascending=True,inplace=True)\nfig = px.bar(df_fi, x='feature_importance', y='features',title=\"CatBoost Feature Importance\",height=500)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T15:29:25.540180Z","iopub.execute_input":"2024-06-03T15:29:25.540567Z","iopub.status.idle":"2024-06-03T15:29:25.601038Z","shell.execute_reply.started":"2024-06-03T15:29:25.540535Z","shell.execute_reply":"2024-06-03T15:29:25.599467Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_train\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      3\u001b[0m fi\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m:features,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_importance\u001b[39m\u001b[38;5;124m'\u001b[39m:feature_importance}\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/catboost/core.py:3217\u001b[0m, in \u001b[0;36mCatBoost.get_feature_importance\u001b[0;34m(self, data, type, prettified, thread_count, verbose, fstr_type, shap_mode, model_output, interaction_indices, shap_calc_type, reference_data, sage_n_samples, sage_batch_size, sage_detect_convergence, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   3215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m need_meta_info:\n\u001b[0;32m-> 3217\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\n\u001b[1;32m   3218\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel has no meta information needed to calculate feature importances. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m   3219\u001b[0m \u001b[38;5;124m            Pass training dataset to this function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3220\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3221\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\n\u001b[1;32m   3222\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature importance type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m requires training dataset \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m   3223\u001b[0m \u001b[38;5;124m            to be passed to this function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m))\n","\u001b[0;31mCatBoostError\u001b[0m: Model has no meta information needed to calculate feature importances.                             Pass training dataset to this function."],"ename":"CatBoostError","evalue":"Model has no meta information needed to calculate feature importances.                             Pass training dataset to this function.","output_type":"error"}],"execution_count":16},{"cell_type":"markdown","source":"## Catboost with Optuna 2","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import f1_score, confusion_matrix, accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import KFold, cross_val_predict, train_test_split,GridSearchCV,cross_val_score\nfrom sklearn.metrics import accuracy_score,classification_report\n\nfrom catboost import CatBoostClassifier","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:28:34.130529Z","iopub.execute_input":"2024-06-06T10:28:34.130993Z","iopub.status.idle":"2024-06-06T10:28:34.139638Z","shell.execute_reply.started":"2024-06-06T10:28:34.130961Z","shell.execute_reply":"2024-06-06T10:28:34.138036Z"},"trusted":true},"outputs":[],"execution_count":52},{"cell_type":"code","source":"train2 = train[df_fi_sort_30['features']]\ntrain2['nforest_type'] = train['nforest_type']\ntrain2['id']  = train['id']\ntrain = train2\ntrain","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:33:14.832971Z","iopub.execute_input":"2024-06-04T07:33:14.833816Z","iopub.status.idle":"2024-06-04T07:33:14.904522Z","shell.execute_reply.started":"2024-06-04T07:33:14.833753Z","shell.execute_reply":"2024-06-04T07:33:14.902487Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/1332898825.py:2: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/tmp/ipykernel_33/1332898825.py:3: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n","output_type":"stream"},{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"           CCCI   b11    b9   NDVI705   b12    b1  b8_a     PSRI2        TCW  \\\n0      0.662169  1927  3039  0.034577  1038   293  2343 -0.012408  -912.8969   \n1      0.728786  1598  2690  0.064212   697   197  2685 -0.060040  -513.4345   \n2      0.788553  1975  2683  0.076750  1031   929  2671 -0.079961  -430.0350   \n3      0.744424  1560  2955  0.176425   689   132  3005 -0.110061  -227.5815   \n4      0.697198  1944  2043  0.047062  1131   241  2077 -0.032924  -998.5686   \n...         ...   ...   ...       ...   ...   ...   ...       ...        ...   \n13048  0.650667  1940  2100  0.113810  1054   374  2291 -0.039928  -809.9922   \n13049  0.733308  3602  6053  0.058824  2720  1983  4097 -0.004587 -1290.2340   \n13050  0.849597  2007  2170  0.043525  1148   940  2247 -0.062921  -611.9148   \n13051  0.807967  2312  3380  0.096925  1190  1174  3396 -0.094385  -466.7947   \n13052  0.730625  2091  2586  0.183358  1084   193  2863 -0.025602  -729.3417   \n\n         b5  ...           BAI       BSI      NDGI        TCB         EVI  \\\n0       987  ...  2.133588e-07  0.044318  0.261620  2667.9857    1.427585   \n1       682  ...  1.796690e-07 -0.146928  0.266423  2469.7465    2.394233   \n2      1220  ...  1.474052e-07 -0.087510  0.018981  3522.3486   23.414634   \n3       609  ...  1.039651e-07 -0.298707  0.366834  2868.3428    2.680151   \n4       918  ...  2.394929e-07  0.081646  0.195556  2642.2587    1.590314   \n...     ...  ...           ...       ...       ...        ...         ...   \n13048   977  ...  1.799128e-07 -0.010753  0.193242  2872.4781    1.803627   \n13049  2314  ...  4.386914e-08 -0.016309  0.047004  6359.6644    2.289898   \n13050  1252  ...  1.965122e-07  0.009844  0.051095  3376.1573    5.553022   \n13051  1310  ...  9.330232e-08 -0.130517  0.006256  4176.2511  120.055556   \n13052   881  ...  1.088938e-07 -0.099345  0.293814  3286.4532    1.704415   \n\n       b11_b8_diff       HGI     MNDWI  nforest_type     id  \n0               27 -0.023707 -0.604496           MDF   2002  \n1             -656 -0.206957 -0.643188           DDF   3212  \n2             -417 -0.087420 -0.318865           MDF  13312  \n3            -1464 -0.399657 -0.585366           MDF  17020  \n4              242 -0.049756 -0.566479           MDF   5967  \n...            ...       ...       ...           ...    ...  \n13048         -169 -0.063029 -0.548902           DDF   9185  \n13049         -322 -0.004510 -0.338039           DDF  13977  \n13050           65 -0.054688 -0.300292           DDF    755  \n13051         -738 -0.117618 -0.344968           MDF   1616  \n13052         -739 -0.052411 -0.612804           MDF  15634  \n\n[13053 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CCCI</th>\n      <th>b11</th>\n      <th>b9</th>\n      <th>NDVI705</th>\n      <th>b12</th>\n      <th>b1</th>\n      <th>b8_a</th>\n      <th>PSRI2</th>\n      <th>TCW</th>\n      <th>b5</th>\n      <th>...</th>\n      <th>BAI</th>\n      <th>BSI</th>\n      <th>NDGI</th>\n      <th>TCB</th>\n      <th>EVI</th>\n      <th>b11_b8_diff</th>\n      <th>HGI</th>\n      <th>MNDWI</th>\n      <th>nforest_type</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.662169</td>\n      <td>1927</td>\n      <td>3039</td>\n      <td>0.034577</td>\n      <td>1038</td>\n      <td>293</td>\n      <td>2343</td>\n      <td>-0.012408</td>\n      <td>-912.8969</td>\n      <td>987</td>\n      <td>...</td>\n      <td>2.133588e-07</td>\n      <td>0.044318</td>\n      <td>0.261620</td>\n      <td>2667.9857</td>\n      <td>1.427585</td>\n      <td>27</td>\n      <td>-0.023707</td>\n      <td>-0.604496</td>\n      <td>MDF</td>\n      <td>2002</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.728786</td>\n      <td>1598</td>\n      <td>2690</td>\n      <td>0.064212</td>\n      <td>697</td>\n      <td>197</td>\n      <td>2685</td>\n      <td>-0.060040</td>\n      <td>-513.4345</td>\n      <td>682</td>\n      <td>...</td>\n      <td>1.796690e-07</td>\n      <td>-0.146928</td>\n      <td>0.266423</td>\n      <td>2469.7465</td>\n      <td>2.394233</td>\n      <td>-656</td>\n      <td>-0.206957</td>\n      <td>-0.643188</td>\n      <td>DDF</td>\n      <td>3212</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.788553</td>\n      <td>1975</td>\n      <td>2683</td>\n      <td>0.076750</td>\n      <td>1031</td>\n      <td>929</td>\n      <td>2671</td>\n      <td>-0.079961</td>\n      <td>-430.0350</td>\n      <td>1220</td>\n      <td>...</td>\n      <td>1.474052e-07</td>\n      <td>-0.087510</td>\n      <td>0.018981</td>\n      <td>3522.3486</td>\n      <td>23.414634</td>\n      <td>-417</td>\n      <td>-0.087420</td>\n      <td>-0.318865</td>\n      <td>MDF</td>\n      <td>13312</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.744424</td>\n      <td>1560</td>\n      <td>2955</td>\n      <td>0.176425</td>\n      <td>689</td>\n      <td>132</td>\n      <td>3005</td>\n      <td>-0.110061</td>\n      <td>-227.5815</td>\n      <td>609</td>\n      <td>...</td>\n      <td>1.039651e-07</td>\n      <td>-0.298707</td>\n      <td>0.366834</td>\n      <td>2868.3428</td>\n      <td>2.680151</td>\n      <td>-1464</td>\n      <td>-0.399657</td>\n      <td>-0.585366</td>\n      <td>MDF</td>\n      <td>17020</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.697198</td>\n      <td>1944</td>\n      <td>2043</td>\n      <td>0.047062</td>\n      <td>1131</td>\n      <td>241</td>\n      <td>2077</td>\n      <td>-0.032924</td>\n      <td>-998.5686</td>\n      <td>918</td>\n      <td>...</td>\n      <td>2.394929e-07</td>\n      <td>0.081646</td>\n      <td>0.195556</td>\n      <td>2642.2587</td>\n      <td>1.590314</td>\n      <td>242</td>\n      <td>-0.049756</td>\n      <td>-0.566479</td>\n      <td>MDF</td>\n      <td>5967</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13048</th>\n      <td>0.650667</td>\n      <td>1940</td>\n      <td>2100</td>\n      <td>0.113810</td>\n      <td>1054</td>\n      <td>374</td>\n      <td>2291</td>\n      <td>-0.039928</td>\n      <td>-809.9922</td>\n      <td>977</td>\n      <td>...</td>\n      <td>1.799128e-07</td>\n      <td>-0.010753</td>\n      <td>0.193242</td>\n      <td>2872.4781</td>\n      <td>1.803627</td>\n      <td>-169</td>\n      <td>-0.063029</td>\n      <td>-0.548902</td>\n      <td>DDF</td>\n      <td>9185</td>\n    </tr>\n    <tr>\n      <th>13049</th>\n      <td>0.733308</td>\n      <td>3602</td>\n      <td>6053</td>\n      <td>0.058824</td>\n      <td>2720</td>\n      <td>1983</td>\n      <td>4097</td>\n      <td>-0.004587</td>\n      <td>-1290.2340</td>\n      <td>2314</td>\n      <td>...</td>\n      <td>4.386914e-08</td>\n      <td>-0.016309</td>\n      <td>0.047004</td>\n      <td>6359.6644</td>\n      <td>2.289898</td>\n      <td>-322</td>\n      <td>-0.004510</td>\n      <td>-0.338039</td>\n      <td>DDF</td>\n      <td>13977</td>\n    </tr>\n    <tr>\n      <th>13050</th>\n      <td>0.849597</td>\n      <td>2007</td>\n      <td>2170</td>\n      <td>0.043525</td>\n      <td>1148</td>\n      <td>940</td>\n      <td>2247</td>\n      <td>-0.062921</td>\n      <td>-611.9148</td>\n      <td>1252</td>\n      <td>...</td>\n      <td>1.965122e-07</td>\n      <td>0.009844</td>\n      <td>0.051095</td>\n      <td>3376.1573</td>\n      <td>5.553022</td>\n      <td>65</td>\n      <td>-0.054688</td>\n      <td>-0.300292</td>\n      <td>DDF</td>\n      <td>755</td>\n    </tr>\n    <tr>\n      <th>13051</th>\n      <td>0.807967</td>\n      <td>2312</td>\n      <td>3380</td>\n      <td>0.096925</td>\n      <td>1190</td>\n      <td>1174</td>\n      <td>3396</td>\n      <td>-0.094385</td>\n      <td>-466.7947</td>\n      <td>1310</td>\n      <td>...</td>\n      <td>9.330232e-08</td>\n      <td>-0.130517</td>\n      <td>0.006256</td>\n      <td>4176.2511</td>\n      <td>120.055556</td>\n      <td>-738</td>\n      <td>-0.117618</td>\n      <td>-0.344968</td>\n      <td>MDF</td>\n      <td>1616</td>\n    </tr>\n    <tr>\n      <th>13052</th>\n      <td>0.730625</td>\n      <td>2091</td>\n      <td>2586</td>\n      <td>0.183358</td>\n      <td>1084</td>\n      <td>193</td>\n      <td>2863</td>\n      <td>-0.025602</td>\n      <td>-729.3417</td>\n      <td>881</td>\n      <td>...</td>\n      <td>1.088938e-07</td>\n      <td>-0.099345</td>\n      <td>0.293814</td>\n      <td>3286.4532</td>\n      <td>1.704415</td>\n      <td>-739</td>\n      <td>-0.052411</td>\n      <td>-0.612804</td>\n      <td>MDF</td>\n      <td>15634</td>\n    </tr>\n  </tbody>\n</table>\n<p>13053 rows × 32 columns</p>\n</div>"},"metadata":{}}],"execution_count":128},{"cell_type":"code","source":"test2 = test[df_fi_sort_30['features']]\ntest2['id'] = test['id']\ntest = test2\ntest","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:33:18.599694Z","iopub.execute_input":"2024-06-04T07:33:18.600171Z","iopub.status.idle":"2024-06-04T07:33:18.646052Z","shell.execute_reply.started":"2024-06-04T07:33:18.600135Z","shell.execute_reply":"2024-06-04T07:33:18.644699Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2846264037.py:2: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n","output_type":"stream"},{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"          CCCI   b11    b9   NDVI705   b12   b1  b8_a     PSRI2        TCW  \\\n0     0.701736  1425  2595  0.132651   693   69  2611 -0.081274  -245.9574   \n1     0.694199  1514  2582  0.176583   691  242  2359 -0.114451  -289.1432   \n2     0.742339  2354  3149  0.131778  1118  218  3645 -0.071926  -740.2233   \n3     0.610738  2013  2345  0.129312  1134  350  2290 -0.055302  -859.5155   \n4     0.754678  1450  2193  0.196216   712  185  2200 -0.037660  -345.4452   \n...        ...   ...   ...       ...   ...  ...   ...       ...        ...   \n3995  0.716282  1686  3312  0.098926   811  447  3126 -0.090461  -219.7318   \n3996  0.758487  2694  2856  0.068821  1503  252  3212 -0.010711 -1218.0759   \n3997  0.749036  1486  3087  0.161365   618  233  3086 -0.068099  -103.3338   \n3998  0.788781  1840  3161  0.137316   774  221  3762 -0.084303  -343.6697   \n3999  0.804974  1431  2630  0.096808   629    2  2645 -0.068391  -407.1696   \n\n        b5  ...       NBR           BAI       BSI      NDGI        TCB  \\\n0      847  ...  0.548681  1.630105e-07 -0.197951  0.253589  2603.5238   \n1      718  ...  0.563073  1.517983e-07 -0.209972  0.206936  2685.2131   \n2      965  ...  0.501894  7.928481e-08 -0.139879  0.342342  3741.0899   \n3      982  ...  0.334702  1.547750e-07 -0.018347  0.302961  2985.5254   \n4      673  ...  0.513162  1.850555e-07 -0.154839  0.200546  2502.0260   \n...    ...  ...       ...           ...       ...       ...        ...   \n3995   958  ...  0.570559  1.057732e-07 -0.229069  0.217311  3190.5830   \n3996  1294  ...  0.281205  1.059846e-07  0.045179  0.246795  3865.3944   \n3997   699  ...  0.661184  1.045791e-07 -0.305075  0.243161  2879.5021   \n3998   703  ...  0.618531  8.785044e-08 -0.260357  0.285714  3224.7298   \n3999   596  ...  0.541211  2.057650e-07 -0.144236  0.454191  2294.3075   \n\n           EVI  b11_b8_diff       HGI     MNDWI     id  \n0     2.180828         -953 -0.164444 -0.462288  13467  \n1     2.911358         -958 -0.234043 -0.487230  12719  \n2     2.032537        -1017 -0.184891 -0.595932   1054  \n3     1.589544         -262 -0.092646 -0.557447  13747  \n4     1.970480         -763 -0.067961 -0.534392   9453  \n...        ...          ...       ...       ...    ...  \n3995  2.602556        -1280 -0.199637 -0.436728    115  \n3996  1.310918           15 -0.016329 -0.551843  10654  \n3997  2.542684        -1544 -0.222720 -0.568338   5718  \n3998  2.693665        -1444 -0.312500 -0.613327  13054  \n3999  1.795788         -682 -0.189793 -0.586475   6539  \n\n[4000 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CCCI</th>\n      <th>b11</th>\n      <th>b9</th>\n      <th>NDVI705</th>\n      <th>b12</th>\n      <th>b1</th>\n      <th>b8_a</th>\n      <th>PSRI2</th>\n      <th>TCW</th>\n      <th>b5</th>\n      <th>...</th>\n      <th>NBR</th>\n      <th>BAI</th>\n      <th>BSI</th>\n      <th>NDGI</th>\n      <th>TCB</th>\n      <th>EVI</th>\n      <th>b11_b8_diff</th>\n      <th>HGI</th>\n      <th>MNDWI</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.701736</td>\n      <td>1425</td>\n      <td>2595</td>\n      <td>0.132651</td>\n      <td>693</td>\n      <td>69</td>\n      <td>2611</td>\n      <td>-0.081274</td>\n      <td>-245.9574</td>\n      <td>847</td>\n      <td>...</td>\n      <td>0.548681</td>\n      <td>1.630105e-07</td>\n      <td>-0.197951</td>\n      <td>0.253589</td>\n      <td>2603.5238</td>\n      <td>2.180828</td>\n      <td>-953</td>\n      <td>-0.164444</td>\n      <td>-0.462288</td>\n      <td>13467</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.694199</td>\n      <td>1514</td>\n      <td>2582</td>\n      <td>0.176583</td>\n      <td>691</td>\n      <td>242</td>\n      <td>2359</td>\n      <td>-0.114451</td>\n      <td>-289.1432</td>\n      <td>718</td>\n      <td>...</td>\n      <td>0.563073</td>\n      <td>1.517983e-07</td>\n      <td>-0.209972</td>\n      <td>0.206936</td>\n      <td>2685.2131</td>\n      <td>2.911358</td>\n      <td>-958</td>\n      <td>-0.234043</td>\n      <td>-0.487230</td>\n      <td>12719</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.742339</td>\n      <td>2354</td>\n      <td>3149</td>\n      <td>0.131778</td>\n      <td>1118</td>\n      <td>218</td>\n      <td>3645</td>\n      <td>-0.071926</td>\n      <td>-740.2233</td>\n      <td>965</td>\n      <td>...</td>\n      <td>0.501894</td>\n      <td>7.928481e-08</td>\n      <td>-0.139879</td>\n      <td>0.342342</td>\n      <td>3741.0899</td>\n      <td>2.032537</td>\n      <td>-1017</td>\n      <td>-0.184891</td>\n      <td>-0.595932</td>\n      <td>1054</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.610738</td>\n      <td>2013</td>\n      <td>2345</td>\n      <td>0.129312</td>\n      <td>1134</td>\n      <td>350</td>\n      <td>2290</td>\n      <td>-0.055302</td>\n      <td>-859.5155</td>\n      <td>982</td>\n      <td>...</td>\n      <td>0.334702</td>\n      <td>1.547750e-07</td>\n      <td>-0.018347</td>\n      <td>0.302961</td>\n      <td>2985.5254</td>\n      <td>1.589544</td>\n      <td>-262</td>\n      <td>-0.092646</td>\n      <td>-0.557447</td>\n      <td>13747</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.754678</td>\n      <td>1450</td>\n      <td>2193</td>\n      <td>0.196216</td>\n      <td>712</td>\n      <td>185</td>\n      <td>2200</td>\n      <td>-0.037660</td>\n      <td>-345.4452</td>\n      <td>673</td>\n      <td>...</td>\n      <td>0.513162</td>\n      <td>1.850555e-07</td>\n      <td>-0.154839</td>\n      <td>0.200546</td>\n      <td>2502.0260</td>\n      <td>1.970480</td>\n      <td>-763</td>\n      <td>-0.067961</td>\n      <td>-0.534392</td>\n      <td>9453</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>0.716282</td>\n      <td>1686</td>\n      <td>3312</td>\n      <td>0.098926</td>\n      <td>811</td>\n      <td>447</td>\n      <td>3126</td>\n      <td>-0.090461</td>\n      <td>-219.7318</td>\n      <td>958</td>\n      <td>...</td>\n      <td>0.570559</td>\n      <td>1.057732e-07</td>\n      <td>-0.229069</td>\n      <td>0.217311</td>\n      <td>3190.5830</td>\n      <td>2.602556</td>\n      <td>-1280</td>\n      <td>-0.199637</td>\n      <td>-0.436728</td>\n      <td>115</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>0.758487</td>\n      <td>2694</td>\n      <td>2856</td>\n      <td>0.068821</td>\n      <td>1503</td>\n      <td>252</td>\n      <td>3212</td>\n      <td>-0.010711</td>\n      <td>-1218.0759</td>\n      <td>1294</td>\n      <td>...</td>\n      <td>0.281205</td>\n      <td>1.059846e-07</td>\n      <td>0.045179</td>\n      <td>0.246795</td>\n      <td>3865.3944</td>\n      <td>1.310918</td>\n      <td>15</td>\n      <td>-0.016329</td>\n      <td>-0.551843</td>\n      <td>10654</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>0.749036</td>\n      <td>1486</td>\n      <td>3087</td>\n      <td>0.161365</td>\n      <td>618</td>\n      <td>233</td>\n      <td>3086</td>\n      <td>-0.068099</td>\n      <td>-103.3338</td>\n      <td>699</td>\n      <td>...</td>\n      <td>0.661184</td>\n      <td>1.045791e-07</td>\n      <td>-0.305075</td>\n      <td>0.243161</td>\n      <td>2879.5021</td>\n      <td>2.542684</td>\n      <td>-1544</td>\n      <td>-0.222720</td>\n      <td>-0.568338</td>\n      <td>5718</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>0.788781</td>\n      <td>1840</td>\n      <td>3161</td>\n      <td>0.137316</td>\n      <td>774</td>\n      <td>221</td>\n      <td>3762</td>\n      <td>-0.084303</td>\n      <td>-343.6697</td>\n      <td>703</td>\n      <td>...</td>\n      <td>0.618531</td>\n      <td>8.785044e-08</td>\n      <td>-0.260357</td>\n      <td>0.285714</td>\n      <td>3224.7298</td>\n      <td>2.693665</td>\n      <td>-1444</td>\n      <td>-0.312500</td>\n      <td>-0.613327</td>\n      <td>13054</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>0.804974</td>\n      <td>1431</td>\n      <td>2630</td>\n      <td>0.096808</td>\n      <td>629</td>\n      <td>2</td>\n      <td>2645</td>\n      <td>-0.068391</td>\n      <td>-407.1696</td>\n      <td>596</td>\n      <td>...</td>\n      <td>0.541211</td>\n      <td>2.057650e-07</td>\n      <td>-0.144236</td>\n      <td>0.454191</td>\n      <td>2294.3075</td>\n      <td>1.795788</td>\n      <td>-682</td>\n      <td>-0.189793</td>\n      <td>-0.586475</td>\n      <td>6539</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows × 31 columns</p>\n</div>"},"metadata":{}}],"execution_count":129},{"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=1150)\nfeature_names = train.drop(columns=['nforest_type', 'id']).columns\nX = train.drop(columns=['nforest_type', 'id']).to_numpy()\ny = train['nforest_type'].to_numpy()\n\n#Imbalanced\n#X = X_res.to_numpy()\n#y = y_res.to_numpy()\n\n# Normalize\n# X = train_normalized.drop(columns=['nforest_type', 'id']).to_numpy()\n# y = train['nforest_type'].to_numpy()\n\nfor i, (train_idx, val_idx) in enumerate(kf.split(X)):\n    X_train, X_val = X[train_idx], X[val_idx]\n    y_train, y_val = y[train_idx], y[val_idx]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:28:40.451104Z","iopub.execute_input":"2024-06-06T10:28:40.451624Z","iopub.status.idle":"2024-06-06T10:28:40.610361Z","shell.execute_reply.started":"2024-06-06T10:28:40.451588Z","shell.execute_reply":"2024-06-06T10:28:40.609244Z"},"trusted":true},"outputs":[],"execution_count":53},{"cell_type":"code","source":"import optuna\n\ndef optimize_hp(trial):\n    cb_params = {\n        'iterations': 100,\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.1, 1.0),\n        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1, 100),\n        'bagging_temperature': trial.suggest_loguniform('bagging_temperature', 0.1, 20.0),\n        'random_strength': trial.suggest_float('random_strength', 1.0, 2.0),\n        'depth': trial.suggest_int('depth', 1, 10),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 300),\n        \"use_best_model\": True,\n        \"task_type\": \"CPU\",\n        'random_seed': 42\n    }\n    \n    model = CatBoostClassifier(**cb_params)\n    model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=False)\n    y_pred = model.predict(X_val)\n    return f1_score(y_val, y_pred, average='weighted')","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:28:56.684779Z","iopub.execute_input":"2024-06-06T10:28:56.685262Z","iopub.status.idle":"2024-06-06T10:28:56.696524Z","shell.execute_reply.started":"2024-06-06T10:28:56.685228Z","shell.execute_reply":"2024-06-06T10:28:56.694717Z"},"trusted":true},"outputs":[],"execution_count":55},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(optimize_hp, n_trials=50)\nprint('Trials:', len(study.trials))\nprint('Best parameters:', study.best_trial.params)\nprint('Best score:', study.best_value)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:29:06.333438Z","iopub.execute_input":"2024-06-06T10:29:06.333889Z","iopub.status.idle":"2024-06-06T10:59:22.571835Z","shell.execute_reply.started":"2024-06-06T10:29:06.333857Z","shell.execute_reply":"2024-06-06T10:59:22.570648Z"},"trusted":true},"outputs":[{"name":"stderr","text":"[I 2024-06-06 10:29:06,336] A new study created in memory with name: no-name-d83a0f21-f227-425f-8041-bdb209bf1412\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:29:11,032] Trial 0 finished with value: 0.640013828763635 and parameters: {'learning_rate': 0.3055027385164379, 'l2_leaf_reg': 7.326500980492952, 'bagging_temperature': 3.7923307188161255, 'random_strength': 1.5634697795288695, 'depth': 3, 'min_data_in_leaf': 124}. Best is trial 0 with value: 0.640013828763635.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:29:14,347] Trial 1 finished with value: 0.5822518703878917 and parameters: {'learning_rate': 0.16850683524410384, 'l2_leaf_reg': 16.28596827827126, 'bagging_temperature': 0.6753831764748004, 'random_strength': 1.9547230492718728, 'depth': 1, 'min_data_in_leaf': 35}. Best is trial 0 with value: 0.640013828763635.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:29:21,023] Trial 2 finished with value: 0.6304449420030094 and parameters: {'learning_rate': 0.229674819199348, 'l2_leaf_reg': 5.46128018108752, 'bagging_temperature': 12.295269363870878, 'random_strength': 1.1088814388866512, 'depth': 4, 'min_data_in_leaf': 5}. Best is trial 0 with value: 0.640013828763635.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:29:25,802] Trial 3 finished with value: 0.6142324360964274 and parameters: {'learning_rate': 0.18091058018721237, 'l2_leaf_reg': 1.850927253844896, 'bagging_temperature': 5.129935227503742, 'random_strength': 1.5912964883451446, 'depth': 3, 'min_data_in_leaf': 143}. Best is trial 0 with value: 0.640013828763635.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:31:13,313] Trial 4 finished with value: 0.6699595677153896 and parameters: {'learning_rate': 0.26379815723839906, 'l2_leaf_reg': 47.829922653163166, 'bagging_temperature': 0.34481468775936186, 'random_strength': 1.1363246133290397, 'depth': 10, 'min_data_in_leaf': 300}. Best is trial 4 with value: 0.6699595677153896.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:31:17,148] Trial 5 finished with value: 0.6566027915791687 and parameters: {'learning_rate': 0.5443056960931236, 'l2_leaf_reg': 2.3563560318632484, 'bagging_temperature': 0.15172878546292046, 'random_strength': 1.7403648016878328, 'depth': 2, 'min_data_in_leaf': 8}. Best is trial 4 with value: 0.6699595677153896.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:31:21,788] Trial 6 finished with value: 0.6626278353442641 and parameters: {'learning_rate': 0.3506896452588923, 'l2_leaf_reg': 1.9882158512314319, 'bagging_temperature': 0.30704494381428915, 'random_strength': 1.9635915230894625, 'depth': 3, 'min_data_in_leaf': 115}. Best is trial 4 with value: 0.6699595677153896.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:31:30,058] Trial 7 finished with value: 0.6425555800728665 and parameters: {'learning_rate': 0.17005591125802316, 'l2_leaf_reg': 83.0771305938303, 'bagging_temperature': 0.1987353811647738, 'random_strength': 1.2749551806569053, 'depth': 5, 'min_data_in_leaf': 117}. Best is trial 4 with value: 0.6699595677153896.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:31:37,970] Trial 8 finished with value: 0.6444586623130689 and parameters: {'learning_rate': 0.8191498044362083, 'l2_leaf_reg': 4.068857254656285, 'bagging_temperature': 4.270105943496857, 'random_strength': 1.9471196650399751, 'depth': 5, 'min_data_in_leaf': 247}. Best is trial 4 with value: 0.6699595677153896.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:31:45,750] Trial 9 finished with value: 0.6691613793026228 and parameters: {'learning_rate': 0.18977883106309895, 'l2_leaf_reg': 5.248196363599924, 'bagging_temperature': 0.38285202685460873, 'random_strength': 1.120710812709388, 'depth': 5, 'min_data_in_leaf': 252}. Best is trial 4 with value: 0.6699595677153896.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:32:16,359] Trial 10 finished with value: 0.6709214537238489 and parameters: {'learning_rate': 0.43876876286996425, 'l2_leaf_reg': 47.005483998352254, 'bagging_temperature': 1.0451972889678591, 'random_strength': 1.323175939088651, 'depth': 8, 'min_data_in_leaf': 278}. Best is trial 10 with value: 0.6709214537238489.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:34:02,137] Trial 11 finished with value: 0.6698971618255883 and parameters: {'learning_rate': 0.44775289953053815, 'l2_leaf_reg': 45.62717383775999, 'bagging_temperature': 1.0911038776574176, 'random_strength': 1.318216487439755, 'depth': 10, 'min_data_in_leaf': 299}. Best is trial 10 with value: 0.6709214537238489.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:34:57,063] Trial 12 finished with value: 0.6465459971004094 and parameters: {'learning_rate': 0.1221683661005709, 'l2_leaf_reg': 23.74767591648254, 'bagging_temperature': 1.905101257068989, 'random_strength': 1.3015545166105937, 'depth': 9, 'min_data_in_leaf': 300}. Best is trial 10 with value: 0.6709214537238489.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:35:27,602] Trial 13 finished with value: 0.6773706246047366 and parameters: {'learning_rate': 0.6887116209153654, 'l2_leaf_reg': 91.1486995373311, 'bagging_temperature': 0.6423965119638497, 'random_strength': 1.0098125695117552, 'depth': 8, 'min_data_in_leaf': 207}. Best is trial 13 with value: 0.6773706246047366.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:35:45,947] Trial 14 finished with value: 0.6712759509147358 and parameters: {'learning_rate': 0.9799322361723567, 'l2_leaf_reg': 96.57836842992045, 'bagging_temperature': 1.4532721518585965, 'random_strength': 1.017265432586788, 'depth': 7, 'min_data_in_leaf': 200}. Best is trial 13 with value: 0.6773706246047366.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:36:04,014] Trial 15 finished with value: 0.6582272205844985 and parameters: {'learning_rate': 0.9913085087750155, 'l2_leaf_reg': 91.8028543414613, 'bagging_temperature': 2.3347164617373606, 'random_strength': 1.0037375929920094, 'depth': 7, 'min_data_in_leaf': 199}. Best is trial 13 with value: 0.6773706246047366.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:36:22,352] Trial 16 finished with value: 0.6788913149937713 and parameters: {'learning_rate': 0.7010109987367242, 'l2_leaf_reg': 20.306984804677466, 'bagging_temperature': 0.6385669813049922, 'random_strength': 1.0256398371647477, 'depth': 7, 'min_data_in_leaf': 182}. Best is trial 16 with value: 0.6788913149937713.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:36:40,235] Trial 17 finished with value: 0.6710470361205468 and parameters: {'learning_rate': 0.6635877228609585, 'l2_leaf_reg': 16.059791908249185, 'bagging_temperature': 0.10296625569999471, 'random_strength': 1.4423631300857227, 'depth': 7, 'min_data_in_leaf': 181}. Best is trial 16 with value: 0.6788913149937713.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:37:11,307] Trial 18 finished with value: 0.6805940035407191 and parameters: {'learning_rate': 0.5807683776929692, 'l2_leaf_reg': 31.66893671319642, 'bagging_temperature': 0.6241498686991191, 'random_strength': 1.2018666553526902, 'depth': 8, 'min_data_in_leaf': 62}. Best is trial 18 with value: 0.6805940035407191.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:37:23,654] Trial 19 finished with value: 0.675258059967815 and parameters: {'learning_rate': 0.5916579303421422, 'l2_leaf_reg': 25.03909819848378, 'bagging_temperature': 0.5816223538997132, 'random_strength': 1.2026343312740788, 'depth': 6, 'min_data_in_leaf': 64}. Best is trial 18 with value: 0.6805940035407191.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:38:17,888] Trial 20 finished with value: 0.6480697635310886 and parameters: {'learning_rate': 0.436442856012085, 'l2_leaf_reg': 1.0763585451537059, 'bagging_temperature': 9.270396788308807, 'random_strength': 1.47417699377558, 'depth': 9, 'min_data_in_leaf': 83}. Best is trial 18 with value: 0.6805940035407191.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:38:48,027] Trial 21 finished with value: 0.6783935928278125 and parameters: {'learning_rate': 0.7299987616888567, 'l2_leaf_reg': 30.689379093042625, 'bagging_temperature': 0.5893042476357914, 'random_strength': 1.025316925628061, 'depth': 8, 'min_data_in_leaf': 177}. Best is trial 18 with value: 0.6805940035407191.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:39:18,207] Trial 22 finished with value: 0.6688340726089155 and parameters: {'learning_rate': 0.7554615190089063, 'l2_leaf_reg': 12.633785619717505, 'bagging_temperature': 0.8709746554036301, 'random_strength': 1.194339815283747, 'depth': 8, 'min_data_in_leaf': 172}. Best is trial 18 with value: 0.6805940035407191.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:39:29,845] Trial 23 finished with value: 0.670802158452573 and parameters: {'learning_rate': 0.535146614123566, 'l2_leaf_reg': 28.8381584693285, 'bagging_temperature': 0.47693383637458214, 'random_strength': 1.078849257275603, 'depth': 6, 'min_data_in_leaf': 158}. Best is trial 18 with value: 0.6805940035407191.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:40:23,697] Trial 24 finished with value: 0.6868376529949756 and parameters: {'learning_rate': 0.798679363266221, 'l2_leaf_reg': 34.42516632639063, 'bagging_temperature': 0.24426980808169563, 'random_strength': 1.216471582971376, 'depth': 9, 'min_data_in_leaf': 85}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:41:19,406] Trial 25 finished with value: 0.6617713779902851 and parameters: {'learning_rate': 0.8501177534627421, 'l2_leaf_reg': 9.48193950342066, 'bagging_temperature': 0.22338041757818405, 'random_strength': 1.2208084806446096, 'depth': 9, 'min_data_in_leaf': 86}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:43:11,624] Trial 26 finished with value: 0.6774050176316896 and parameters: {'learning_rate': 0.5909842425343768, 'l2_leaf_reg': 38.04214470630886, 'bagging_temperature': 0.10388627767187787, 'random_strength': 1.411290368867019, 'depth': 10, 'min_data_in_leaf': 32}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:43:30,904] Trial 27 finished with value: 0.6860477351040678 and parameters: {'learning_rate': 0.5034130965451761, 'l2_leaf_reg': 18.985855559733242, 'bagging_temperature': 0.2727038322857529, 'random_strength': 1.1722721297238496, 'depth': 7, 'min_data_in_leaf': 68}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:44:29,905] Trial 28 finished with value: 0.6789198558779078 and parameters: {'learning_rate': 0.36850221886526896, 'l2_leaf_reg': 57.77602929975985, 'bagging_temperature': 0.21754552214454478, 'random_strength': 1.3812899153820788, 'depth': 9, 'min_data_in_leaf': 58}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:44:41,402] Trial 29 finished with value: 0.6770885230060378 and parameters: {'learning_rate': 0.4839922538819483, 'l2_leaf_reg': 12.45564767125844, 'bagging_temperature': 0.1519651639021329, 'random_strength': 1.5448318080156749, 'depth': 6, 'min_data_in_leaf': 100}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:45:13,146] Trial 30 finished with value: 0.6774812367751952 and parameters: {'learning_rate': 0.31571547213787676, 'l2_leaf_reg': 8.601803833909692, 'bagging_temperature': 0.2992265564902746, 'random_strength': 1.629780669566745, 'depth': 8, 'min_data_in_leaf': 56}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:46:11,337] Trial 31 finished with value: 0.6726613438485745 and parameters: {'learning_rate': 0.3693002748951284, 'l2_leaf_reg': 63.8035738117868, 'bagging_temperature': 0.23539407822328318, 'random_strength': 1.3810558177373262, 'depth': 9, 'min_data_in_leaf': 59}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:47:19,051] Trial 32 finished with value: 0.6743212686662521 and parameters: {'learning_rate': 0.37544225973407147, 'l2_leaf_reg': 61.59200079930126, 'bagging_temperature': 0.1502396740699602, 'random_strength': 1.2219728083377346, 'depth': 9, 'min_data_in_leaf': 35}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:49:17,080] Trial 33 finished with value: 0.6656244352656319 and parameters: {'learning_rate': 0.26199746832768256, 'l2_leaf_reg': 35.757811351772865, 'bagging_temperature': 0.4405516075004528, 'random_strength': 1.383218402368402, 'depth': 10, 'min_data_in_leaf': 87}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:49:49,260] Trial 34 finished with value: 0.6765315010057811 and parameters: {'learning_rate': 0.5160447074503347, 'l2_leaf_reg': 16.754152321152517, 'bagging_temperature': 0.26204947582645355, 'random_strength': 1.1601577812871533, 'depth': 8, 'min_data_in_leaf': 29}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:50:07,481] Trial 35 finished with value: 0.6750766172953236 and parameters: {'learning_rate': 0.6386519506057984, 'l2_leaf_reg': 61.97026941419957, 'bagging_temperature': 0.1846030407371137, 'random_strength': 1.261829838564912, 'depth': 7, 'min_data_in_leaf': 130}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:51:03,527] Trial 36 finished with value: 0.6755292095526397 and parameters: {'learning_rate': 0.40636486948102274, 'l2_leaf_reg': 18.34110422878281, 'bagging_temperature': 0.4028684048416552, 'random_strength': 1.3470071386187814, 'depth': 9, 'min_data_in_leaf': 72}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:52:50,934] Trial 37 finished with value: 0.671887351578024 and parameters: {'learning_rate': 0.29307810135338513, 'l2_leaf_reg': 39.323726021299166, 'bagging_temperature': 0.13563258181672963, 'random_strength': 1.0749204005317106, 'depth': 10, 'min_data_in_leaf': 47}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:52:54,660] Trial 38 finished with value: 0.631002955286549 and parameters: {'learning_rate': 0.8520790656133833, 'l2_leaf_reg': 30.090986538056114, 'bagging_temperature': 0.31309174164186004, 'random_strength': 1.1544370736986322, 'depth': 1, 'min_data_in_leaf': 8}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:53:25,276] Trial 39 finished with value: 0.6771717314694372 and parameters: {'learning_rate': 0.6011515737209097, 'l2_leaf_reg': 69.30864644373789, 'bagging_temperature': 0.8214324990372978, 'random_strength': 1.2377137249578505, 'depth': 8, 'min_data_in_leaf': 19}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:53:37,171] Trial 40 finished with value: 0.6587716996888764 and parameters: {'learning_rate': 0.47424150882570043, 'l2_leaf_reg': 12.530477317356793, 'bagging_temperature': 17.21299711259139, 'random_strength': 1.6569474384659681, 'depth': 6, 'min_data_in_leaf': 105}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:53:55,125] Trial 41 finished with value: 0.6672705506138913 and parameters: {'learning_rate': 0.7471090347083474, 'l2_leaf_reg': 22.704275769727445, 'bagging_temperature': 0.5151347868042916, 'random_strength': 1.0858406946999593, 'depth': 7, 'min_data_in_leaf': 134}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:54:01,038] Trial 42 finished with value: 0.6618458681934618 and parameters: {'learning_rate': 0.5365776595140033, 'l2_leaf_reg': 18.537330163131877, 'bagging_temperature': 0.7829117549916982, 'random_strength': 1.1655811376996479, 'depth': 4, 'min_data_in_leaf': 151}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:54:18,996] Trial 43 finished with value: 0.6673569756582993 and parameters: {'learning_rate': 0.8663992172074808, 'l2_leaf_reg': 51.41669412910377, 'bagging_temperature': 0.35494183086206144, 'random_strength': 1.2769794971068091, 'depth': 7, 'min_data_in_leaf': 45}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:55:13,408] Trial 44 finished with value: 0.679366678541731 and parameters: {'learning_rate': 0.4130733757726312, 'l2_leaf_reg': 22.10522057805927, 'bagging_temperature': 0.19307447968199645, 'random_strength': 1.1120370624487617, 'depth': 9, 'min_data_in_leaf': 77}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:56:07,668] Trial 45 finished with value: 0.6797197642619024 and parameters: {'learning_rate': 0.33693274407388557, 'l2_leaf_reg': 32.60105160008083, 'bagging_temperature': 0.21389028320136896, 'random_strength': 1.8490877583387924, 'depth': 9, 'min_data_in_leaf': 75}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:57:50,778] Trial 46 finished with value: 0.673859630353727 and parameters: {'learning_rate': 0.2743067009034292, 'l2_leaf_reg': 14.49820996855891, 'bagging_temperature': 0.1754035969429395, 'random_strength': 1.892643220307043, 'depth': 10, 'min_data_in_leaf': 102}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:58:21,232] Trial 47 finished with value: 0.680565450857089 and parameters: {'learning_rate': 0.23635579851954314, 'l2_leaf_reg': 6.6047890436130015, 'bagging_temperature': 0.12389949865884903, 'random_strength': 1.9093510746464974, 'depth': 8, 'min_data_in_leaf': 77}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:58:51,810] Trial 48 finished with value: 0.6665127482993555 and parameters: {'learning_rate': 0.24468314521511111, 'l2_leaf_reg': 4.77145247178759, 'bagging_temperature': 0.12449907762000373, 'random_strength': 1.8112910778563645, 'depth': 8, 'min_data_in_leaf': 116}. Best is trial 24 with value: 0.6868376529949756.\n/tmp/ipykernel_33/1825468385.py:6: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:7: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n/tmp/ipykernel_33/1825468385.py:8: FutureWarning:\n\nsuggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n\n[I 2024-06-06 10:59:22,555] Trial 49 finished with value: 0.6784964446276778 and parameters: {'learning_rate': 0.21841776228594073, 'l2_leaf_reg': 3.555028763233495, 'bagging_temperature': 0.28375778081866687, 'random_strength': 1.9949151700366072, 'depth': 8, 'min_data_in_leaf': 93}. Best is trial 24 with value: 0.6868376529949756.\n","output_type":"stream"},{"name":"stdout","text":"Trials: 50\nBest parameters: {'learning_rate': 0.798679363266221, 'l2_leaf_reg': 34.42516632639063, 'bagging_temperature': 0.24426980808169563, 'random_strength': 1.216471582971376, 'depth': 9, 'min_data_in_leaf': 85}\nBest score: 0.6868376529949756\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"# params = {\n#     'learning_rate': 0.21013650167871153,\n#     'l2_leaf_reg': 3.2043883814749985,\n#     'bagging_temperature': 0.40261597011996586,\n#     'random_strength': 1.923342236523092,\n#     'depth': 8,\n#     'min_data_in_leaf': 56,\n#     'loss_function': 'MultiClass',\n#     'objective': 'MultiClass',\n#     'boosting_type' : 'Plain',\n#     'bootstrap_type' : 'MVS',\n#     'random_seed' : 99\n# }\n\n\n# params = {\n#     'learning_rate': 0.26699263525621014,\n#     'l2_leaf_reg': 17.157839998796707,\n#     'bagging_temperature': 0.22871053476831218,\n#     'random_strength': 1.815833226315431,\n#     'depth': 7,\n#      'min_data_in_leaf': 268,\n#     'loss_function': 'MultiClass',\n#     'objective': 'MultiClass',\n#     'boosting_type' : 'Plain',\n#     'bootstrap_type' : 'MVS',\n#     'random_seed' : 1150\n# }\n\nparams = {'learning_rate': 0.2523244427996981, \n          'l2_leaf_reg': 1.1882301020799804, \n          'bagging_temperature': 0.19479371564457265, \n          'random_strength': 1.365501267771134, \n          'depth': 9, \n          'min_data_in_leaf': 178,\n        'loss_function': 'MultiClass',\n        'objective': 'MultiClass',\n        'boosting_type' : 'Plain',\n        'bootstrap_type' : 'MVS',\n        'random_seed' : 1150\n          \n         }","metadata":{"execution":{"iopub.status.busy":"2024-06-06T06:52:52.388328Z","iopub.execute_input":"2024-06-06T06:52:52.389302Z","iopub.status.idle":"2024-06-06T06:52:52.395169Z","shell.execute_reply.started":"2024-06-06T06:52:52.389267Z","shell.execute_reply":"2024-06-06T06:52:52.394162Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"y_test_proba = []\naccuracies = []\nconf_matrices = []\n\n\n# K-fold cross-validation\nfor i, (train_idx, val_idx) in enumerate(kf.split(X)):\n    X_train, X_val = X[train_idx], X[val_idx]\n    y_train, y_val = y[train_idx], y[val_idx]\n\n    model = CatBoostClassifier(**params)\n    model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True, verbose=False, early_stopping_rounds=100)\n\n    y_pred = model.predict(X_val)\n    y_pred_proba = model.predict_proba(X_val)\n    accuracy = accuracy_score(y_val, y_pred)\n    accuracies.append(accuracy)\n    print(f\"CV{i+1}: {accuracy:.4f}\")\n\n    cm = confusion_matrix(y_val, y_pred)\n    conf_matrices.append(cm)\n    print(f\"Confusion Matrix for CV{i+1}:\\n{cm}\")\n\n    y_test_proba.append(y_pred_proba)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:22:11.753458Z","iopub.execute_input":"2024-06-06T08:22:11.753905Z","iopub.status.idle":"2024-06-06T08:22:11.836556Z","shell.execute_reply.started":"2024-06-06T08:22:11.753872Z","shell.execute_reply":"2024-06-06T08:22:11.834985Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m X_train, X_val \u001b[38;5;241m=\u001b[39m X[train_idx], X[val_idx]\n\u001b[1;32m      9\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m y[train_idx], y[val_idx]\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mparams\u001b[49m)\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, eval_set\u001b[38;5;241m=\u001b[39m(X_val, y_val), use_best_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     14\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n","\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"],"ename":"NameError","evalue":"name 'params' is not defined","output_type":"error"}],"execution_count":28},{"cell_type":"code","source":"y_test_proba = []\naccuracies = []\nconf_matrices = []\naccuracy =[]\n\n# K-fold cross-validation\nfor i, (train_idx, val_idx) in enumerate(kf.split(X)):\n    X_train, X_val = X[train_idx], X[val_idx]\n    y_train, y_val = y[train_idx], y[val_idx]\n\n    model = CatBoostClassifier(**study.best_trial.params)\n    model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True, verbose=False, early_stopping_rounds=100)\n\n    y_pred = model.predict(X_val)\n    y_pred_proba = model.predict_proba(X_val)\n    accuracy = accuracy_score(y_val, y_pred)\n    accuracies.append(accuracy)\n    print(f\"CV{i+1}: {accuracy:.4f}\")\n\n    cm = confusion_matrix(y_val, y_pred)\n    conf_matrices.append(cm)\n    print(f\"Confusion Matrix for CV{i+1}:\\n{cm}\")\n\n    y_test_proba.append(y_pred_proba)\n    \nmax_accuracy_index = accuracies.index(max(accuracies))\nmax_accuracy = max(accuracies)\n\nprint(f\"Highest Accuracy: {max_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:01:01.187687Z","iopub.execute_input":"2024-06-06T11:01:01.188787Z","iopub.status.idle":"2024-06-06T11:14:31.167778Z","shell.execute_reply.started":"2024-06-06T11:01:01.188751Z","shell.execute_reply":"2024-06-06T11:14:31.166660Z"},"trusted":true},"outputs":[{"name":"stdout","text":"CV1: 0.6626\nConfusion Matrix for CV1:\n[[540  40 338]\n [ 55 371  93]\n [275  80 819]]\nCV2: 0.7036\nConfusion Matrix for CV2:\n[[600  32 268]\n [ 56 351  99]\n [264  55 886]]\nCV3: 0.6829\nConfusion Matrix for CV3:\n[[557  54 319]\n [ 42 381 107]\n [248  58 845]]\nCV4: 0.6816\nConfusion Matrix for CV4:\n[[593  31 304]\n [ 63 343 108]\n [267  58 843]]\nCV5: 0.6877\nConfusion Matrix for CV5:\n[[589  44 294]\n [ 52 367  97]\n [253  75 839]]\nHighest Accuracy: 0.7036\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"feature_importance = np.array(model.get_feature_importance())\nfeatures = np.array(feature_names)\nfi={'features':features,'feature_importance':feature_importance}\ndf_fi = pd.DataFrame(fi)\ndf_fi.sort_values(by=['feature_importance'], ascending=True,inplace=True)\nfig = px.bar(df_fi, x='feature_importance', y='features',title=\"CatBoost Feature Importance\",height=800)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:14:31.169600Z","iopub.execute_input":"2024-06-06T11:14:31.169935Z","iopub.status.idle":"2024-06-06T11:14:31.261427Z","shell.execute_reply.started":"2024-06-06T11:14:31.169906Z","shell.execute_reply":"2024-06-06T11:14:31.260291Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"79a42c45-7634-40b1-8e76-faf5eff2a3e4\" class=\"plotly-graph-div\" style=\"height:800px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"79a42c45-7634-40b1-8e76-faf5eff2a3e4\")) {                    Plotly.newPlot(                        \"79a42c45-7634-40b1-8e76-faf5eff2a3e4\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"feature_importance=%{x}\\u003cbr\\u003efeatures=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.000655966209263574,0.000942716244810508,0.0010163063626819767,0.002694292800855511,0.0057617718403787654,0.005875050636129155,0.007284663465894023,0.020621478327882033,0.022675006779624134,0.02298083520492532,0.03052448551102061,0.035459525859880894,0.03647182644847056,0.038537542976747295,0.040280989786347185,0.0406364414487976,0.04270844488666212,0.04382700458263755,0.044539669584337034,0.045789352041221906,0.04800294591024812,0.06330090107838506,0.06550719704270544,0.06712178969548376,0.06738853204353154,0.07703605415736614,0.07846896029883517,0.08097503195792569,0.08165417781030346,0.08601249945037534,0.08704891456287413,0.09005345358608892,0.09148721792183546,0.09297693056430055,0.09625061137301107,0.09841659208056329,0.10173372475622659,0.1042664045889165,0.1046730915162044,0.10683340656265122,0.10950395152029471,0.11441658120554245,0.11529704043501142,0.11538345322622048,0.11959673881081914,0.12054826101035115,0.12173404898163208,0.12237389155017925,0.1267985707739375,0.12711842909342166,0.1274928543166026,0.13769320128069673,0.13983389860701398,0.14349130799628088,0.14667051389992106,0.14759693755479478,0.1523304968043373,0.1567278748414578,0.156872244566914,0.16116554046831305,0.16726039678381763,0.16886857762729193,0.17589045221348235,0.1766626504030392,0.18230847651117485,0.18448607666573433,0.18875923127090288,0.19488850854138498,0.20355132943644805,0.20683032936308432,0.2078193107243229,0.21863210363675853,0.2300035146336712,0.2321954670060558,0.2562722166956933,0.26245525246660045,0.26502771132882247,0.2725256714287719,0.27530905721729554,0.27819068149676107,0.28710830247248326,0.2943114753226713,0.3137507357778531,0.31920107262460073,0.33175141737113895,0.3345387495490038,0.33930312874300506,0.34327461333444187,0.3445088264534261,0.34593366813238235,0.3546873971262658,0.356753663879569,0.37061858618869886,0.372043715339195,0.39078291582596764,0.3974612003614577,0.4038516325353523,0.40934223067432707,0.41325369014215085,0.41437384033359465,0.4157029481545351,0.41894882147356044,0.4434637649031087,0.4455892535472416,0.46566420340993303,0.46587685364946363,0.46627598290993605,0.47162385092266124,0.5018284219377659,0.5132107568156556,0.5164751850733861,0.5603115148613493,0.5721803491926033,0.5937769653009685,0.607001267951286,0.6216486020564906,0.6299741313390479,0.630492213363286,0.6334785285705941,0.6399521624989848,0.685781627605103,0.6990733460598795,0.70079067666959,0.7389004641170873,0.745472936551947,0.7475698257931219,0.8512069669673381,0.8641737662217336,0.8734803588724591,0.886989480052853,0.901581225304192,0.9281534525287158,0.9429427940926061,0.9450114390673722,1.0006833390366643,1.0707532490858815,1.131278798817859,1.1849848615550838,1.198578812065077,1.2244484462964171,1.228299406839163,1.2752325367235113,1.2816276628397156,1.3226221579737516,1.372668067682043,1.452544626537797,1.457245570097611,1.5131611292636524,1.520969875199371,1.6588951574446944,1.7913402266144607,1.8096115381213733,1.8317194353545494,2.004033189930598,2.0531505216015784,2.5809392449333686,2.618408404591585,2.705630221862317,2.987543753492585,3.2345009368983906,3.444963166027664,4.022646060679775,4.445240266391737,5.125749675666966],\"xaxis\":\"x\",\"y\":[\"nd800\\u002f680\",\"gndvihyper2\",\"nd800\\u002f2170\",\"nd790\\u002f670\",\"gndvihyper\",\"norm nir\",\"sr833\\u002f658\",\"nli\",\"msavihyper\",\"msrnir\\u002fred\",\"datt2\",\"grvi\",\"srnir\\u002fmir\",\"rri1\",\"logr\",\"lwci\",\"ipvi\",\"ivi\",\"srred\\u002fnir\",\"sb2240\",\"epi\",\"dvimss\",\"psndb1\",\"psnda1\",\"nd833\\u002f658\",\"ngrdi\",\"sr675\\u002f555\",\"gi\",\"dswi-4\",\"sr550\\u002f670\",\"sr774\\u002f677\",\"pssrc2\",\"sr800\\u002f550\",\"pssrb1\",\"rsr\",\"rvi\",\"d800\\u002f680\",\"pssra1\",\"rededge2\",\"rededge1\",\"rdvi2\",\"rarSc4\",\"rarSa4\",\"rarSa2\",\"osavi\",\"ndvic\",\"ndre\",\"bndvi\",\"sr800\\u002f680\",\"d800\\u002f550\",\"sr700\\u002f670\",\"sb655\",\"arvi2\",\"rdvi\",\"msavi\",\"ndvi\",\"cigreen\",\"sr495\",\"sb675\",\"sb660\",\"afri1600\",\"savi3\",\"savi2\",\"sb555\",\"sqrt(ir\\u002fr)\",\"cari2\",\"ctvi\",\"wdvi\",\"sb550\",\"pndvi\",\"nd782\\u002f666\",\"sb703\",\"rarSa3\",\"sr675\\u002f705\",\"sarvi\",\"sb850\",\"evi2\",\"ir550\",\"sr674\\u002f553\",\"mtvi1\",\"tvi\",\"rgr\",\"nbr\",\"rbndvi\",\"srswiri\\u002fnir\",\"mtvi2\",\"sb670\",\"io\",\"ndii\",\"lci\",\"savimir\",\"i\",\"sr710\\u002f670\",\"ir700\",\"gosavi\",\"ndvi690-710\",\"slavi\",\"arvi\",\"sb2250\",\"ndii2\",\"datt4\",\"d833\\u002f658\",\"siwsi\",\"cri550\",\"norm r\",\"nd827\\u002f668\",\"sbl\",\"sr675\\u002f700\",\"nd833\\u002f1649\",\"ndwi\",\"mcari\\u002fmtvi2\",\"gemi\",\"cvi\",\"rarSa1\",\"sr801\\u002f670\",\"dvi\",\"b4\",\"nd774\\u002f677\",\"gndvi\",\"wdrvi\",\"bwdrvi\",\"sr833\\u002f1649\",\"psndc2\",\"cirededge\",\"sr672\\u002f708\",\"pbi\",\"sb2280\",\"b3\",\"mcari2\",\"pvi\",\"sr560\\u002f658\",\"sr550\\u002f800\",\"gvmi\",\"gbndvi\",\"gsavi\",\"mndvi\",\"ngrdri\",\"avi\",\"reip3\",\"mcari\",\"savi\",\"sb705\",\"sb801\",\"ri\",\"bb3\",\"mcari\\u002fosavi\",\"sr700\",\"b8\",\"msi\",\"b2\",\"cari\",\"atsavi\",\"sr801\\u002f550\",\"sr672\\u002f550\",\"gdvi\",\"sb2130\",\"rdi\",\"bb1\",\"mcari1\",\"afri2100\",\"sb460\",\"datt6\",\"nd895\\u002f675\",\"sr440\\u002f740\",\"mgvi\",\"sb2180\",\"gvimss\",\"alteration\",\"mari\",\"sr520\\u002f670\",\"grndvi\",\"sr860\\u002f550\",\"sb700\",\"sarvi2\",\"norm g\",\"msbi\",\"cri700\",\"sipi1\",\"gari\",\"h\",\"ci\",\"reip2\",\"sipi3\",\"b7\",\"fe3+\",\"sb2270\",\"sr860\\u002f708\",\"bri\",\"sb2218\",\"myvi\",\"pvr\",\"psndc1\",\"ppr\",\"srnir\\u002f700-715\",\"chlred-edge\",\"tci\",\"mnsi\",\"b1\",\"chlgreen\",\"ari\",\"reip1\",\"sr800\\u002f2170\",\"bgi\",\"sb885\",\"sbi\",\"evi\",\"mcrig\",\"msi2\",\"sr735\\u002f710\",\"msr\",\"mcrire\",\"srmir\\u002fred\",\"b6\",\"sb735\",\"b5\",\"rre\",\"d678\\u002f500\",\"rep\",\"b12\",\"mnd680\",\"ndsi\",\"tm5\\u002ftm7\",\"ndmi\",\"sb1580\",\"gli\",\"ccci\",\"datt1\",\"fe2+\",\"b11\",\"sb2100\",\"b8_a\",\"b9\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"feature_importance\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"features\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"CatBoost Feature Importance\"},\"barmode\":\"relative\",\"height\":800},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('79a42c45-7634-40b1-8e76-faf5eff2a3e4');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"df_fi_sort = df_fi.sort_values(by='feature_importance', ascending=False)\ndf_fi_sort_50 = df_fi_sort.head(50)\ndf_fi_sort_50['features']\n#df_fi_sort.to_csv('fi.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:14:31.262572Z","iopub.execute_input":"2024-06-06T11:14:31.262903Z","iopub.status.idle":"2024-06-06T11:14:31.274050Z","shell.execute_reply.started":"2024-06-06T11:14:31.262875Z","shell.execute_reply":"2024-06-06T11:14:31.272595Z"},"trusted":true},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"11                b9\n10              b8_a\n196           sb2100\n1                b11\n61              fe2+\n50             datt1\n22              ccci\n66               gli\n195           sb1580\n30              ndmi\n149          tm5/tm7\n28              ndsi\n88            mnd680\n2                b12\n143              rep\n53          d678/500\n145              rre\n6                 b5\n217            sb735\n7                 b6\n185        srmir/red\n83            mcrire\n94               msr\n167        sr735/710\n147             msi2\n82             mcrig\n13               evi\n230              sbi\n220            sb885\n151              bgi\n169       sr800/2170\n140            reip1\n21               ari\n41          chlgreen\n0                 b1\n85              mnsi\n20               tci\n44       chlred-edge\n186    srnir/700-715\n103              ppr\n111           psndc1\n104              pvr\n87              myvi\n199           sb2218\n38               bri\n183        sr860/708\n202           sb2270\n62              fe3+\n8                 b7\n229            sipi3\nName: features, dtype: object"},"metadata":{}}],"execution_count":60},{"cell_type":"markdown","source":"## Submition","metadata":{}},{"cell_type":"code","source":"test = test.drop(columns=['id'])\ny_test_pred = model.predict(test)\ndf_y_test = pd.DataFrame(y_test_pred)\ndf_y_test = df_y_test.rename(columns={0: 'nforest_type'})\ndf_y_test","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:14:31.276420Z","iopub.execute_input":"2024-06-06T11:14:31.276795Z","iopub.status.idle":"2024-06-06T11:14:31.328287Z","shell.execute_reply.started":"2024-06-06T11:14:31.276753Z","shell.execute_reply":"2024-06-06T11:14:31.327221Z"},"trusted":true},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"     nforest_type\n0             DEF\n1             MDF\n2             MDF\n3             DDF\n4             DEF\n...           ...\n3995          DEF\n3996          MDF\n3997          DEF\n3998          MDF\n3999          DEF\n\n[4000 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nforest_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DEF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DDF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DEF</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>DEF</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>DEF</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>DEF</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows × 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"sample_submission['nforest_type'] = df_y_test['nforest_type']\nsample_submission['nforest_type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:14:31.329779Z","iopub.execute_input":"2024-06-06T11:14:31.330239Z","iopub.status.idle":"2024-06-06T11:14:31.340433Z","shell.execute_reply.started":"2024-06-06T11:14:31.330202Z","shell.execute_reply":"2024-06-06T11:14:31.339439Z"},"trusted":true},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"nforest_type\nMDF    1721\nDDF    1409\nDEF     870\nName: count, dtype: int64"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"sample_submission.to_csv('catboost+optuna+featureeng(tong)+sed(1150).csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:30:41.233438Z","iopub.status.idle":"2024-06-06T08:30:41.233829Z","shell.execute_reply.started":"2024-06-06T08:30:41.233629Z","shell.execute_reply":"2024-06-06T08:30:41.233644Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Pytorch","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, random_split, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-06-06T10:59:22.573681Z","iopub.execute_input":"2024-06-06T10:59:22.573992Z","iopub.status.idle":"2024-06-06T10:59:25.931682Z","shell.execute_reply.started":"2024-06-06T10:59:22.573964Z","shell.execute_reply":"2024-06-06T10:59:25.930540Z"},"trusted":true},"outputs":[],"execution_count":57},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = torch.from_numpy(train).type(torch.float).to(device)\ny = torch.from_numpy(train['nforresttype']).type(torch.float).to(device)\n\nprint(X.shape)\nprint(y.shape)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine them into a TensorDataset\ndataset = TensorDataset(X, y)\n\n# Calculate the lengths of each split\ntrain_length = int(0.6 * len(dataset))\nvalidation_length = int(0.2 * len(dataset))\ntest_length = len(dataset) - train_length - validation_length\n\n# Split the dataset\ntrain_dataset, validation_dataset, test_dataset = random_split(\n                                                dataset,\n                                                [train_length, validation_length, test_length]\n                                                )\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\nX_val, y_yal = validation_dataset[:]\nX_test, y_test = test_dataset[:]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(1)\ntorch.cuda.manual_seed(1)\n\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2, out_features=8),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=8, out_features = N_CLASSES),\n).to(device)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model(X_val)[:5]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.softmax(model(X_val)[:5], dim=1)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.softmax(model(X_val)[:5], dim=1).argmax(dim=1)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n_epochs =100\n\noptimizer = torch.optim.AdamW(model.parameters(), lr= 0.001)\nloss_fn = torch.nn.CrossEntropyLoss()\n\ntraining_parameters = []\nfor epoch in range(n_epochs):\n    model.train()\n    batch_losses = []\n    for X_batch, y_batch in train_loader:\n        y_logits = model(X_batch)\n        loss = loss_fn(y_logits, y_batch.type(torch.LongTensor).squeeze().to(device))\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        batch_losses.append(loss.item())\n    avg_batch_losses = np.mean(batch_losses)\n    \n    #testing\n    model.eval()\n    with torch.inference_mode():\n        y_logits_val = model(X_val)\n        loss_val = loss_fn\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## TabPFN","metadata":{}},{"cell_type":"code","source":"!pip install tabpfn[Full]","metadata":{"execution":{"iopub.status.busy":"2024-06-04T08:06:19.327857Z","iopub.execute_input":"2024-06-04T08:06:19.328519Z","iopub.status.idle":"2024-06-04T08:06:21.824570Z","shell.execute_reply.started":"2024-06-04T08:06:19.328475Z","shell.execute_reply":"2024-06-04T08:06:21.822396Z"},"trusted":true},"outputs":[{"name":"stdout","text":"^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":137},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\n\nfrom tabpfn import TabPFNClassifier\n\nX = train.drop(columns=['nforest_type', 'id']).to_numpy()\ny = train['nforest_type'].to_numpy()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n# N_ensemble_configurations controls the number of model predictions that are ensembled with feature and class rotations (See our work for details).\n# When N_ensemble_configurations > #features * #classes, no further averaging is applied.\n\nclassifier = TabPFNClassifier(device='cpu', N_ensemble_configurations=32)\n\nclassifier.fit(X_train, y_train)\ny_eval, p_eval = classifier.predict(X_test, return_winning_probability=True)\n\nprint('Accuracy', accuracy_score(y_test, y_eval))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T07:51:48.449922Z","iopub.execute_input":"2024-06-04T07:51:48.450473Z","iopub.status.idle":"2024-06-04T07:51:57.039235Z","shell.execute_reply.started":"2024-06-04T07:51:48.450433Z","shell.execute_reply":"2024-06-04T07:51:57.037170Z"},"trusted":true},"outputs":[{"name":"stdout","text":"We have to download the TabPFN, as there is no checkpoint at  /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/prior_diff_real_checkpoint_n_0_epoch_100.cpkt\nIt has about 100MB, so this might take a moment.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[135], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# N_ensemble_configurations controls the number of model predictions that are ensembled with feature and class rotations (See our work for details).\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# When N_ensemble_configurations > #features * #classes, no further averaging is applied.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m classifier \u001b[38;5;241m=\u001b[39m TabPFNClassifier(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, N_ensemble_configurations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m y_eval, p_eval \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(X_test, return_winning_probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, accuracy_score(y_test, y_eval))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tabpfn/scripts/transformer_prediction_interface.py:239\u001b[0m, in \u001b[0;36mTabPFNClassifier.fit\u001b[0;34m(self, X, y, overwrite_warning)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of classes for this classifier is restricted to \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_num_classes)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite_warning:\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ WARNING: TabPFN is not made for datasets with a trainingsize > 1024. Prediction might take a while, be less reliable. We advise not to run datasets > 10k samples, which might lead to your machine crashing (due to quadratic memory scaling of TabPFN). Please confirm you want to run by passing overwrite_warning=True to the fit function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Return the classifier\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","\u001b[0;31mValueError\u001b[0m: ⚠️ WARNING: TabPFN is not made for datasets with a trainingsize > 1024. Prediction might take a while, be less reliable. We advise not to run datasets > 10k samples, which might lead to your machine crashing (due to quadratic memory scaling of TabPFN). Please confirm you want to run by passing overwrite_warning=True to the fit function."],"ename":"ValueError","evalue":"⚠️ WARNING: TabPFN is not made for datasets with a trainingsize > 1024. Prediction might take a while, be less reliable. We advise not to run datasets > 10k samples, which might lead to your machine crashing (due to quadratic memory scaling of TabPFN). Please confirm you want to run by passing overwrite_warning=True to the fit function.","output_type":"error"}],"execution_count":135},{"cell_type":"markdown","source":"## CAAFE","metadata":{}},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2024-06-03T17:54:11.008525Z","iopub.execute_input":"2024-06-03T17:54:11.009038Z","iopub.status.idle":"2024-06-03T17:54:11.056034Z","shell.execute_reply.started":"2024-06-03T17:54:11.008999Z","shell.execute_reply":"2024-06-03T17:54:11.054812Z"},"trusted":true},"outputs":[],"execution_count":226},{"cell_type":"code","source":"!pip install caafe","metadata":{"execution":{"iopub.status.busy":"2024-06-03T17:54:13.400833Z","iopub.execute_input":"2024-06-03T17:54:13.401467Z","iopub.status.idle":"2024-06-03T17:54:34.596044Z","shell.execute_reply.started":"2024-06-03T17:54:13.401432Z","shell.execute_reply":"2024-06-03T17:54:34.594565Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting caafe\n  Downloading caafe-0.1.6-py3-none-any.whl.metadata (7.1 kB)\nCollecting openai (from caafe)\n  Downloading openai-1.30.5-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: kaggle in /opt/conda/lib/python3.10/site-packages (from caafe) (1.6.14)\nCollecting openml==0.12.0 (from caafe)\n  Downloading openml-0.12.0.tar.gz (116 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.1/116.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting tabpfn (from caafe)\n  Downloading tabpfn-0.1.10-py3-none-any.whl.metadata (5.6 kB)\nCollecting liac-arff>=2.4.0 (from openml==0.12.0->caafe)\n  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting xmltodict (from openml==0.12.0->caafe)\n  Downloading xmltodict-0.13.0-py2.py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from openml==0.12.0->caafe) (2.31.0)\nRequirement already satisfied: scikit-learn>=0.18 in /opt/conda/lib/python3.10/site-packages (from openml==0.12.0->caafe) (1.2.2)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from openml==0.12.0->caafe) (2.9.0.post0)\nRequirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from openml==0.12.0->caafe) (2.2.2)\nRequirement already satisfied: scipy>=0.13.3 in /opt/conda/lib/python3.10/site-packages (from openml==0.12.0->caafe) (1.11.4)\nRequirement already satisfied: numpy>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from openml==0.12.0->caafe) (1.26.4)\nCollecting minio (from openml==0.12.0->caafe)\n  Downloading minio-7.2.7-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from openml==0.12.0->caafe) (16.1.0)\nRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle->caafe) (1.16.0)\nRequirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.10/site-packages (from kaggle->caafe) (2024.2.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle->caafe) (4.66.4)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle->caafe) (8.0.4)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle->caafe) (1.26.18)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle->caafe) (6.1.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai->caafe) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai->caafe) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai->caafe) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai->caafe) (2.5.3)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai->caafe) (1.3.0)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai->caafe) (4.9.0)\nRequirement already satisfied: pyyaml>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from tabpfn->caafe) (6.0.1)\nRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from tabpfn->caafe) (2.1.2+cpu)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->caafe) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->caafe) (1.2.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->caafe) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->caafe) (0.14.0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->openml==0.12.0->caafe) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->openml==0.12.0->caafe) (2023.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->caafe) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai->caafe) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->openml==0.12.0->caafe) (3.3.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.18->openml==0.12.0->caafe) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.18->openml==0.12.0->caafe) (3.2.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn->caafe) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn->caafe) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn->caafe) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn->caafe) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn->caafe) (2024.3.1)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle->caafe) (0.5.1)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from minio->openml==0.12.0->caafe) (23.1.0)\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from minio->openml==0.12.0->caafe) (3.20.0)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle->caafe) (1.3)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->minio->openml==0.12.0->caafe) (21.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->tabpfn->caafe) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->tabpfn->caafe) (1.3.0)\nRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml==0.12.0->caafe) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml==0.12.0->caafe) (2.21)\nDownloading caafe-0.1.6-py3-none-any.whl (23 kB)\nDownloading openai-1.30.5-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tabpfn-0.1.10-py3-none-any.whl (156 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.6/156.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading minio-7.2.7-py3-none-any.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\nBuilding wheels for collected packages: openml, liac-arff\n  Building wheel for openml (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openml: filename=openml-0.12.0-py3-none-any.whl size=132448 sha256=b261ca0346242d9af40a2771a1b6af3b69e209e71d58bb3394efbf63687d1fc3\n  Stored in directory: /root/.cache/pip/wheels/12/e6/70/524ba51f9a88c468256ccea4c242eb0dea9def83c13c0389d3\n  Building wheel for liac-arff (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11716 sha256=b85cca3df94caac9aaad7b500ce5d8173635964e2c3810d0d9a9773a3551aebd\n  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\nSuccessfully built openml liac-arff\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: xmltodict, liac-arff, tabpfn, openai, minio, openml, caafe\nSuccessfully installed caafe-0.1.6 liac-arff-2.5.0 minio-7.2.7 openai-1.30.5 openml-0.12.0 tabpfn-0.1.10 xmltodict-0.13.0\n","output_type":"stream"}],"execution_count":227},{"cell_type":"code","source":"!pip install google-generativeai","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:03:50.248967Z","iopub.execute_input":"2024-06-03T18:03:50.249400Z","iopub.status.idle":"2024-06-03T18:04:03.103126Z","shell.execute_reply.started":"2024-06-03T18:03:50.249354Z","shell.execute_reply":"2024-06-03T18:04:03.101696Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-generativeai in /opt/conda/lib/python3.10/site-packages (0.5.4)\nRequirement already satisfied: google-ai-generativelanguage==0.6.4 in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (0.6.4)\nRequirement already satisfied: google-api-core in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.11.1)\nRequirement already satisfied: google-api-python-client in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.131.0)\nRequirement already satisfied: google-auth>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.26.1)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.5.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (4.66.4)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (4.9.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai) (1.23.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.62.0)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.31.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.21.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (3.0.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.14.6)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai) (1.60.0)\nRequirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai) (1.48.1)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.1)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.5.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":233},{"cell_type":"code","source":"from caafe import CAAFEClassifier # Automated Feature Engineering for tabular datasets\nfrom tabpfn import TabPFNClassifier # Fast Automated Machine Learning method for small tabular datasets\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport os\nimport google.generativeai as genai\nimport torch\nfrom caafe import data\nfrom sklearn.metrics import accuracy_score\nfrom tabpfn.scripts import tabular_metrics\nfrom functools import partial","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:04:31.880306Z","iopub.execute_input":"2024-06-03T18:04:31.880725Z","iopub.status.idle":"2024-06-03T18:04:32.985980Z","shell.execute_reply.started":"2024-06-03T18:04:31.880694Z","shell.execute_reply":"2024-06-03T18:04:32.984669Z"},"trusted":true},"outputs":[],"execution_count":235},{"cell_type":"code","source":"genai.configure(api_key=\"AIzaSyDTadzIHBWOiysP5O-vcxJ53ihHryQHkLo\")\nmodel_gemini = genai.GenerativeModel('gemini-1.5-pro')\nstability_generation_config = genai.GenerationConfig(temperature=0, top_p=1, top_k=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:04:35.345112Z","iopub.execute_input":"2024-06-03T18:04:35.346043Z","iopub.status.idle":"2024-06-03T18:04:35.406348Z","shell.execute_reply.started":"2024-06-03T18:04:35.346004Z","shell.execute_reply":"2024-06-03T18:04:35.405169Z"},"trusted":true},"outputs":[],"execution_count":236},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:39:00.473825Z","iopub.execute_input":"2024-06-03T18:39:00.474225Z","iopub.status.idle":"2024-06-03T18:39:00.552426Z","shell.execute_reply.started":"2024-06-03T18:39:00.474194Z","shell.execute_reply":"2024-06-03T18:39:00.551297Z"},"trusted":true},"outputs":[{"execution_count":240,"output_type":"execute_result","data":{"text/plain":"          id    b1   b11   b12    b2    b3    b4    b5    b6    b7    b8  \\\n0       2002   293  1927  1038   278   475   453   987  1773  2184  1900   \n1       3212   197  1598   697   201   347   228   682  1982  2449  2254   \n2      13312   929  1975  1031   982  1020   856  1220  2051  2421  2392   \n3      17020   132  1560   689   189   408   175   609  2117  2907  3024   \n4       5967   241  1944  1131   362   538   487   918  1549  1844  1702   \n...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n13048   9185   374  1940  1054   382   565   498   977  1678  1929  2109   \n13049  13977  1983  3602  2720  1622  1782  1766  2314  3488  3900  3924   \n13050    755   940  2007  1148   975  1080   968  1252  1780  1983  1942   \n13051   1616  1174  2312  1190  1112  1126   889  1310  2511  3085  3050   \n13052  15634   193  2091  1084   274   502   452   881  1953  2427  2830   \n\n       b8_a    b9 nforest_type  \n0      2343  3039          MDF  \n1      2685  2690          DDF  \n2      2671  2683          MDF  \n3      3005  2955          MDF  \n4      2077  2043          MDF  \n...     ...   ...          ...  \n13048  2291  2100          DDF  \n13049  4097  6053          DDF  \n13050  2247  2170          DDF  \n13051  3396  3380          MDF  \n13052  2863  2586          MDF  \n\n[13053 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>b1</th>\n      <th>b11</th>\n      <th>b12</th>\n      <th>b2</th>\n      <th>b3</th>\n      <th>b4</th>\n      <th>b5</th>\n      <th>b6</th>\n      <th>b7</th>\n      <th>b8</th>\n      <th>b8_a</th>\n      <th>b9</th>\n      <th>nforest_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2002</td>\n      <td>293</td>\n      <td>1927</td>\n      <td>1038</td>\n      <td>278</td>\n      <td>475</td>\n      <td>453</td>\n      <td>987</td>\n      <td>1773</td>\n      <td>2184</td>\n      <td>1900</td>\n      <td>2343</td>\n      <td>3039</td>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3212</td>\n      <td>197</td>\n      <td>1598</td>\n      <td>697</td>\n      <td>201</td>\n      <td>347</td>\n      <td>228</td>\n      <td>682</td>\n      <td>1982</td>\n      <td>2449</td>\n      <td>2254</td>\n      <td>2685</td>\n      <td>2690</td>\n      <td>DDF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13312</td>\n      <td>929</td>\n      <td>1975</td>\n      <td>1031</td>\n      <td>982</td>\n      <td>1020</td>\n      <td>856</td>\n      <td>1220</td>\n      <td>2051</td>\n      <td>2421</td>\n      <td>2392</td>\n      <td>2671</td>\n      <td>2683</td>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17020</td>\n      <td>132</td>\n      <td>1560</td>\n      <td>689</td>\n      <td>189</td>\n      <td>408</td>\n      <td>175</td>\n      <td>609</td>\n      <td>2117</td>\n      <td>2907</td>\n      <td>3024</td>\n      <td>3005</td>\n      <td>2955</td>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5967</td>\n      <td>241</td>\n      <td>1944</td>\n      <td>1131</td>\n      <td>362</td>\n      <td>538</td>\n      <td>487</td>\n      <td>918</td>\n      <td>1549</td>\n      <td>1844</td>\n      <td>1702</td>\n      <td>2077</td>\n      <td>2043</td>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13048</th>\n      <td>9185</td>\n      <td>374</td>\n      <td>1940</td>\n      <td>1054</td>\n      <td>382</td>\n      <td>565</td>\n      <td>498</td>\n      <td>977</td>\n      <td>1678</td>\n      <td>1929</td>\n      <td>2109</td>\n      <td>2291</td>\n      <td>2100</td>\n      <td>DDF</td>\n    </tr>\n    <tr>\n      <th>13049</th>\n      <td>13977</td>\n      <td>1983</td>\n      <td>3602</td>\n      <td>2720</td>\n      <td>1622</td>\n      <td>1782</td>\n      <td>1766</td>\n      <td>2314</td>\n      <td>3488</td>\n      <td>3900</td>\n      <td>3924</td>\n      <td>4097</td>\n      <td>6053</td>\n      <td>DDF</td>\n    </tr>\n    <tr>\n      <th>13050</th>\n      <td>755</td>\n      <td>940</td>\n      <td>2007</td>\n      <td>1148</td>\n      <td>975</td>\n      <td>1080</td>\n      <td>968</td>\n      <td>1252</td>\n      <td>1780</td>\n      <td>1983</td>\n      <td>1942</td>\n      <td>2247</td>\n      <td>2170</td>\n      <td>DDF</td>\n    </tr>\n    <tr>\n      <th>13051</th>\n      <td>1616</td>\n      <td>1174</td>\n      <td>2312</td>\n      <td>1190</td>\n      <td>1112</td>\n      <td>1126</td>\n      <td>889</td>\n      <td>1310</td>\n      <td>2511</td>\n      <td>3085</td>\n      <td>3050</td>\n      <td>3396</td>\n      <td>3380</td>\n      <td>MDF</td>\n    </tr>\n    <tr>\n      <th>13052</th>\n      <td>15634</td>\n      <td>193</td>\n      <td>2091</td>\n      <td>1084</td>\n      <td>274</td>\n      <td>502</td>\n      <td>452</td>\n      <td>881</td>\n      <td>1953</td>\n      <td>2427</td>\n      <td>2830</td>\n      <td>2863</td>\n      <td>2586</td>\n      <td>MDF</td>\n    </tr>\n  </tbody>\n</table>\n<p>13053 rows × 14 columns</p>\n</div>"},"metadata":{}}],"execution_count":240},{"cell_type":"code","source":"metric_used = tabular_metrics.auc_metric\ncc_test_datasets_multiclass = train","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:05:08.326746Z","iopub.execute_input":"2024-06-03T18:05:08.327222Z","iopub.status.idle":"2024-06-03T18:05:08.388207Z","shell.execute_reply.started":"2024-06-03T18:05:08.327186Z","shell.execute_reply":"2024-06-03T18:05:08.387032Z"},"trusted":true},"outputs":[],"execution_count":237},{"cell_type":"code","source":"ds = cc_test_datasets_multiclass\nds, df_train, df_test, _, _ = train.get_data_split(ds, seed=0)\n\n X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\ntarget_column_name = ds[13]\ndataset_description = pd.read_csv('/kaggle/input/forest-type-classification-spai/metaData.csv')\nds","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:57:28.223877Z","iopub.execute_input":"2024-06-03T18:57:28.224309Z","iopub.status.idle":"2024-06-03T18:57:28.329168Z","shell.execute_reply.started":"2024-06-03T18:57:28.224279Z","shell.execute_reply":"2024-06-03T18:57:28.327409Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/36842140.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcc_test_datasets_multiclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtarget_column_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/forest-type-classification-spai/metaData.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'get_data_split'"],"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'get_data_split'","output_type":"error"}],"execution_count":247},{"cell_type":"code","source":"dataset_description = pd.read_csv('/kaggle/input/forest-type-classification-spai/metaData.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:46:36.742241Z","iopub.execute_input":"2024-06-03T18:46:36.742707Z","iopub.status.idle":"2024-06-03T18:46:36.808045Z","shell.execute_reply.started":"2024-06-03T18:46:36.742675Z","shell.execute_reply":"2024-06-03T18:46:36.807151Z"},"trusted":true},"outputs":[],"execution_count":244},{"cell_type":"code","source":"caafe_clf = CAAFEClassifier(base_classifier=clf_no_feat_eng,\n                            llm_model=\"model_gemini\",\n                            iterations=2)\n\ncaafe_clf.fit_pandas(train,\n                     target_column_name=train['nforest_type'],\n                     dataset_description=dataset_description)\n\npred = caafe_clf.predict(df_test)\nacc = accuracy_score(pred, test_y)\nprint(f'Accuracy after CAAFE {acc}')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:46:40.787705Z","iopub.execute_input":"2024-06-03T18:46:40.788685Z","iopub.status.idle":"2024-06-03T18:46:40.881073Z","shell.execute_reply.started":"2024-06-03T18:46:40.788645Z","shell.execute_reply":"2024-06-03T18:46:40.879921Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[245], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcaafe_clf\u001b[49m\u001b[38;5;241m.\u001b[39mfit_pandas(train,\n\u001b[1;32m      2\u001b[0m                      target_column_name\u001b[38;5;241m=\u001b[39mtrain[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnforest_type\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      3\u001b[0m                      dataset_description\u001b[38;5;241m=\u001b[39mdataset_description)\n\u001b[1;32m      5\u001b[0m pred \u001b[38;5;241m=\u001b[39m caafe_clf\u001b[38;5;241m.\u001b[39mpredict(df_test)\n\u001b[1;32m      6\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(pred, test_y)\n","\u001b[0;31mNameError\u001b[0m: name 'caafe_clf' is not defined"],"ename":"NameError","evalue":"name 'caafe_clf' is not defined","output_type":"error"}],"execution_count":245},{"cell_type":"markdown","source":"## LLM","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport google.generativeai as genai","metadata":{"execution":{"iopub.status.busy":"2024-06-03T19:03:50.080572Z","iopub.execute_input":"2024-06-03T19:03:50.081071Z","iopub.status.idle":"2024-06-03T19:03:50.142942Z","shell.execute_reply.started":"2024-06-03T19:03:50.081034Z","shell.execute_reply":"2024-06-03T19:03:50.141709Z"},"trusted":true},"outputs":[],"execution_count":250},{"cell_type":"code","source":"genai.configure(api_key=\"AIzaSyDTadzIHBWOiysP5O-vcxJ53ihHryQHkLo\")\nmodel_gemini = genai.GenerativeModel('gemini-1.5-pro')\nstability_generation_config = genai.GenerationConfig(temperature=0, top_p=1, top_k=1)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"domain = \"GIS Analyst\"\ntask_description = \"\"\"\nAs a GIS Analyst with extensive expertise in Thailand's geography and environmental dynamics, \nyou're tasked with a crucial project: mapping the country's diverse forest types. Leveraging the Sentinel-2 satellite imagery, your goal is to classify these forests into deciduous, mixed, and dry evergreen categories. Additionally, \nyou'll incorporate remote sensing data from humidity survey satellites to better understand the climate-forest interactions.\nYour tasks include:\n\nUtilizing Sentinel-2 imagery to capture high-resolution data of Thailand's landscape.\nPreprocessing Sentinel-2 data and extracting relevant bands for analysis, focusing on vegetation indices such as NDVI (Normalized Difference Vegetation Index).\nImplementing classification algorithms to differentiate between deciduous, mixed, and dry evergreen forests.\nIntegrating remote sensing data on humidity levels to assess the influence of climate on forest distribution.\nGenerating maps and reports to communicate your findings effectively to stakeholders, including policymakers and environmental agencies.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-03T19:11:46.834936Z","iopub.execute_input":"2024-06-03T19:11:46.835412Z","iopub.status.idle":"2024-06-03T19:11:46.895723Z","shell.execute_reply.started":"2024-06-03T19:11:46.835364Z","shell.execute_reply":"2024-06-03T19:11:46.894474Z"},"trusted":true},"outputs":[],"execution_count":251},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features_df","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:59:34.075273Z","iopub.execute_input":"2024-06-03T18:59:34.075716Z","iopub.status.idle":"2024-06-03T18:59:34.138869Z","shell.execute_reply.started":"2024-06-03T18:59:34.075681Z","shell.execute_reply":"2024-06-03T18:59:34.137693Z"},"trusted":true},"outputs":[{"execution_count":249,"output_type":"execute_result","data":{"text/plain":"     column_name                                        description\n0             id                                          unique id\n1             b1                         Band instrument  Sentinel2\n2            b11                         Band instrument  Sentinel2\n3            b12                         Band instrument  Sentinel2\n4             b2                         Band instrument  Sentinel2\n5             b3                         Band instrument  Sentinel2\n6             b4                         Band instrument  Sentinel2\n7             b5                         Band instrument  Sentinel2\n8             b6                         Band instrument  Sentinel2\n9             b7                         Band instrument  Sentinel2\n10            b8                         Band instrument  Sentinel2\n11          b8_a                         Band instrument  Sentinel2\n12            b9                         Band instrument  Sentinel2\n13  nforest_type  Forest Type (DDF (ป่าเต็งรัง), MDF (ป่าเบญจพรร...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>column_name</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id</td>\n      <td>unique id</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b1</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b11</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b12</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b2</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>b3</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>b4</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>b5</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>b6</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>b7</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>b8</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>b8_a</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>b9</td>\n      <td>Band instrument  Sentinel2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>nforest_type</td>\n      <td>Forest Type (DDF (ป่าเต็งรัง), MDF (ป่าเบญจพรร...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":249},{"cell_type":"code","source":"features_df = pd.read_csv(\"/kaggle/input/forest-type-classification-spai/metaData.csv\")\navailable_columns = features_df['Variable'].tolist()\n\nvalid_columns = list(set(available_columns).intersection(set(df_train.columns)))\nother_columns = list(set(df_train.columns) - set(valid_columns))","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:59:17.695043Z","iopub.execute_input":"2024-06-03T18:59:17.695557Z","iopub.status.idle":"2024-06-03T18:59:17.895025Z","shell.execute_reply.started":"2024-06-03T18:59:17.695519Z","shell.execute_reply":"2024-06-03T18:59:17.893474Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Variable'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[248], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m features_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/forest-type-classification-spai/metaData.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m available_columns \u001b[38;5;241m=\u001b[39m \u001b[43mfeatures_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVariable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      4\u001b[0m valid_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(available_columns)\u001b[38;5;241m.\u001b[39mintersection(\u001b[38;5;28mset\u001b[39m(df_train\u001b[38;5;241m.\u001b[39mcolumns)))\n\u001b[1;32m      5\u001b[0m other_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(df_train\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(valid_columns))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: 'Variable'"],"ename":"KeyError","evalue":"'Variable'","output_type":"error"}],"execution_count":248}]}