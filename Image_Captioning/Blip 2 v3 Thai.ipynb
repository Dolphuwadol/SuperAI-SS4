{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eHvKhloSuQnx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not find the bitsandbytes CUDA binary at PosixPath('/home/ai4103/.conda/envs/main/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda121.so')\n",
            "Could not load bitsandbytes native library: /home/ai4103/.conda/envs/main/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: cannot open shared object file: No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ai4103/.conda/envs/main/lib/python3.10/site-packages/bitsandbytes/cextension.py\", line 109, in <module>\n",
            "    lib = get_native_library()\n",
            "  File \"/home/ai4103/.conda/envs/main/lib/python3.10/site-packages/bitsandbytes/cextension.py\", line 96, in get_native_library\n",
            "    dll = ct.cdll.LoadLibrary(str(binary_path))\n",
            "  File \"/home/ai4103/.conda/envs/main/lib/python3.10/ctypes/__init__.py\", line 452, in LoadLibrary\n",
            "    return self._dlltype(name)\n",
            "  File \"/home/ai4103/.conda/envs/main/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: /home/ai4103/.conda/envs/main/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: cannot open shared object file: No such file or directory\n",
            "\n",
            "CUDA Setup failed despite CUDA being available. Please run the following command to get more information:\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            "Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n",
            "to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n",
            "and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "\n",
            "Could not load bitsandbytes native library: /home/ai4103/.conda/envs/main/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: cannot open shared object file: No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ai4103/.conda/envs/main/lib/python3.10/site-packages/bitsandbytes/cextension.py\", line 109, in <module>\n",
            "    lib = get_native_library()\n",
            "  File \"/home/ai4103/.conda/envs/main/lib/python3.10/site-packages/bitsandbytes/cextension.py\", line 96, in get_native_library\n",
            "    dll = ct.cdll.LoadLibrary(str(binary_path))\n",
            "  File \"/home/ai4103/.conda/envs/main/lib/python3.10/ctypes/__init__.py\", line 452, in LoadLibrary\n",
            "    return self._dlltype(name)\n",
            "  File \"/home/ai4103/.conda/envs/main/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: /home/ai4103/.conda/envs/main/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: cannot open shared object file: No such file or directory\n",
            "\n",
            "CUDA Setup failed despite CUDA being available. Please run the following command to get more information:\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            "Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n",
            "to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n",
            "and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import Blip2Processor, Blip2VisionModel, Blip2QFormerModel, Blip2QFormerConfig, Blip2ForConditionalGeneration\n",
        "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
        "import os\n",
        "import bitsandbytes as bnb\n",
        "\n",
        "import torch\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, LoftQConfig\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        ")\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193,
          "referenced_widgets": [
            "f0b3f8bf13f34d10b0fe8cfbc871ff1e",
            "787048bad4dd447da3943f50fbba0e85",
            "808caf7af33c4f8aae378a5e2457f627",
            "4f9b0117a741421aa0f81907940e41be",
            "c2959d1a39aa4b979b6282cf9c9f7161",
            "e614afbc5bf84b918b6b490a844c46c1",
            "0ba6b962cd7b49798138e09a77d68102",
            "f0d8478db20840f58db14f99348018e7",
            "da7ee783ab334c76b80ae48c75487b02",
            "d14bf5714f864f1fa0ed9dd05a86113c",
            "93b2dd2c3fdf4c198db62146ef4c9881"
          ]
        },
        "id": "NPnPOcXb8sO6",
        "outputId": "9ec35549-e82e-4494-f3bb-bb9e346ebe32"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model,LoftQConfig\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\"]\n",
        ")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTkkwJodf1LR",
        "outputId": "ac6fa3e9-e4f2-4ae8-ab48-5b5270a64282"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76a5ddecd6214df19568a0504a699188",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "class BlipZSIC:\n",
        "    def __init__(self, bnb_config: BitsAndBytesConfig, loraConfig: LoraConfig) -> None:\n",
        "        self.base = Blip2ForConditionalGeneration.from_pretrained(\n",
        "            \"Salesforce/blip2-opt-2.7b\",  # TODO put back in \"load_in_8bit\" for model\n",
        "            device_map={\"\": 0},\n",
        "            # trust_remote_code=True,\n",
        "            # quantization_config=bnb_config\n",
        "        )\n",
        "        self.processor = Blip2Processor.from_pretrained(\n",
        "            \"Salesforce/blip2-opt-2.7b\")\n",
        "        \n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"airesearch/wangchanberta-base-att-spm-uncased\")\n",
        "        \n",
        "        self.base.config.text_config.vocab_size = 25004\n",
        "        self.base.language_model.resize_token_embeddings(len(self.tokenizer))\n",
        "        self.base.config.eos_token_id = 6\n",
        "        self.processor.tokenizer = self.tokenizer\n",
        "\n",
        "        self.model = None\n",
        "\n",
        "        self.loraConfig = loraConfig\n",
        "        self.adapterList = []\n",
        "        self.currentState = ''\n",
        "\n",
        "    def compileModel(self)->None: # compile the model into qLora\n",
        "        self.model = get_peft_model(self.base, self.loraConfig)\n",
        "        self.model.print_trainable_parameters()\n",
        "\n",
        "    def addAdapter(self,adapter:str): #pass in the adapter path to add\n",
        "        self.adapterList.append(adapter)\n",
        "        self.model.add_adapter(self.lora_config, adapter_name=adapter)\n",
        "\n",
        "    def switchAdapter(self,adapterNum:int): \n",
        "        if adapterNum != 0: #left in for clarity\n",
        "            try:\n",
        "                if self.currentState != adapterNum:\n",
        "                    self.model.set_adapter(self.adapterList[adapterNum])\n",
        "                    self.currentState = adapterNum\n",
        "                    print(f\"switched to adapter {adapterNum}\")\n",
        "            except IndexError:\n",
        "                print(\"index out of range, returning\")\n",
        "            \n",
        "        else:\n",
        "            self.model.disable_adapters()\n",
        "            self.currentState = adapterNum\n",
        "            print(\"adapters disabled\")\n",
        "\n",
        "    def forward(self,input_ids,pixel_values,modeltype = -1):\n",
        "        if modeltype != -1 :\n",
        "            self.switchAdapter(modeltype)\n",
        "        \n",
        "        return self.model(input_ids=input_ids,\n",
        "                   pixel_values=pixel_values,\n",
        "                   labels=input_ids)\n",
        "    \n",
        "    def predict(self, imgs):\n",
        "        self.model.eval()\n",
        "        \n",
        "        pixel_values = self.processor(sample_img, return_tensors=\"pt\").to(device).pixel_values\n",
        "\n",
        "        outputs = self.model.generate(pixel_values=pixel_values)\n",
        "\n",
        "        generated_caption = self.processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "        \n",
        "        return generated_caption\n",
        "        \n",
        "Blip = BlipZSIC(bnb_config,config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 5,242,880 || all params: 3,685,236,736 || trainable%: 0.1423\n"
          ]
        }
      ],
      "source": [
        "Blip.compileModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CnS4l5WP6Orr"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ImageCaptioningDataset(Dataset):\n",
        "    def __init__(self, dataset, processor):\n",
        "        self.dataset = dataset\n",
        "        self.processor = processor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        encoding = self.processor(images=item[\"image\"], padding=\"max_length\", return_tensors=\"pt\")\n",
        "        # remove batch dimension\n",
        "        encoding = {k: v.squeeze() for k, v in encoding.items()}\n",
        "        encoding[\"text\"] = item[\"text\"]\n",
        "        return encoding\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # pad the input_ids and attention_mask\n",
        "    processed_batch = {}\n",
        "    for key in batch[0].keys():\n",
        "        if key != \"text\":\n",
        "            processed_batch[key] = torch.stack([example[key] for example in batch])\n",
        "        else:\n",
        "            text_inputs = Blip.processor.tokenizer(\n",
        "                [example[\"text\"] for example in batch], padding=True, return_tensors=\"pt\"\n",
        "            )\n",
        "            processed_batch[\"input_ids\"] = text_inputs[\"input_ids\"]\n",
        "            processed_batch[\"attention_mask\"] = text_inputs[\"attention_mask\"]\n",
        "    return processed_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data and Dataloader setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "images_path = list(Path(\"/project/lt900331-ai24nr/blip/Image\").glob(\"*.jpg\"))\n",
        "\n",
        "labels = pd.DataFrame(\n",
        "    {\"image\": images_path,\n",
        "    \"caption\": [\"น่าจะเป็นดาวแหละ\"] * len(images_path)\n",
        "    }\n",
        ")\n",
        "# labels = pd.read_csv(\"/root/Datasets/preprocess.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Z0f0SiWn58cU"
      },
      "outputs": [],
      "source": [
        "images = [Image.open(str(images_path[0].parent / path)) for path in labels['image']]\n",
        "\n",
        "dataset = datasets.Dataset.from_dict({\"image\": images, \"text\": labels['caption']})\n",
        "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "train_dataset = ImageCaptioningDataset(dataset['train'], Blip.processor)\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=4, collate_fn=collate_fn)\n",
        "\n",
        "test_dataset = ImageCaptioningDataset(dataset['test'], Blip.processor)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=4, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dpZUR16yY6Lo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10.002299308776855\n",
            "Epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.557210922241211\n",
            "Epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.596506118774414\n",
            "Epoch: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.382016181945801\n",
            "Epoch: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.052756309509277\n",
            "Epoch: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.780925750732422\n",
            "Epoch: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.195636510848999\n",
            "Epoch: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.720263719558716\n",
            "Epoch: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.5085463523864746\n",
            "Epoch: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9145419001579285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "optimizer = torch.optim.Adam(Blip.model.parameters(), lr=5e-4)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "Blip.model.train()\n",
        "\n",
        "for epoch in range(10):\n",
        "    training_loss = 0\n",
        "    print(\"Epoch:\", epoch)\n",
        "    for idx, batch in enumerate(tqdm(train_dataloader)):\n",
        "        input_ids = batch.pop(\"input_ids\").to(device)\n",
        "        pixel_values = batch.pop(\"pixel_values\").to(device)\n",
        "        outputs = Blip.forward(input_ids=input_ids,\n",
        "                        pixel_values=pixel_values,\n",
        "        )#put in a 4th value as an int to select adapters\n",
        "\n",
        "        loss = outputs.loss\n",
        "        training_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "    print(training_loss / len(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z6Hp54hHLzrt"
      },
      "outputs": [],
      "source": [
        "# sample image in dataset['test']\n",
        "sample_img = dataset['test']['image'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "je60XdrrY6Lp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'จน่าจะเป็นดาวแหละ น่าจะเป็นดาวแหละ น่าจะเป็นดาวแหละ น่าจะเป็นดาว'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Blip.predict(sample_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 31296,
          "sourceId": 39911,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4836244,
          "sourceId": 8171532,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30703,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ba6b962cd7b49798138e09a77d68102": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f9b0117a741421aa0f81907940e41be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d14bf5714f864f1fa0ed9dd05a86113c",
            "placeholder": "​",
            "style": "IPY_MODEL_93b2dd2c3fdf4c198db62146ef4c9881",
            "value": " 2/2 [01:19&lt;00:00, 37.71s/it]"
          }
        },
        "787048bad4dd447da3943f50fbba0e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e614afbc5bf84b918b6b490a844c46c1",
            "placeholder": "​",
            "style": "IPY_MODEL_0ba6b962cd7b49798138e09a77d68102",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "808caf7af33c4f8aae378a5e2457f627": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0d8478db20840f58db14f99348018e7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da7ee783ab334c76b80ae48c75487b02",
            "value": 2
          }
        },
        "93b2dd2c3fdf4c198db62146ef4c9881": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2959d1a39aa4b979b6282cf9c9f7161": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d14bf5714f864f1fa0ed9dd05a86113c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da7ee783ab334c76b80ae48c75487b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e614afbc5bf84b918b6b490a844c46c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0b3f8bf13f34d10b0fe8cfbc871ff1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_787048bad4dd447da3943f50fbba0e85",
              "IPY_MODEL_808caf7af33c4f8aae378a5e2457f627",
              "IPY_MODEL_4f9b0117a741421aa0f81907940e41be"
            ],
            "layout": "IPY_MODEL_c2959d1a39aa4b979b6282cf9c9f7161"
          }
        },
        "f0d8478db20840f58db14f99348018e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
