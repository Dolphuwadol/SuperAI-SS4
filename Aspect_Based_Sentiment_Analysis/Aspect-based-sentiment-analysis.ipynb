{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":82757,"databundleVersionId":9093595,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets \n!pip install seqeval \n!pip install transformers[torch] -p\n!pip install wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-13T17:49:00.645794Z","iopub.execute_input":"2024-07-13T17:49:00.646734Z","iopub.status.idle":"2024-07-13T17:49:51.483553Z","shell.execute_reply.started":"2024-07-13T17:49:00.646700Z","shell.execute_reply":"2024-07-13T17:49:51.482269Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=2dcafb2c0ce6a4c9bf9a7e3ea30fa65b24189bd81830484bd8b8b46edb664ae4\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n\nUsage:   \n  pip install [options] <requirement specifier> [package-index-options] ...\n  pip install [options] -r <requirements file> [package-index-options] ...\n  pip install [options] [-e] <vcs project url> ...\n  pip install [options] [-e] <local project path> ...\n  pip install [options] <archive url/path> ...\n\nno such option: -p\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.4)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.8.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport wandb\nfrom datasets import load_dataset, load_metric\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:49:51.485830Z","iopub.execute_input":"2024-07-13T17:49:51.486218Z","iopub.status.idle":"2024-07-13T17:50:12.295699Z","shell.execute_reply.started":"2024-07-13T17:49:51.486155Z","shell.execute_reply":"2024-07-13T17:50:12.294555Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2024-07-13 17:50:00.394868: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-13 17:50:00.395009: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-13 17:50:00.550905: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"train_path = \"/kaggle/input/hackathon-online-aspect-based-sentiment-analysis/train.txt\"\ntest_path = \"/kaggle/input/hackathon-online-aspect-based-sentiment-analysis/test.csv\"\nsample_submission_path = \"/kaggle/input/hackathon-online-aspect-based-sentiment-analysis/sample_submission.csv\"\n\ntrain = pd.read_csv(train_path, delimiter = \"\\t\", header=None)\ntest = pd.read_csv(test_path, sep = \",\", on_bad_lines='skip')\nsample_submission = pd.read_csv(sample_submission_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:12.297077Z","iopub.execute_input":"2024-07-13T17:50:12.297749Z","iopub.status.idle":"2024-07-13T17:50:12.371748Z","shell.execute_reply.started":"2024-07-13T17:50:12.297719Z","shell.execute_reply":"2024-07-13T17:50:12.370588Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"test.columns = [0, 1]","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:12.374935Z","iopub.execute_input":"2024-07-13T17:50:12.375727Z","iopub.status.idle":"2024-07-13T17:50:12.380845Z","shell.execute_reply.started":"2024-07-13T17:50:12.375684Z","shell.execute_reply":"2024-07-13T17:50:12.379651Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntest_val = test\nval_size = 0.2\ntest_val, val = train_test_split(test_val, test_size=val_size)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:12.382198Z","iopub.execute_input":"2024-07-13T17:50:12.382522Z","iopub.status.idle":"2024-07-13T17:50:12.410398Z","shell.execute_reply.started":"2024-07-13T17:50:12.382494Z","shell.execute_reply":"2024-07-13T17:50:12.409351Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"test_txt_path = '/kaggle/working/test.txt'\nval_txt_path = '/kaggle/working/val.txt'\n\ntest.to_csv(test_txt_path, sep='\\t', index=False,header=False)\nval.to_csv(val_txt_path, sep='\\t', index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:12.411668Z","iopub.execute_input":"2024-07-13T17:50:12.412084Z","iopub.status.idle":"2024-07-13T17:50:12.783418Z","shell.execute_reply.started":"2024-07-13T17:50:12.412049Z","shell.execute_reply":"2024-07-13T17:50:12.782222Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def load_data(fname, tag_id=None):\n    data = []\n    if tag_id is None:\n        tag_id = {}\n\n    with open(fname, encoding='utf-8') as fp:\n        lines = fp.readlines()\n        tmp_sen = []\n        for line in lines:\n            if line.strip() == \"\":\n                if len(tmp_sen) > 0:\n                    tokens = []\n                    tags = []\n                    for token, tag in tmp_sen:\n                        tokens.append(token)\n                        if tag not in tag_id.keys():\n                            tag_id[tag] = len(tag_id)\n                        tags.append(tag_id[tag])\n\n                    data.append({\"tokens\": tokens, \"tags\": tags})\n                    tmp_sen = []\n\n                continue\n\n            _x = line.strip().split('\\t')\n            if len(_x) == 2:  # Ensure that there are exactly two columns\n                tmp_sen.append((_x[0], _x[1]))\n            else:\n                print(f\"Skipping malformed line: {line.strip()}\")\n\n    if len(tmp_sen) > 0:  # In case the last sentence does not end with a blank line\n        tokens = []\n        tags = []\n        for token, tag in tmp_sen:\n            tokens.append(token)\n            if tag not in tag_id.keys():\n                tag_id[tag] = len(tag_id)\n            tags.append(tag_id[tag])\n\n        data.append({\"tokens\": tokens, \"tags\": tags})\n\n    return data, tag_id","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:12.786788Z","iopub.execute_input":"2024-07-13T17:50:12.787239Z","iopub.status.idle":"2024-07-13T17:50:12.801256Z","shell.execute_reply.started":"2024-07-13T17:50:12.787199Z","shell.execute_reply":"2024-07-13T17:50:12.800097Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import json\n\ndef write_jsonl(data, file_path):\n    with open(file_path, 'w') as file:\n        for entry in data:\n            json_line = json.dumps(entry)\n            file.write(json_line + '\\n')","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:12.802876Z","iopub.execute_input":"2024-07-13T17:50:12.803308Z","iopub.status.idle":"2024-07-13T17:50:12.815612Z","shell.execute_reply.started":"2024-07-13T17:50:12.803274Z","shell.execute_reply":"2024-07-13T17:50:12.814483Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:12.817170Z","iopub.execute_input":"2024-07-13T17:50:12.817878Z","iopub.status.idle":"2024-07-13T17:50:12.843754Z","shell.execute_reply.started":"2024-07-13T17:50:12.817839Z","shell.execute_reply":"2024-07-13T17:50:12.842469Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"           0            1\n0        1_1       ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤\n1        1_2           ‡∏°‡∏µ\n2        1_3          ‡∏Å‡∏≤‡∏£\n3        1_4    ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡πÅ‡∏ó‡∏Å\n4        1_5        ‡∏≠‡∏¢‡πà‡∏≤‡∏á\n...      ...          ...\n6385  153_31  ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢\n6386  153_32           ‡πÉ‡∏ô\n6387  153_33    ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n6388  153_34          ‡∏Ç‡∏≠‡∏á\n6389  153_35         ‡∏´‡∏°‡πâ‡∏≠\n\n[6390 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_1</td>\n      <td>‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_2</td>\n      <td>‡∏°‡∏µ</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1_3</td>\n      <td>‡∏Å‡∏≤‡∏£</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1_4</td>\n      <td>‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡πÅ‡∏ó‡∏Å</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_5</td>\n      <td>‡∏≠‡∏¢‡πà‡∏≤‡∏á</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6385</th>\n      <td>153_31</td>\n      <td>‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢</td>\n    </tr>\n    <tr>\n      <th>6386</th>\n      <td>153_32</td>\n      <td>‡πÉ‡∏ô</td>\n    </tr>\n    <tr>\n      <th>6387</th>\n      <td>153_33</td>\n      <td>‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô</td>\n    </tr>\n    <tr>\n      <th>6388</th>\n      <td>153_34</td>\n      <td>‡∏Ç‡∏≠‡∏á</td>\n    </tr>\n    <tr>\n      <th>6389</th>\n      <td>153_35</td>\n      <td>‡∏´‡∏°‡πâ‡∏≠</td>\n    </tr>\n  </tbody>\n</table>\n<p>6390 rows √ó 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"tag_id = {'Appearance': 0,\n 'DeliveryTime': 1,\n 'Price': 2,\n 'Quality': 3,\n 'StoreService': 4,\n 'NEG-Quality': 5,\n 'O': 6,\n 'NEG-Appearance': 7,\n 'NEG-StoreService': 8,\n 'Size': 9,\n 'NEG-DeliveryTime': 10,\n 'Packaging': 11,\n 'NEG-Price': 12,\n 'NEG-Size': 13,\n 'NEG-Packaging': 14}\n\ntrain_data, _ = load_data(train_path)\ntest_data,_ = load_data(test_txt_path,tag_id)\nval_data,_ = load_data(val_txt_path,tag_id)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:12.849273Z","iopub.execute_input":"2024-07-13T17:50:12.849650Z","iopub.status.idle":"2024-07-13T17:50:12.935991Z","shell.execute_reply.started":"2024-07-13T17:50:12.849619Z","shell.execute_reply":"2024-07-13T17:50:12.934883Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"tag_id = {'Appearance': 0,\n 'DeliveryTime': 1,\n 'Price': 2,\n 'Quality': 3,\n 'StoreService': 4,\n 'NEG-Quality': 5,\n 'O': 6,\n 'NEG-Appearance': 7,\n 'NEG-StoreService': 8,\n 'Size': 9,\n 'NEG-DeliveryTime': 10,\n 'Packaging': 11,\n 'NEG-Price': 12,\n 'NEG-Size': 13,\n 'NEG-Packaging': 14}","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:12.937320Z","iopub.execute_input":"2024-07-13T17:50:12.937665Z","iopub.status.idle":"2024-07-13T17:50:12.943783Z","shell.execute_reply.started":"2024-07-13T17:50:12.937637Z","shell.execute_reply":"2024-07-13T17:50:12.942619Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"tag_id","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:12.945294Z","iopub.execute_input":"2024-07-13T17:50:12.945643Z","iopub.status.idle":"2024-07-13T17:50:12.959367Z","shell.execute_reply.started":"2024-07-13T17:50:12.945615Z","shell.execute_reply":"2024-07-13T17:50:12.958282Z"},"trusted":true},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'Appearance': 0,\n 'DeliveryTime': 1,\n 'Price': 2,\n 'Quality': 3,\n 'StoreService': 4,\n 'NEG-Quality': 5,\n 'O': 6,\n 'NEG-Appearance': 7,\n 'NEG-StoreService': 8,\n 'Size': 9,\n 'NEG-DeliveryTime': 10,\n 'Packaging': 11,\n 'NEG-Price': 12,\n 'NEG-Size': 13,\n 'NEG-Packaging': 14}"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"write_jsonl(train_data,'train.json')\nwrite_jsonl(test_data,'test.json')\nwrite_jsonl(val_data,'val.json')","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:12.960883Z","iopub.execute_input":"2024-07-13T17:50:12.961281Z","iopub.status.idle":"2024-07-13T17:50:12.994183Z","shell.execute_reply.started":"2024-07-13T17:50:12.961251Z","shell.execute_reply":"2024-07-13T17:50:12.993028Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"task = \"asp\"\nmodel_checkpoint = \"Geotrend/bert-base-th-cased\"\nbatch_size = 16\n\nfile_dict = {\n  \"train\" : \"./train.json\",\n  \"test\" : \"./test.json\",\n  \"val\" : \"./val.json\"\n}\n\ndatasets =  load_dataset(\n  'json',\n  data_files=file_dict\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:12.995639Z","iopub.execute_input":"2024-07-13T17:50:12.996009Z","iopub.status.idle":"2024-07-13T17:50:13.511014Z","shell.execute_reply.started":"2024-07-13T17:50:12.995980Z","shell.execute_reply":"2024-07-13T17:50:13.509763Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc7a80f6ce8645c7bfef6c460f246b23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a086b7c63c74668bb6be55b6b021256"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating val split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c7253d629f04c2393d58385d6fb0951"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"datasets","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:13.512714Z","iopub.execute_input":"2024-07-13T17:50:13.513419Z","iopub.status.idle":"2024-07-13T17:50:13.521021Z","shell.execute_reply.started":"2024-07-13T17:50:13.513381Z","shell.execute_reply":"2024-07-13T17:50:13.519737Z"},"trusted":true},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'tags'],\n        num_rows: 609\n    })\n    test: Dataset({\n        features: ['tokens', 'tags'],\n        num_rows: 1\n    })\n    val: Dataset({\n        features: ['tokens', 'tags'],\n        num_rows: 1\n    })\n})"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"datasets['train']['tags'][0]","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:13.522780Z","iopub.execute_input":"2024-07-13T17:50:13.523469Z","iopub.status.idle":"2024-07-13T17:50:13.560633Z","shell.execute_reply.started":"2024-07-13T17:50:13.523431Z","shell.execute_reply":"2024-07-13T17:50:13.559409Z"},"trusted":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 1,\n 2,\n 2,\n 2,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 3,\n 1,\n 1]"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"tag_id","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:13.562576Z","iopub.execute_input":"2024-07-13T17:50:13.563033Z","iopub.status.idle":"2024-07-13T17:50:13.571393Z","shell.execute_reply.started":"2024-07-13T17:50:13.562996Z","shell.execute_reply":"2024-07-13T17:50:13.570400Z"},"trusted":true},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'Appearance': 0,\n 'DeliveryTime': 1,\n 'Price': 2,\n 'Quality': 3,\n 'StoreService': 4,\n 'NEG-Quality': 5,\n 'O': 6,\n 'NEG-Appearance': 7,\n 'NEG-StoreService': 8,\n 'Size': 9,\n 'NEG-DeliveryTime': 10,\n 'Packaging': 11,\n 'NEG-Price': 12,\n 'NEG-Size': 13,\n 'NEG-Packaging': 14}"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(tag_id))","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:13.573086Z","iopub.execute_input":"2024-07-13T17:50:13.573675Z","iopub.status.idle":"2024-07-13T17:50:16.259153Z","shell.execute_reply.started":"2024-07-13T17:50:13.573638Z","shell.execute_reply":"2024-07-13T17:50:16.258185Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/658 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5b98a2daca8427c8e4a264c187b8ddc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/370M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"876f5e54255a461f87daf4c23c5f7464"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at Geotrend/bert-base-th-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:16.260650Z","iopub.execute_input":"2024-07-13T17:50:16.261088Z","iopub.status.idle":"2024-07-13T17:50:17.075030Z","shell.execute_reply.started":"2024-07-13T17:50:16.261049Z","shell.execute_reply":"2024-07-13T17:50:17.074018Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"278ad19429fa4c7f8f98b6068e3081aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/47.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d556008ccbe47fdae0acae0762d9f35"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"print(tokenizer(\"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö‡∏ú‡∏°‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏≠\"))\nprint(tokenizer([\"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ\",\"‡∏Ñ‡∏£‡∏±‡∏ö\",\"‡∏ú‡∏°\",\"‡∏ä‡∏∑‡πà‡∏≠\", \"‡πÄ‡∏≠\"]))","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:17.076617Z","iopub.execute_input":"2024-07-13T17:50:17.077012Z","iopub.status.idle":"2024-07-13T17:50:17.086749Z","shell.execute_reply.started":"2024-07-13T17:50:17.076980Z","shell.execute_reply":"2024-07-13T17:50:17.085620Z"},"trusted":true},"outputs":[{"name":"stdout","text":"{'input_ids': [11, 175, 4953, 8342, 6910, 6602, 8305, 8473, 2939, 5972, 6398, 8484, 5136, 12], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n{'input_ids': [[11, 175, 4953, 8342, 6910, 12], [11, 140, 3920, 8305, 12], [11, 162, 2939, 12], [11, 145, 6398, 12], [11, 184, 5136, 12]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]}\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n    label_all_tokens = True\n    #print('tokenized_inputs:',tokenized_inputs)\n    labels = []\n    lab2index = {}\n    word_idxs = []\n    for i, label in enumerate(examples[f\"tags\"]):\n        #print(label)\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        #print('x word_ids',word_ids)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n\n            else:\n                label_ids.append(label[word_idx] if label_all_tokens else -100)\n\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n        word_idxs.append(word_ids)\n    tokenized_inputs[\"labels\"] = labels\n    tokenized_inputs[\"word_ids\"] = word_idxs\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:17.087911Z","iopub.execute_input":"2024-07-13T17:50:17.088235Z","iopub.status.idle":"2024-07-13T17:50:17.097985Z","shell.execute_reply.started":"2024-07-13T17:50:17.088196Z","shell.execute_reply":"2024-07-13T17:50:17.096879Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:17.099600Z","iopub.execute_input":"2024-07-13T17:50:17.100378Z","iopub.status.idle":"2024-07-13T17:50:17.670487Z","shell.execute_reply.started":"2024-07-13T17:50:17.100339Z","shell.execute_reply":"2024-07-13T17:50:17.669404Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/609 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5dcc5b9719c426db0d9883fc4172bcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"284c6b820a07435496063ca66f3b25d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a1edb361d2449f29682a081fda10006"}},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"print(tokenized_datasets['train']['tokens'][0])\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_datasets['train']['input_ids'][0]\nprint(tokenized_datasets['train']['tokens'][0])\nprint(tokenized_datasets['train']['input_ids'][0])\nprint(tokenized_datasets['train']['tags'][0])\nprint(tokenized_datasets['train']['labels'][0])\nprint(tokenized_datasets['train']['word_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2024-07-13T18:12:28.907518Z","iopub.execute_input":"2024-07-13T18:12:28.908540Z","iopub.status.idle":"2024-07-13T18:12:29.269253Z","shell.execute_reply.started":"2024-07-13T18:12:28.908494Z","shell.execute_reply":"2024-07-13T18:12:29.268160Z"},"trusted":true},"outputs":[{"name":"stdout","text":"['‡∏™‡∏¥‡πâ‡∏ô', '‡∏Ñ‡πâ‡∏≤', '‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô', '‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á', '‡∏°‡∏≤', '‡∏ó‡∏µ‡πà', '‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠', '‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤', '‡∏Ç‡∏ô‡∏™‡πà‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡πÑ‡∏°‡πà', '‡∏ä‡πâ‡∏≤', '‡πÑ‡∏°‡πà', '‡πÄ‡∏£‡πá‡∏ß', '‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏µ', '‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°', '‡∏Å‡∏±‡∏ö', '‡∏£‡∏≤‡∏Ñ‡∏≤', '‡∏ó‡∏µ‡πà', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏£‡∏≠‡∏¢', '‡∏î‡∏≥', '‡πÄ‡∏û‡∏£‡∏≤‡∏∞', '‡πÉ‡∏™‡πà', '‡πÅ‡∏•‡πâ‡∏ß', '‡πÑ‡∏°‡πà', '‡πÇ‡∏î‡∏ô', '‡∏Å‡∏±‡∏î', '‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡πà‡∏≤', '‡∏Å‡∏≤‡∏£‡∏Ç‡∏ô‡∏™‡πà‡∏á', '‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß']\n[11, 175, 4610, 6478, 140, 6018, 140, 3920, 6443, 8472, 5398, 7561, 156, 5671, 3167, 4799, 7652, 167, 2930, 6702, 175, 8480, 6104, 8071, 8482, 5398, 5136, 169, 3894, 3552, 3894, 8484, 4953, 7111, 139, 2617, 4665, 6104, 4665, 4358, 4949, 6018, 188, 2939, 5013, 145, 6018, 188, 2939, 5013, 184, 3920, 8490, 4953, 138, 6812, 3554, 6958, 6910, 184, 8477, 7322, 3894, 4665, 2939, 8085, 169, 2930, 4949, 2930, 6702, 7439, 169, 8261, 154, 6812, 184, 5795, 3920, 2930, 3894, 187, 4665, 5013, 185, 8092, 188, 2939, 5013, 186, 3827, 2617, 138, 7751, 140, 6729, 5398, 2939, 4949, 5724, 138, 6663, 7806, 2617, 4665, 6104, 169, 4953, 3827, 8484, 3920, 8490, 4953, 12]\n[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1]\n[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100]\n[None, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 10, 10, 11, 11, 11, 12, 12, 12, 12, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 15, 16, 16, 16, 16, 17, 18, 19, 19, 20, 20, 21, 21, 21, 21, 21, 22, 22, 22, 23, 23, 24, 24, 24, 25, 25, 25, 26, 26, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, None]\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"args = TrainingArguments(\n    f\"test-{task}\",\n    eval_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=30,\n    weight_decay=0.01,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:17.958371Z","iopub.execute_input":"2024-07-13T17:50:17.958834Z","iopub.status.idle":"2024-07-13T17:50:17.971840Z","shell.execute_reply.started":"2024-07-13T17:50:17.958774Z","shell.execute_reply":"2024-07-13T17:50:17.970747Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"metric = load_metric(\"seqeval\")","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:17.973484Z","iopub.execute_input":"2024-07-13T17:50:17.973919Z","iopub.status.idle":"2024-07-13T17:50:59.001512Z","shell.execute_reply.started":"2024-07-13T17:50:17.973888Z","shell.execute_reply":"2024-07-13T17:50:59.000374Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/152412463.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric(\"seqeval\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0527206eb5d54c38a4320f2f760f3914"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for seqeval contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/seqeval.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"}],"execution_count":25},{"cell_type":"code","source":"id_tag = {value: key for key, value in tag_id.items()}\nid_tag","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:59.002843Z","iopub.execute_input":"2024-07-13T17:50:59.003174Z","iopub.status.idle":"2024-07-13T17:50:59.010879Z","shell.execute_reply.started":"2024-07-13T17:50:59.003146Z","shell.execute_reply":"2024-07-13T17:50:59.009789Z"},"trusted":true},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{0: 'Appearance',\n 1: 'DeliveryTime',\n 2: 'Price',\n 3: 'Quality',\n 4: 'StoreService',\n 5: 'NEG-Quality',\n 6: 'O',\n 7: 'NEG-Appearance',\n 8: 'NEG-StoreService',\n 9: 'Size',\n 10: 'NEG-DeliveryTime',\n 11: 'Packaging',\n 12: 'NEG-Price',\n 13: 'NEG-Size',\n 14: 'NEG-Packaging'}"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"def compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n    true_predictions = [\n        [id_tag[p].replace('_','-') for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [id_tag[l].replace('_','-') for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:59.012537Z","iopub.execute_input":"2024-07-13T17:50:59.012977Z","iopub.status.idle":"2024-07-13T17:50:59.023286Z","shell.execute_reply.started":"2024-07-13T17:50:59.012939Z","shell.execute_reply":"2024-07-13T17:50:59.022273Z"},"trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:59.030267Z","iopub.execute_input":"2024-07-13T17:50:59.031295Z","iopub.status.idle":"2024-07-13T17:50:59.040138Z","shell.execute_reply.started":"2024-07-13T17:50:59.031256Z","shell.execute_reply":"2024-07-13T17:50:59.038967Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"val\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:57:24.183235Z","iopub.execute_input":"2024-07-13T17:57:24.183704Z","iopub.status.idle":"2024-07-13T17:57:24.200862Z","shell.execute_reply.started":"2024-07-13T17:57:24.183673Z","shell.execute_reply":"2024-07-13T17:57:24.199623Z"},"trusted":true},"outputs":[],"execution_count":35},{"cell_type":"code","source":"wandb.login()\n#87bcb981fbde472f632869f1bc5b2bfa8b11edeb","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:50:59.088238Z","iopub.execute_input":"2024-07-13T17:50:59.088574Z","iopub.status.idle":"2024-07-13T17:51:09.561033Z","shell.execute_reply.started":"2024-07-13T17:50:59.088546Z","shell.execute_reply":"2024-07-13T17:51:09.559985Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:57:41.348942Z","iopub.execute_input":"2024-07-13T17:57:41.350071Z","iopub.status.idle":"2024-07-13T18:08:09.371975Z","shell.execute_reply.started":"2024-07-13T17:57:41.350022Z","shell.execute_reply":"2024-07-13T18:08:09.369981Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240713_175741-o0092fo6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/phuwadol19090/huggingface/runs/o0092fo6' target=\"_blank\">test-asp</a></strong> to <a href='https://wandb.ai/phuwadol19090/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/phuwadol19090/huggingface' target=\"_blank\">https://wandb.ai/phuwadol19090/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/phuwadol19090/huggingface/runs/o0092fo6' target=\"_blank\">https://wandb.ai/phuwadol19090/huggingface/runs/o0092fo6</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='40' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  40/1170 09:34 < 4:44:48, 0.07 it/s, Epoch 1/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2365\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2369\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2793\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2791\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2793\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2796\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2750\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2750\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2753\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3641\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3638\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3640\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3641\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3642\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3644\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3645\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3651\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3826\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3823\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   3825\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3826\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3827\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3828\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:4040\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   4038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   4039\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 4040\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4041\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m   4043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3338\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3337\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3338\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3339\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3340\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1909\u001b[0m, in \u001b[0;36mBertForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1907\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1908\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m-> 1909\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1912\u001b[0m     output \u001b[38;5;241m=\u001b[39m (logits,) \u001b[38;5;241m+\u001b[39m outputs[\u001b[38;5;241m2\u001b[39m:]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mIndexError\u001b[0m: Target 180 is out of bounds."],"ename":"IndexError","evalue":"Target 180 is out of bounds.","output_type":"error"}],"execution_count":37},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-07-13T17:51:23.438034Z","iopub.status.idle":"2024-07-13T17:51:23.439354Z","shell.execute_reply.started":"2024-07-13T17:51:23.439056Z","shell.execute_reply":"2024-07-13T17:51:23.439081Z"},"trusted":true},"outputs":[],"execution_count":null}]}