{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":80835,"databundleVersionId":9026511,"sourceType":"competition"}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install Library","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics -q","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:40:22.258981Z","iopub.execute_input":"2024-07-06T16:40:22.259309Z","iopub.status.idle":"2024-07-06T16:40:36.658026Z","shell.execute_reply.started":"2024-07-06T16:40:22.259285Z","shell.execute_reply":"2024-07-06T16:40:36.656917Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os,os.path as osp\nfrom glob import glob\nfrom tqdm import tqdm\nimport shutil\nimport random\n\nimport cv2\nimport numpy as np\n\nfrom ultralytics import YOLO\nfrom ultralytics import RTDETR\nfrom ultralytics import settings\n\nimport yaml\nfrom sklearn.model_selection import train_test_split\n\nsettings.update({\"wandb\": False})","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:40:36.660039Z","iopub.execute_input":"2024-07-06T16:40:36.660342Z","iopub.status.idle":"2024-07-06T16:40:40.732238Z","shell.execute_reply.started":"2024-07-06T16:40:36.660315Z","shell.execute_reply":"2024-07-06T16:40:40.731429Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/th-road-safety/TrafficHackathon'\ntrain_dir = dataset_dir + '/train'\ntest_dir = dataset_dir + '/test'\nsave_dir = '/kaggle/working/yolov8'\nval_ratio = 0.05\n\n# Create folder dataset for yolov8\nos.makedirs(save_dir,exist_ok=True)\nos.makedirs(save_dir + '/' + 'images',exist_ok=True)\nos.makedirs(save_dir + '/' + 'labels',exist_ok=True)\n\nos.makedirs(save_dir + '/' + 'images/train',exist_ok=True)\nos.makedirs(save_dir + '/' + 'labels/train',exist_ok=True)\n\nos.makedirs(save_dir + '/' + 'images/val',exist_ok=True)\nos.makedirs(save_dir + '/' + 'labels/val',exist_ok=True)\n\n# List annotation file  \nann_paths = glob(osp.join(train_dir , '*.txt'))\nann_train, ann_val = train_test_split(ann_paths, test_size=val_ratio)\n\n# Copy train images and labels folder\nprint('Copy images and labels in train folder')\nfor ann_path in tqdm(ann_train):\n    filename = osp.split(ann_path[:-4])[-1]\n    \n    img_path = ann_path[0:-4] + '.jpg'\n    save_img_path = save_dir + '/images/train/' + filename + '.jpg'\n    save_label_path = save_dir + '/labels/train/' + filename + '.txt'\n    \n    if os.path.exists(img_path):  \n        shutil.copy(img_path, save_img_path)\n        shutil.copy(ann_path, save_label_path)\n\n# Copy val images and labels folder\nprint('Copy images and labels in val folder')\nfor ann_path in tqdm(ann_val):\n    filename = osp.split(ann_path[:-4])[-1]\n    \n    img_path = ann_path[0:-4] + '.jpg'\n    save_img_path = save_dir + '/images/val/' + filename + '.jpg'\n    save_label_path = save_dir + '/labels/val/' + filename + '.txt'\n    \n    if os.path.exists(img_path):  \n        shutil.copy(img_path, save_img_path)\n        shutil.copy(ann_path,  save_label_path)\n    \n# Create .yaml yolo format\nprint('Create config file dataset.yaml')\nclasses_list = []\nindex = 0\n\nfor label in open(train_dir + \"/classes.txt\", \"r\").read().split('\\n'): \n    classes_list.append(str(index) + ': ' + label)\n    index += 1\n    \ndata = {\n    \"path\" : save_dir,\n    \"train\" : save_dir + '/' + 'images/train',\n    \"val\" : save_dir + '/' + 'images/val',\n    \"names\" : classes_list\n}\n\nwith open('yolov8/dataset.yaml', 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False, sort_keys=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:40:40.733355Z","iopub.execute_input":"2024-07-06T16:40:40.733744Z","iopub.status.idle":"2024-07-06T16:41:06.058076Z","shell.execute_reply.started":"2024-07-06T16:40:40.733721Z","shell.execute_reply":"2024-07-06T16:41:06.057167Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Copy images and labels in train folder\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1525/1525 [00:23<00:00, 63.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Copy images and labels in val folder\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:01<00:00, 66.05it/s]","output_type":"stream"},{"name":"stdout","text":"Create config file dataset.yaml\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"#model = YOLO('yolov8m.pt')  # load a pretrained model (recommended for training)\nmodel = RTDETR(\"rtdetr-l.pt\")\nresults = model.train(data='yolov8/dataset.yaml',project='detect',name = 'train', \n                     epochs=50\n                     )","metadata":{"execution":{"iopub.status.busy":"2024-07-05T16:26:12.404060Z","iopub.execute_input":"2024-07-05T16:26:12.404683Z","iopub.status.idle":"2024-07-05T18:38:57.161085Z","shell.execute_reply.started":"2024-07-05T16:26:12.404653Z","shell.execute_reply":"2024-07-05T18:38:57.160144Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.2.49 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=rtdetr-l.pt, data=yolov8/dataset.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=detect, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=detect/train2\nOverriding model.yaml nc=80 with nc=12\nWARNING âš ï¸ no model scale passed. Assuming scale='l'.\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 28        [21, 24, 27]  1   7326512  ultralytics.nn.modules.head.RTDETRDecoder    [12, [256, 256, 256]]         \nrt-detr-l summary: 673 layers, 32830736 parameters, 32830736 gradients, 108.0 GFLOPs\n\nTransferred 926/941 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir detect/train2', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov8/labels/train... 1598 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1598/1598 [00:01<00:00, 1243.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolov8/labels/train.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov8/labels/val... 1035 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1035/1035 [00:00<00:00, 1078.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolov8/labels/val.cache\nPlotting labels to detect/train2/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mdetect/train2\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       1/50      14.2G      1.521      2.731     0.6071        212        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:20<00:00,  1.41s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.815      0.231      0.224      0.156\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       2/50      14.2G      0.668     0.6039    0.09897        210        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:12<00:00,  1.33s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.605       0.44      0.487      0.349\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       3/50      14.7G     0.5755     0.5123    0.07729        251        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.863      0.565      0.653      0.479\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       4/50      14.1G     0.5435     0.4854    0.06869        155        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.858      0.711      0.769      0.566\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       5/50      14.5G     0.5184      0.461    0.06506        192        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.903      0.754       0.83      0.617\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       6/50      14.2G     0.5005     0.4378    0.06271        218        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.888      0.797      0.843      0.626\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       7/50      14.1G     0.4947     0.4345    0.06031        250        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.925      0.787      0.825      0.611\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       8/50      14.3G     0.4893     0.4281    0.05999        329        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.31s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.915      0.821       0.86      0.655\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       9/50        14G     0.5003     0.4192    0.05804        382        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.932       0.85       0.89      0.676\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      10/50      14.4G     0.4724     0.4185    0.05626        244        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.917      0.828      0.877      0.665\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      11/50      14.3G     0.4766     0.4161    0.05536        392        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:12<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.949      0.859      0.901       0.69\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      12/50      13.5G     0.4603     0.3999    0.05455        221        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.938      0.865      0.916      0.699\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      13/50        14G     0.4458     0.4004    0.05174        192        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.928      0.874      0.913      0.694\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      14/50      13.9G     0.4554     0.3969    0.05114        259        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728       0.93      0.888      0.927      0.714\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      15/50      13.3G     0.4217     0.3824    0.04977        274        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.946      0.892      0.931      0.717\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      16/50      14.6G     0.4379      0.385    0.04937        375        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.945      0.888      0.927      0.717\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      17/50      14.2G     0.4367     0.3837    0.04949        168        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728       0.95      0.891      0.924      0.713\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      18/50      14.1G     0.4258      0.383    0.04826        244        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.945      0.909      0.939      0.726\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      19/50      14.3G     0.4175      0.374    0.04715        264        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.31s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.956      0.892      0.933      0.728\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      20/50      14.4G     0.4324     0.3765    0.04621        270        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.951      0.902      0.931      0.727\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      21/50      14.5G     0.4139     0.3825    0.04748        174        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728       0.95      0.909      0.942      0.735\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      22/50      13.7G     0.4121     0.3776     0.0454        235        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.31s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.956      0.914      0.944      0.733\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      23/50      13.6G     0.4222     0.3753    0.04407        371        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:12<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.953      0.903      0.941      0.726\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      24/50      14.1G     0.4266     0.3788    0.04693        340        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.949        0.9      0.943      0.719\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      25/50      13.4G     0.4219     0.3742    0.04703        214        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.958      0.908      0.947      0.741\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      26/50      14.8G      0.409      0.378    0.04603        268        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.957      0.902      0.938      0.737\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      27/50        14G     0.4063     0.3652    0.04404        187        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.31s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.955      0.911      0.945      0.742\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      28/50        14G     0.3941     0.3654    0.04299        262        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.956      0.916      0.948      0.747\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      29/50      14.1G     0.3921     0.3597    0.04493        204        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.952      0.909      0.946      0.741\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      30/50      13.8G     0.3913     0.3639    0.04365        271        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.962      0.917      0.953      0.753\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      31/50      14.2G     0.3834     0.3562    0.04301        144        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.962      0.921      0.953      0.762\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      32/50      14.5G     0.3741      0.351    0.04055        282        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.962      0.925      0.954      0.766\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      33/50      14.1G     0.3853     0.3511    0.04001        215        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.31s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.956       0.93      0.958      0.761\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      34/50      14.7G     0.3761     0.3523    0.04097        212        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.44it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.968      0.915      0.955      0.761\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      35/50        14G     0.3729     0.3469    0.04058        205        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:12<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.949      0.925      0.949      0.762\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      36/50      14.3G     0.3689     0.3499    0.04019        151        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.967      0.924      0.959       0.77\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      37/50        14G     0.3671     0.3484    0.03908        188        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.967      0.928      0.958      0.768\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      38/50      13.9G     0.3676     0.3468    0.03851        310        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.968      0.938      0.962      0.776\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      39/50        14G     0.3656     0.3443    0.03869        253        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.966      0.928      0.959      0.767\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      40/50      14.2G     0.3494     0.3379    0.03871        304        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.972      0.934      0.962      0.783\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      41/50        14G     0.3241      0.326    0.03706        180        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:15<00:00,  1.35s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.967      0.939      0.962       0.78\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      42/50      13.6G     0.3222     0.3241    0.03652        260        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.967      0.931      0.959      0.777\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      43/50      13.3G     0.3212     0.3217    0.03663        145        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.977      0.938      0.963      0.783\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      44/50      13.5G     0.3165     0.3221    0.03526        274        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.974       0.94      0.964      0.784\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      45/50      14.8G       0.32     0.3157    0.03503         96        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.976      0.938      0.965      0.786\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      46/50        14G     0.3138     0.3134    0.03446        194        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.31s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.975      0.943      0.965      0.792\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      47/50      13.6G     0.3114     0.3126    0.03447        102        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.31s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.971      0.944      0.968      0.794\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      48/50      13.6G     0.3042      0.311    0.03347        142        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.976       0.94      0.966      0.796\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      49/50      14.3G     0.3003     0.3099    0.03419        148        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.978      0.943      0.968      0.797\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n      50/50      13.6G     0.3044     0.3075    0.03361        170        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [02:11<00:00,  1.32s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.978      0.943      0.968      0.795\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n50 epochs completed in 2.199 hours.\nOptimizer stripped from detect/train2/weights/last.pt, 66.2MB\nOptimizer stripped from detect/train2/weights/best.pt, 66.2MB\n\nValidating detect/train2/weights/best.pt...\nUltralytics YOLOv8.2.49 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nrt-detr-l summary: 494 layers, 32008400 parameters, 0 gradients, 103.5 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:27<00:00,  1.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       1035      12728      0.978      0.944      0.968      0.796\n        0: pedestrian         698       1368      0.968      0.936      0.972      0.726\n            1: bicycle        191        223      0.997      0.933       0.96      0.804\n         2: motorcycle        809       4621      0.959       0.92      0.958      0.763\n                3: car        893       3548      0.963      0.907      0.961      0.766\n               4: taxi        526        812      0.956      0.941      0.971      0.816\n                5: van        169        189      0.989       0.95      0.974      0.759\n              6: truck        651       1370      0.988      0.966      0.983      0.831\n                7: bus         98        136      0.985      0.955      0.955      0.787\n      8: emergency_car         20         20      0.984          1      0.995      0.931\n             9: tuktuk        173        323      0.966      0.882      0.921      0.729\n             10: other        118        118      0.997      0.992      0.995      0.849\nSpeed: 0.1ms preprocess, 17.3ms inference, 0.0ms loss, 0.3ms postprocess per image\nResults saved to \u001b[1mdetect/train2\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:41:06.059695Z","iopub.execute_input":"2024-07-06T16:41:06.059986Z","iopub.status.idle":"2024-07-06T16:41:06.065317Z","shell.execute_reply.started":"2024-07-06T16:41:06.059961Z","shell.execute_reply":"2024-07-06T16:41:06.064575Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"model = RTDETR(\"rtdetr-x.pt\")\nresults = model.train(data='yolov8/dataset.yaml',project='detect',name = 'train', \n                     epochs=50,\n                    batch=8\n                     #auto_augment='autoaugment'\n                     )\n#                      hsv_h=0.1,\n#                      hsv_s=0.3,\n#                      hsv_v=0.3,\n#                      flipud=0.1,\n#                      fliplr=0.5,\n#                      mosaic=0.5,\n#                      mixup=0.2","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:41:06.066369Z","iopub.execute_input":"2024-07-06T16:41:06.066656Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/rtdetr-x.pt to 'rtdetr-x.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129M/129M [00:00<00:00, 294MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Ultralytics YOLOv8.2.50 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=rtdetr-x.pt, data=yolov8/dataset.yaml, epochs=50, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=detect, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 26.0MB/s]\n2024-07-06 16:41:10,277\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-07-06 16:41:11,365\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=12\nWARNING âš ï¸ no model scale passed. Assuming scale='x'.\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1     25792  ultralytics.nn.modules.block.HGStem          [3, 32, 64]                   \n  1                  -1  6    259200  ultralytics.nn.modules.block.HGBlock         [64, 64, 128, 3, 6]           \n  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n  3                  -1  6   1248256  ultralytics.nn.modules.block.HGBlock         [128, 128, 512, 3, 6]         \n  4                  -1  6   1788928  ultralytics.nn.modules.block.HGBlock         [512, 128, 512, 3, 6, False, True]\n  5                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n  6                  -1  6   2079232  ultralytics.nn.modules.block.HGBlock         [512, 256, 1024, 5, 6, True, False]\n  7                  -1  6   2472448  ultralytics.nn.modules.block.HGBlock         [1024, 256, 1024, 5, 6, True, True]\n  8                  -1  6   2472448  ultralytics.nn.modules.block.HGBlock         [1024, 256, 1024, 5, 6, True, True]\n  9                  -1  6   2472448  ultralytics.nn.modules.block.HGBlock         [1024, 256, 1024, 5, 6, True, True]\n 10                  -1  6   2472448  ultralytics.nn.modules.block.HGBlock         [1024, 256, 1024, 5, 6, True, True]\n 11                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n 12                  -1  6   8221696  ultralytics.nn.modules.block.HGBlock         [1024, 512, 2048, 5, 6, True, False]\n 13                  -1  6   9794560  ultralytics.nn.modules.block.HGBlock         [2048, 512, 2048, 5, 6, True, True]\n 14                  -1  1    787200  ultralytics.nn.modules.conv.Conv             [2048, 384, 1, 1, None, 1, 1, False]\n 15                  -1  1   2168192  ultralytics.nn.modules.transformer.AIFI      [384, 2048, 8]                \n 16                  -1  1    148224  ultralytics.nn.modules.conv.Conv             [384, 384, 1, 1]              \n 17                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 18                  10  1    393984  ultralytics.nn.modules.conv.Conv             [1024, 384, 1, 1, None, 1, 1, False]\n 19            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 20                  -1  3   5019648  ultralytics.nn.modules.block.RepC3           [768, 384, 3]                 \n 21                  -1  1    148224  ultralytics.nn.modules.conv.Conv             [384, 384, 1, 1]              \n 22                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 23                   4  1    197376  ultralytics.nn.modules.conv.Conv             [512, 384, 1, 1, None, 1, 1, False]\n 24            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 25                  -1  3   5019648  ultralytics.nn.modules.block.RepC3           [768, 384, 3]                 \n 26                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 27            [-1, 21]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 28                  -1  3   5019648  ultralytics.nn.modules.block.RepC3           [768, 384, 3]                 \n 29                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 30            [-1, 16]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 31                  -1  3   5019648  ultralytics.nn.modules.block.RepC3           [768, 384, 3]                 \n 32        [25, 28, 31]  1   7424816  ultralytics.nn.modules.head.RTDETRDecoder    [12, [384, 384, 384]]         \nrt-detr-x summary: 867 layers, 67328112 parameters, 67328112 gradients, 232.4 GFLOPs\n\nTransferred 1226/1241 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir detect/train', view at http://localhost:6006/\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 122MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov8/labels/train... 1524 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1524/1524 [00:01<00:00, 1143.68it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolov8/labels/train.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov8/labels/val... 81 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:00<00:00, 1163.74it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolov8/labels/val.cache\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 193 weight(decay=0.0), 256 weight(decay=0.0005), 276 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mdetect/train\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/191 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       1/50      10.9G      1.312      3.149     0.4783         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191/191 [03:30<00:00,  1.10s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.43it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         81        904      0.844      0.283      0.291      0.206\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/191 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       2/50      10.4G     0.6015     0.5886    0.08004         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191/191 [03:22<00:00,  1.06s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.02it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         81        904      0.657      0.527      0.583      0.404\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/191 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       3/50      10.2G     0.5345     0.5171    0.07261         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191/191 [03:21<00:00,  1.05s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.02it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         81        904      0.852      0.661      0.711      0.509\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/191 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       4/50        11G     0.5116     0.4703    0.06602         96        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191/191 [03:20<00:00,  1.05s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.03it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         81        904      0.816      0.746      0.794       0.58\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/191 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       5/50      10.3G     0.4885     0.4613    0.06168         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191/191 [03:20<00:00,  1.05s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.03it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         81        904      0.919      0.779       0.84      0.589\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/191 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       6/50      10.2G     0.4881     0.4595    0.05977         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191/191 [03:20<00:00,  1.05s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.03it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         81        904       0.93      0.775      0.857      0.618\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/191 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       7/50      10.2G     0.4654     0.4453    0.05901         68        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191/191 [03:20<00:00,  1.05s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.01it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         81        904      0.936       0.77      0.842      0.605\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/191 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/Context.cpp:71.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n       8/50      10.3G     0.4454     0.4251    0.05969         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 191/191 [03:21<00:00,  1.05s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/6 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"answer_list = []\n# Use the model\nmodel = RTDETR('/kaggle/working/detect/train/weights/best.pt')\n\nfor file in tqdm(glob(test_dir + '/*')):\n    \n    bbox_list = []\n    cls_list = []\n    scores_list = []\n\n    # Predict on an image\n    results = model(file, verbose=False)\n    # Process results list\n    for result in results:\n        \n        boxes = result.boxes\n        for box in boxes:\n            coor_box = box.xyxy.cpu().numpy().tolist()  # Boxes object for bounding box outputs\n            class_box = box.cls.cpu().numpy().tolist()\n            class_scores = box.conf.cpu().numpy().tolist()\n        \n            bbox_list.append(coor_box[0])\n            cls_list.append(int(class_box[0]))\n            scores_list.append(class_scores[0])\n        \n        value = (file.split('/')[-1], bbox_list, cls_list,scores_list )\n\n    answer_list.append(value)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ncolumn_name = ['id','boxes', 'labels', 'scores']\nxml_df = pd.DataFrame(answer_list, columns=column_name)\nxml_df.to_csv('/kaggle/working/50_RTDTRx_finetune.csv', index=None)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xml_df","metadata":{"execution":{"iopub.status.busy":"2024-07-05T18:50:50.324893Z","iopub.execute_input":"2024-07-05T18:50:50.325243Z","iopub.status.idle":"2024-07-05T18:50:50.389278Z","shell.execute_reply.started":"2024-07-05T18:50:50.325217Z","shell.execute_reply":"2024-07-05T18:50:50.388389Z"},"trusted":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                              id  \\\n0                  TF7-KS-2-03-28032023_1411.jpg   \n1     TF7-DM-1-03-28032023(12.00-13.00)_1563.jpg   \n2        TF7-DM-02-28032023(12.00-13.00)_964.jpg   \n3     TF7-BT-3-03-28032023(12.00-13.00)_1338.jpg   \n4     TF7-KS-1-01-28032023(12.00-13.00)_1444.jpg   \n...                                          ...   \n1402  TF7-KS-1-02-28032023(12.00-13.00)_1263.jpg   \n1403   TF7-RW-1-03-28032023(12.00-13.00)_859.jpg   \n1404   TF7-KS-1-03-28032023(12.00-13.00)_984.jpg   \n1405  TF7-KS-1-01-28032023(12.00-13.00)_1234.jpg   \n1406  TF4-DS-12-02-28032023(12.00-13.00)_780.jpg   \n\n                                                  boxes  \\\n0     [[1604.2265625, 772.9917602539062, 1782.855346...   \n1     [[620.3967895507812, 126.69283294677734, 985.8...   \n2     [[205.878173828125, 827.057373046875, 580.6764...   \n3     [[1494.9986572265625, -0.06147220730781555, 17...   \n4     [[1109.875244140625, 159.33265686035156, 1170....   \n...                                                 ...   \n1402  [[890.6900024414062, 503.99090576171875, 1118....   \n1403  [[975.640380859375, 251.21788024902344, 1301.8...   \n1404  [[1055.2891845703125, 233.0370330810547, 1358....   \n1405  [[1131.261962890625, 225.55148315429688, 1221....   \n1406  [[1556.6392822265625, 0.0701826810836792, 1793...   \n\n                                                 labels  \\\n0                                    [2, 3, 2, 2, 3, 6]   \n1                              [3, 4, 2, 3, 3, 2, 2, 2]   \n2     [3, 4, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 4, 2, 1, ...   \n3                                             [3, 2, 2]   \n4                                       [6, 6, 6, 0, 6]   \n...                                                 ...   \n1402  [3, 3, 0, 1, 2, 2, 2, 7, 2, 3, 2, 2, 2, 2, 2, ...   \n1403               [3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4]   \n1404                                    [3, 6, 3, 4, 2]   \n1405                        [3, 6, 2, 4, 2, 0, 2, 3, 3]   \n1406                                    [6, 2, 3, 0, 3]   \n\n                                                 scores  \n0     [0.9686948657035828, 0.963720977306366, 0.9288...  \n1     [0.9757187366485596, 0.9729746580123901, 0.978...  \n2     [0.9816930294036865, 0.9542747139930725, 0.931...  \n3     [0.9589695334434509, 0.879623532295227, 0.8697...  \n4     [0.4902559518814087, 0.3028828501701355, 0.507...  \n...                                                 ...  \n1402  [0.9504495859146118, 0.9273397922515869, 0.959...  \n1403  [0.9795659184455872, 0.9412915706634521, 0.969...  \n1404  [0.9763023853302002, 0.9730518460273743, 0.984...  \n1405  [0.9173907041549683, 0.8902944326400757, 0.830...  \n1406  [0.9521411061286926, 0.9485293626785278, 0.968...  \n\n[1407 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>boxes</th>\n      <th>labels</th>\n      <th>scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TF7-KS-2-03-28032023_1411.jpg</td>\n      <td>[[1604.2265625, 772.9917602539062, 1782.855346...</td>\n      <td>[2, 3, 2, 2, 3, 6]</td>\n      <td>[0.9686948657035828, 0.963720977306366, 0.9288...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TF7-DM-1-03-28032023(12.00-13.00)_1563.jpg</td>\n      <td>[[620.3967895507812, 126.69283294677734, 985.8...</td>\n      <td>[3, 4, 2, 3, 3, 2, 2, 2]</td>\n      <td>[0.9757187366485596, 0.9729746580123901, 0.978...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TF7-DM-02-28032023(12.00-13.00)_964.jpg</td>\n      <td>[[205.878173828125, 827.057373046875, 580.6764...</td>\n      <td>[3, 4, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 4, 2, 1, ...</td>\n      <td>[0.9816930294036865, 0.9542747139930725, 0.931...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TF7-BT-3-03-28032023(12.00-13.00)_1338.jpg</td>\n      <td>[[1494.9986572265625, -0.06147220730781555, 17...</td>\n      <td>[3, 2, 2]</td>\n      <td>[0.9589695334434509, 0.879623532295227, 0.8697...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TF7-KS-1-01-28032023(12.00-13.00)_1444.jpg</td>\n      <td>[[1109.875244140625, 159.33265686035156, 1170....</td>\n      <td>[6, 6, 6, 0, 6]</td>\n      <td>[0.4902559518814087, 0.3028828501701355, 0.507...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1402</th>\n      <td>TF7-KS-1-02-28032023(12.00-13.00)_1263.jpg</td>\n      <td>[[890.6900024414062, 503.99090576171875, 1118....</td>\n      <td>[3, 3, 0, 1, 2, 2, 2, 7, 2, 3, 2, 2, 2, 2, 2, ...</td>\n      <td>[0.9504495859146118, 0.9273397922515869, 0.959...</td>\n    </tr>\n    <tr>\n      <th>1403</th>\n      <td>TF7-RW-1-03-28032023(12.00-13.00)_859.jpg</td>\n      <td>[[975.640380859375, 251.21788024902344, 1301.8...</td>\n      <td>[3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4]</td>\n      <td>[0.9795659184455872, 0.9412915706634521, 0.969...</td>\n    </tr>\n    <tr>\n      <th>1404</th>\n      <td>TF7-KS-1-03-28032023(12.00-13.00)_984.jpg</td>\n      <td>[[1055.2891845703125, 233.0370330810547, 1358....</td>\n      <td>[3, 6, 3, 4, 2]</td>\n      <td>[0.9763023853302002, 0.9730518460273743, 0.984...</td>\n    </tr>\n    <tr>\n      <th>1405</th>\n      <td>TF7-KS-1-01-28032023(12.00-13.00)_1234.jpg</td>\n      <td>[[1131.261962890625, 225.55148315429688, 1221....</td>\n      <td>[3, 6, 2, 4, 2, 0, 2, 3, 3]</td>\n      <td>[0.9173907041549683, 0.8902944326400757, 0.830...</td>\n    </tr>\n    <tr>\n      <th>1406</th>\n      <td>TF4-DS-12-02-28032023(12.00-13.00)_780.jpg</td>\n      <td>[[1556.6392822265625, 0.0701826810836792, 1793...</td>\n      <td>[6, 2, 3, 0, 3]</td>\n      <td>[0.9521411061286926, 0.9485293626785278, 0.968...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1407 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":18}]}